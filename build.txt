The concept of Graph Neural Network (GNN) models designed for brain disorder classification that rely solely on imaging data, thus operating **without using auxiliary phenotypic or demographic information**, is directly supported by the sources. These models primarily use regional brain graphs where nodes represent brain regions (ROIs) and edges represent functional connectivity derived from fMRI or EEG.

Below are the specific GNN models identified in the sources as utilizing pure imaging features, along with details of their architecture:

## I. GNN Models Primarily Operating on Imaging Data (Regional Brain Graphs)

Models belonging to the *regional brain graph* category often focus on identifying local brain regions and biomarkers, and a recognized limitation of these methods is that they frequently **ignore or do not sufficiently exploit non-imaging information** such as gender, age, and acquisition site.

### 1. BrainGNN (Interpretable Brain Graph Neural Network)

BrainGNN is an architecture proposed for analyzing functional Magnetic Resonance Images (fMRI) to map regional and cross-regional functional activation patterns for classification tasks, such as classifying neurodisorder patients versus healthy control (HC) subjects.

**Input Data Structure:**
*   BrainGNN models **each subject’s brain as one graph**, where each brain Region of Interest (ROI) is a node.
*   Nodes ($V$) are preordered and defined by partitioning the brain into $N$ ROIs.
*   **Node Features ($F$):** Input features are derived from fMRI data, typically the **Pearson correlation coefficient** (as a vector of correlation coefficients to all ROIs) extracted from the mean time series of each ROI. Node features often form an $N \times D$ matrix where $D=84$ or $D=268$ depending on the atlas used.
*   **Edges ($E$):** Edges are defined by **thresholding partial correlations**, which is done to achieve sparse connections and avoid the over-smoothing effect common in general GNNs for dense graphs.

**Core Architecture Layers:**
The architecture consists of blocks of specialized layers trained in an end-to-end fashion.

1.  **ROI-aware Graph Convolutional (Ra-GConv) Layers:**
    *   **Purpose:** These layers address the limitation that existing GNNs for fMRI analysis often implicitly assume that brain ROIs are identical (translation invariant). Ra-GConv layers are designed to **learn different embedding weights** in graph convolutional kernels, conditioned on regional information.
    *   **Mechanism:** Nodes are softly assigned to communities based on their membership scores. Each node is embedded using basis vectors specific to the communities it belongs to. The regional information input ($r_i$) for node $v_i$ often uses **one-hot encoding** to represent the ROI's location, since brain nodes are well-aligned using parcellation atlases.

2.  **ROI-selection Pooling (R-pool) Layers:**
    *   **Purpose:** These layers select salient ROIs (nodes) to retain, reducing the graph size and enhancing interpretability by highlighting important biomarkers.
    *   **Mechanism:** Node representations are projected to a learnable vector. Nodes with **large projected values are retained** along with their corresponding connections (a pruning method).
    *   **Regularization:** The pooling operation is regulated by innovative loss terms, including unit loss, **Group-Level Consistency (GLC) loss**, and **TopK Pooling (TPK) loss**, to encourage reasonable ROI selection.

3.  **Readout Layer:**
    *   **Function:** Summarizes the final node feature vectors into a single fixed-size vector representation for the whole graph.
    *   **Operation:** Produces the final summary vector ($z$) by **concatenating both the mean and max element-wise summarization** of the node representations from previous layers. This vector is then fed into a Multi-Layer Perceptron (MLP) for final prediction.

### 2. GNN for AD using EEG Functional Connectivity

An empirical evaluation of Functional Connectivity (FC) methods for Alzheimer’s Disease (AD) classification utilized a GNN model that exclusively processes EEG-derived features, aiming to leverage the topological information of the brain graph.

**Input Data Structure:**
*   The GNN takes a **weighted featured brain graph** ($G = \{N, E, F\}$) as input, where $N$ is the set of nodes (EEG electrodes), $E$ is the set of edges (adjacency matrix $A$), and $F$ is the node feature matrix.
*   **Adjacency Matrix ($A$ / Edges $E$):** Constructed using various **Functional Connectivity (FC) measures** (e.g., Phase Lag Index, Coherence, Mutual Information) derived from EEG signals, providing the edge weights. These graphs are sparser than fully connected graphs.
*   **Node Feature Matrix ($F$):** An $N \times D$ matrix where $D=100$. Each row encodes a 100-dimensional feature vector consisting of **Power Spectral Density (PSD)** computed across the $0–100 \text{ Hz}$ interval for the corresponding electrode (node).

**Core Architecture Layers (GCN):**
1.  **Graph Convolutional Network (GCN) Layers:**
    *   **Mechanism:** The GCN operates based on the message-passing framework, assuming neighboring nodes should have similar features. The node features ($x_{i}^{l}$) are updated by aggregating information from neighboring nodes ($j \in G_i$), weighted by the edge strength ($e_{ij}$).
    *   **Layer Stacking:** The optimal architecture found utilized **two graph convolutional layers** (N-GCN=2), suggesting the model aggregates information from 1-hop and 2-hop neighbors.

2.  **Readout Layer:**
    *   The model performs classification based on graph embeddings. The readout layer in this simple GCN architecture computes the **maximum of the node embeddings**.

### 3. RAGNN (Regional-Asymmetric Adaptive GCNN)

RAGNN is an end-to-end framework for Autism Spectrum Disorder (ASD) diagnosis in children using resting-state EEG, which explicitly focuses on features derived from the signal itself, noting that the model **does not consider the effects of different factors, such as age, gender, and symptoms**.

**Input Data Structure:**
*   Uses $46$ symmetrically sorted EEG channels covering four functional brain regions (frontal, parietal, temporal, and occipital lobes).
*   Input matrix ($X$) is structured to enable feature learning in both temporal and spatial dimensions.

**Core Architecture Layers:**
1.  **Regional-Temporal Feature Extractor:**
    *   **Mechanism:** Uses convolutional blocks (consisting of a 2D convolutional layer, average pooling, and ReLU activation) on each of the four brain regions within the left and right hemispheres to extract temporal features of the subregions. Convolution kernel parameters are shared within the respective brain regions.

2.  **Adaptive Graph Structure Learning:**
    *   **Purpose:** Learns the adjacency matrix ($A_{left}, A_{right}$) for the left and right hemi-brains based on the adjacent feature relationships of the electrodes. This contrasts with fixed graph structures (e.g., Euclidean distance based on electrode spatial position).
    *   **Optimization:** The adjacency matrix is obtained by learning the feature relationships and is optimized via a cross-entropy loss function.

3.  **Asymmetric-Spatial Feature Extractor:**
    *   **Mechanism:** Utilizes **Chebyshev graph convolution** to generalize convolution from Euclidean space to non-Euclidean space. This module combines the learned adjacency matrices (graph structure) and the temporal characteristics (node features) to extract non-Euclidean spatial features for the left and right hemispheres separately. The computational complexity of the graph convolution kernel approximated by Chebyshev polynomials is reduced to $K$ (the number of Chebyshev polynomials).

4.  **Attention-Based Feature Fusion:**
    *   An attention mechanism is introduced to dynamically weigh the spatiotemporal features of the left and right brains before they are sent to the classifier.

5.  **Classifier:**
    *   A fully connected layer with SoftMax activation outputs the classification prediction ($\hat{y}$).

### 4. Other Regional GNN Methods

The sources also mention several other GNN architectures built upon regional brain graphs that primarily focus on imaging features and are noted for *ignoring* non-imaging data:

*   **Dynamic Spectral Graph Convolution Networks (DS-GCNs):** Proposed for early Mild Cognitive Impairment (MCI) diagnosis using functional MRI.
*   **Siamese Graph Convolution Network (s-GCN):** Employed polynomial filters to learn a similarity metric between brain connectivity graphs for ASD classification.
*   **Multiview Graph Convolutional Neural Network (MVS-GCN):** Combines graph structure learning with multi-task graph embedding learning to improve classification performance of brain disorders.