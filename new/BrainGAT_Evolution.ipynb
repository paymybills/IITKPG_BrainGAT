{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1492922",
   "metadata": {},
   "source": [
    "# BrainGAT Evolution: Temporal-Spatial Graph Attention Network\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ“‹ CHANGELOG (For Rollback Reference)\n",
    "\n",
    "### Version 2.0.0 - Temporal Branch Enhancement (2025-12-18)\n",
    "\n",
    "**1. Mean + Variance Dynamic Pooling** (Replaces AdaptiveAvgPool1d)\n",
    "- **File**: `TemporalBranch` class\n",
    "- **Change**: Replaced `self.pool = nn.AdaptiveAvgPool1d(1)` with combined mean + std pooling\n",
    "- **Rollback**: Change `temporal_feats = torch.cat([mean_pool, std_pool], dim=-1)` back to `self.pool(x).squeeze(-1)` and restore `self.pool = nn.AdaptiveAvgPool1d(1)` in `__init__`\n",
    "- **Reason**: ASD biomarkers appear in signal fluctuations/volatility, not just mean activation\n",
    "\n",
    "**2. Branch Normalization (LayerNorm)**\n",
    "- **File**: `TemporalSpatialBrainGAT` class\n",
    "- **Change**: Added `self.temporal_norm = nn.LayerNorm(temporal_dim * 2)` and `self.spatial_norm = nn.LayerNorm(spatial_dim)`\n",
    "- **Rollback**: Remove LayerNorm layers and their application in forward pass\n",
    "- **Reason**: Puts temporal and spatial features on equal footing for the classifier\n",
    "\n",
    "**3. Learnable Branch Scaling (Î±, Î²)**\n",
    "- **File**: `TemporalSpatialBrainGAT` class\n",
    "- **Change**: Added `self.temporal_scale = nn.Parameter(torch.ones(1))` and `self.spatial_scale = nn.Parameter(torch.ones(1))`\n",
    "- **Rollback**: Remove scale parameters and multiplication in forward pass\n",
    "- **Reason**: Allows optimizer to explicitly tune branch importance; monitor during training\n",
    "\n",
    "**4. Temporal Context Adjustment (Stride 20)**\n",
    "- **File**: Windowing configuration\n",
    "- **Change**: Changed `STRIDE = 40` to `STRIDE = 20` (from 50% to 75% overlap)\n",
    "- **Rollback**: Change `STRIDE = 20` back to `STRIDE = 40`\n",
    "- **Reason**: More windows per subject captures faster dynamics for 1D-CNN\n",
    "\n",
    "**5. Phase Synchrony Ablation Option**\n",
    "- **File**: `build_multiscale_graphs()` function\n",
    "- **Change**: Added `exclude_phase_sync=False` parameter to optionally remove phase sync from edges\n",
    "- **Rollback**: Remove the `exclude_phase_sync` parameter and conditional logic\n",
    "- **Reason**: Phase sync may be \"stealing\" temporal info from temporal branch\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook extends the baseline BrainGAT model with novel architectural improvements for ASD classification using **IMAGING-ONLY fMRI data** from the full ABIDE dataset.\n",
    "\n",
    "---\n",
    "\n",
    "## Dataset: ABIDE (Autism Brain Imaging Data Exchange)\n",
    "\n",
    "- **Full Dataset**: ~1,100+ subjects across 20+ sites\n",
    "- **Data Used**: Complete set with available resting-state fMRI (all successfully downloaded .1D files)\n",
    "- **Features**: **IMAGING ONLY** - No demographic/phenotypic data used for classification\n",
    "  - Raw fMRI timeseries: 196 timepoints Ã— 392 ROIs (CC400 atlas)\n",
    "  - Derived connectivity features: Correlation, Partial Correlation, Mutual Information, Phase Synchrony\n",
    "- **Labels**: Binary (Control vs ASD) from phenotype file (for ground truth only)\n",
    "\n",
    "---\n",
    "\n",
    "## Baseline BrainGAT (What We Started With)\n",
    "\n",
    "### Architecture:\n",
    "- **Input**: Correlation matrix (392Ã—392) derived from fMRI timeseries\n",
    "- **Graph Construction**: k-NN (k=20) based on correlation magnitude\n",
    "- **Node Features**: Correlation vectors (each ROI's correlations to all other ROIs)\n",
    "- **Edge Features**: Scalar correlation values\n",
    "- **Network**: 3-layer GAT with multi-head attention (4 heads)\n",
    "- **Pooling**: Global mean + max pooling\n",
    "- **Output**: MLP classifier (2 classes: Control vs ASD)\n",
    "\n",
    "### Limitations:\n",
    "1. **Temporal Information Loss**: 196 timepoints collapsed into static correlation matrix\n",
    "2. **Weak Edge Features**: Only using correlation magnitude (scalar)\n",
    "3. **Fixed Graph Structure**: k-NN graph doesn't adapt during training\n",
    "4. **No Multi-Scale Modeling**: Single receptive field for all attention heads\n",
    "5. **Limited Interpretability**: No mechanism to identify important ROIs or timepoints\n",
    "\n",
    "### Performance (351 subjects subset):\n",
    "- Accuracy: ~52% (barely better than random)\n",
    "- ASD Recall: ~16% (fails to detect ASD)\n",
    "- **Problem**: Heavy bias toward majority class (Control)\n",
    "\n",
    "---\n",
    "\n",
    "## Evolution: What We're Adding\n",
    "\n",
    "### 1. **Temporal-Spatial Joint Modeling**\n",
    "**Motivation**: fMRI data has rich temporal dynamics (196 timepoints) that we're currently discarding.\n",
    "\n",
    "**Implementation**:\n",
    "- **Temporal Branch**: 1D Conv + Temporal Attention on raw timeseries\n",
    "  - Learns dynamic patterns (e.g., periodic activations, bursts)\n",
    "  - Captures temporal dependencies between timepoints\n",
    "  - **NEW v2.0**: Uses Mean + Variance pooling to capture signal volatility\n",
    "- **Spatial Branch**: GAT on correlation graph (as before)\n",
    "  - Learns which ROI connections are important\n",
    "- **Fusion**: Concatenate temporal + spatial features before classification\n",
    "  - **NEW v2.0**: LayerNorm + Learnable scaling for balanced fusion\n",
    "\n",
    "**Expected Gain**: +5-10% accuracy by exploiting temporal information\n",
    "\n",
    "### 2. **Rich Edge Features**\n",
    "**Motivation**: Brain connections have multiple properties beyond correlation.\n",
    "\n",
    "**Implementation**:\n",
    "Replace scalar edge weights with 4D edge features:\n",
    "- **Pearson Correlation**: Linear relationship strength\n",
    "- **Partial Correlation**: Direct connection (removing confounds)\n",
    "- **Mutual Information**: Non-linear dependencies\n",
    "- **Phase Synchrony**: Temporal alignment of signals (optional in v2.0)\n",
    "\n",
    "**Expected Gain**: +3-5% accuracy by capturing diverse connectivity patterns\n",
    "\n",
    "### 3. **Multi-Scale Graph Construction**\n",
    "**Motivation**: Brain operates at multiple spatial scales (local circuits â†’ networks â†’ whole-brain).\n",
    "\n",
    "**Implementation**:\n",
    "- Build 3 graphs with different connectivity radii:\n",
    "  - **Local** (k=10): Short-range connections within regions\n",
    "  - **Regional** (k=30): Medium-range connections between nearby areas\n",
    "  - **Global** (k=100): Long-range connections (e.g., DMN)\n",
    "- Run separate GATs on each scale\n",
    "- Concatenate multi-scale features\n",
    "\n",
    "**Expected Gain**: +4-7% accuracy by capturing hierarchical organization\n",
    "\n",
    "### 4. **Full Dataset Utilization**\n",
    "- Using **all available subjects** from ABIDE (not just 351)\n",
    "- Expected ~800-1000 subjects after quality control\n",
    "- More data = better generalization\n",
    "\n",
    "---\n",
    "\n",
    "## Architecture Diagram\n",
    "\n",
    "```\n",
    "Input: fMRI Timeseries (N=392 ROIs, T=196 timepoints)\n",
    "         |\n",
    "         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "         â†“                 â†“                  â†“\n",
    "   TEMPORAL BRANCH   SPATIAL BRANCH   EDGE FEATURES\n",
    "         |                 |                  |\n",
    "   1D Conv (Tâ†’64)    Correlation Matrix   Pearson Corr\n",
    "         |                 |              Partial Corr\n",
    "   Temporal Attn     k-NN Graph (3 scales)  Mutual Info\n",
    "         |                 |              Phase Sync*\n",
    "   Mean+Var Pool     Multi-Scale GAT        |\n",
    "   (NEW: volatility)       |                  |\n",
    "         |                 |                  |\n",
    "   LayerNorm         LayerNorm              |\n",
    "   Î±-scaling         Î²-scaling              |\n",
    "         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "                           â†“\n",
    "                   Concatenate Features\n",
    "                           â†“\n",
    "                      MLP Classifier\n",
    "                           â†“\n",
    "                  [Control / ASD]\n",
    "\n",
    "* Phase Sync can be excluded for ablation (--exclude_phase_sync)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Expected Performance\n",
    "\n",
    "- **Baseline BrainGAT** (351 subjects): 52% accuracy, 16% ASD recall\n",
    "- **Target (Evolution v2.0)**: 70-75% accuracy, 60-70% ASD recall\n",
    "- This would be competitive with state-of-the-art on ABIDE (BrainGNN: 71-74%)\n",
    "\n",
    "---\n",
    "\n",
    "## Novelty Contributions\n",
    "\n",
    "1. **Joint Temporal-Spatial Modeling**: First to combine 1D temporal convolutions with graph attention for fMRI\n",
    "2. **Dynamic Variance Pooling**: Captures signal volatility critical for ASD biomarkers\n",
    "3. **Balanced Branch Fusion**: LayerNorm + learnable scaling prevents branch dominance\n",
    "4. **Multi-Modal Edge Features**: Using 4 complementary connectivity measures simultaneously\n",
    "5. **Multi-Scale Hierarchical GAT**: Explicitly modeling brain's hierarchical organization\n",
    "6. **Imaging-Only**: Pure neuroimaging approach (no demographic confounds)\n",
    "\n",
    "---\n",
    "\n",
    "Let's implement it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3af9ab6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Jan 22 11:46:41 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 570.172.08             Driver Version: 570.172.08     CUDA Version: 12.8     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   38C    P0             30W /  250W |     795MiB /  16384MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "\n",
      "PyTorch version: 2.8.0+cu126\n",
      "CUDA available: True\n",
      "CUDA version: 12.6\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edc63a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "   GPU: Tesla P100-PCIE-16GB\n",
      "   Memory: 17.06 GB\n"
     ]
    }
   ],
   "source": [
    "# Imports & Setup\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import importlib\n",
    "import torch\n",
    "\n",
    "def install_dependencies():\n",
    "    print(\"Installing torch-geometric and dependencies...\")\n",
    "    torch_ver = torch.__version__.split('+')[0]\n",
    "    cuda_ver = \"cpu\"\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        cuda_ver = \"cu\" + torch.version.cuda.replace('.', '')\n",
    "    \n",
    "    wheel_url = f\"https://data.pyg.org/whl/torch-{torch_ver}+{cuda_ver}.html\"\n",
    "    print(f\"   Targeting wheels from: {wheel_url}\")\n",
    "\n",
    "    pkgs = [\"torch-scatter\", \"torch-sparse\", \"torch-geometric\"]\n",
    "    cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"-q\"] + pkgs + [\"-f\", wheel_url]\n",
    "    \n",
    "    try:\n",
    "        subprocess.check_call(cmd)\n",
    "        print(\"Dependencies installed.\")\n",
    "    except subprocess.CalledProcessError:\n",
    "        print(\"Warning: Wheel installation failed, falling back to default pip install...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\"] + pkgs)\n",
    "\n",
    "    importlib.invalidate_caches()\n",
    "\n",
    "try:\n",
    "    import torch_geometric\n",
    "except ImportError:\n",
    "    install_dependencies()\n",
    "\n",
    "import torch_geometric\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, global_mean_pool, global_max_pool\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader as PyGDataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    gpu_name = torch.cuda.get_device_name(0)\n",
    "    print(f\"   GPU: {gpu_name}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86a60be7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced data loading functions defined\n"
     ]
    }
   ],
   "source": [
    "# Enhanced Data Loading with Temporal Features & Rich Edge Features\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "from pathlib import Path\n",
    "\n",
    "def load_timeseries_1d(path: str) -> np.ndarray:\n",
    "    \"\"\"Load .1D file as TÃ—N array (196 timepoints Ã— 392 ROIs)\"\"\"\n",
    "    arr = np.loadtxt(path)\n",
    "    \n",
    "    # Ensure correct orientation: TÃ—N (196Ã—392)\n",
    "    # Some files may be stored as NÃ—T, so transpose if needed\n",
    "    if arr.shape[0] == 392 and arr.shape[1] == 196:\n",
    "        arr = arr.T\n",
    "    elif arr.shape[0] != 196 or arr.shape[1] != 392:\n",
    "        # Skip files with unexpected dimensions\n",
    "        raise ValueError(f\"Unexpected dimensions: {arr.shape}. Expected (196, 392) or (392, 196)\")\n",
    "    \n",
    "    return arr\n",
    "\n",
    "def compute_partial_correlation(ts: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Compute partial correlation matrix (removes indirect effects)\"\"\"\n",
    "    corr = np.corrcoef(ts, rowvar=False)\n",
    "    try:\n",
    "        # Add small regularization to ensure positive definiteness\n",
    "        corr_reg = corr + np.eye(corr.shape[0]) * 1e-6\n",
    "        \n",
    "        # Partial correlation = negative normalized inverse covariance\n",
    "        precision = np.linalg.inv(corr_reg)\n",
    "        \n",
    "        # Take absolute value of diagonal before sqrt to avoid negatives\n",
    "        diag_vals = np.diag(precision)\n",
    "        diag = np.sqrt(np.abs(diag_vals))\n",
    "        \n",
    "        # Avoid division by zero\n",
    "        diag = np.where(diag < 1e-10, 1e-10, diag)\n",
    "        \n",
    "        partial = -precision / np.outer(diag, diag)\n",
    "        np.fill_diagonal(partial, 1.0)\n",
    "        \n",
    "        # Clip to valid correlation range and handle NaNs\n",
    "        partial = np.clip(partial, -1.0, 1.0)\n",
    "        partial = np.nan_to_num(partial, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        \n",
    "        return partial\n",
    "    except np.linalg.LinAlgError:\n",
    "        return np.zeros_like(corr)\n",
    "\n",
    "def compute_mutual_information(ts: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Compute mutual information matrix (captures non-linear dependencies)\"\"\"\n",
    "    from scipy.stats import spearmanr\n",
    "    import warnings\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings('ignore')\n",
    "        mi_matrix, _ = spearmanr(ts, axis=0)\n",
    "    \n",
    "    mi_matrix = np.abs(mi_matrix)\n",
    "    mi_matrix = np.nan_to_num(mi_matrix, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    \n",
    "    max_val = np.max(mi_matrix)\n",
    "    if max_val > 1e-8:\n",
    "        mi_matrix = mi_matrix / max_val\n",
    "    \n",
    "    return mi_matrix\n",
    "\n",
    "def compute_phase_synchrony(ts: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Compute phase synchronization via Hilbert transform (vectorized)\"\"\"\n",
    "    from scipy.signal import hilbert\n",
    "    \n",
    "    N = ts.shape[1]\n",
    "    analytic = hilbert(ts, axis=0)\n",
    "    phases = np.angle(analytic)\n",
    "    \n",
    "    phase_diff = phases[:, :, np.newaxis] - phases[:, np.newaxis, :]\n",
    "    plv = np.abs(np.mean(np.exp(1j * phase_diff), axis=0))\n",
    "    \n",
    "    return plv\n",
    "\n",
    "def build_multiscale_graphs(ts: np.ndarray, k_values=[10, 30, 100]):\n",
    "    \"\"\"Build multiple graphs at different connectivity scales\"\"\"\n",
    "    import warnings\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "        \n",
    "        corr = np.corrcoef(ts, rowvar=False)\n",
    "        corr = np.nan_to_num(corr, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "        corr = np.clip(corr, -1.0, 1.0)\n",
    "        \n",
    "        partial = compute_partial_correlation(ts)\n",
    "        \n",
    "        ts_downsampled = ts[::4, :]\n",
    "        mi = compute_mutual_information(ts_downsampled)\n",
    "        plv = compute_phase_synchrony(ts_downsampled)\n",
    "    \n",
    "    N = corr.shape[0]\n",
    "    graphs = []\n",
    "    \n",
    "    for k in k_values:\n",
    "        np.fill_diagonal(corr, 0.0)\n",
    "        absC = np.abs(corr)\n",
    "        k_eff = min(k, max(1, N - 1))\n",
    "        \n",
    "        edge_src, edge_dst, edge_feats = [], [], []\n",
    "        \n",
    "        for i in range(N):\n",
    "            nbrs = np.argpartition(absC[i], -k_eff)[-k_eff:]\n",
    "            for j in nbrs:\n",
    "                if i != j:\n",
    "                    edge_src.append(i)\n",
    "                    edge_dst.append(j)\n",
    "                    edge_feats.append([corr[i, j], partial[i, j], mi[i, j], plv[i, j]])\n",
    "        \n",
    "        edge_index = np.vstack([edge_src + edge_dst, edge_dst + edge_src])\n",
    "        edge_attr = np.vstack([edge_feats, edge_feats])\n",
    "        \n",
    "        pairs = {}\n",
    "        for idx, (s, d) in enumerate(edge_index.T):\n",
    "            key = (min(s, d), max(s, d))\n",
    "            if key not in pairs:\n",
    "                pairs[key] = edge_attr[idx]\n",
    "        \n",
    "        final_edges = list(pairs.keys())\n",
    "        final_src = [e[0] for e in final_edges]\n",
    "        final_dst = [e[1] for e in final_edges]\n",
    "        final_attr = np.array([pairs[e] for e in final_edges])\n",
    "        \n",
    "        final_src_bi = final_src + final_dst\n",
    "        final_dst_bi = final_dst + final_src\n",
    "        final_attr_bi = np.vstack([final_attr, final_attr])\n",
    "        \n",
    "        edge_index_tensor = torch.tensor([final_src_bi, final_dst_bi], dtype=torch.long)\n",
    "        edge_attr_tensor = torch.tensor(final_attr_bi, dtype=torch.float)\n",
    "        \n",
    "        graphs.append((edge_index_tensor, edge_attr_tensor))\n",
    "    \n",
    "    return graphs, corr\n",
    "\n",
    "def graph_from_timeseries_enhanced(timeseries: np.ndarray, k_values=[10, 30, 100]):\n",
    "    \"\"\"Build enhanced graph with temporal features + multi-scale spatial graphs\"\"\"\n",
    "    ts_tensor = torch.tensor(timeseries.T, dtype=torch.float)\n",
    "    graphs, corr = build_multiscale_graphs(timeseries, k_values)\n",
    "    x = torch.tensor(corr, dtype=torch.float)\n",
    "    \n",
    "    data = Data(\n",
    "        x=x,\n",
    "        timeseries=ts_tensor,\n",
    "    )\n",
    "    \n",
    "    for i, (edge_idx, edge_attr) in enumerate(graphs):\n",
    "        setattr(data, f'edge_index_{i}', edge_idx)\n",
    "        setattr(data, f'edge_attr_{i}', edge_attr)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def load_abide_graphs_enhanced(data_dir, phenotype_file, k_values=[10, 30, 100]):\n",
    "    \"\"\"Load ABIDE with enhanced features\"\"\"\n",
    "    pheno_df = pd.read_csv(phenotype_file)\n",
    "    roi_files = sorted(glob(f'{data_dir}/*.1D'))\n",
    "    \n",
    "    print(f\"Loading ABIDE data (Enhanced Mode)...\")\n",
    "    print(f\"   Multi-scale k values: {k_values}\")\n",
    "    print(f\"   Edge features: [Correlation, Partial Corr, MI, Phase Sync]\")\n",
    "    \n",
    "    graphs, labels, subjects = [], [], []\n",
    "    \n",
    "    site_map = {\n",
    "        'MaxMun': 'MAX_MUN', 'Leuven_1': 'LEUVEN_1', 'Leuven_2': 'LEUVEN_2',\n",
    "        'UCLA_1': 'UCLA_1', 'UCLA_2': 'UCLA_2', 'UM_1': 'UM_1', 'UM_2': 'UM_2',\n",
    "        'Trinity': 'TRINITY', 'Yale': 'YALE', 'Olin': 'OLIN', 'OHSU': 'OHSU',\n",
    "        'SBL': 'SBL', 'SDSU': 'SDSU', 'Stanford': 'STANFORD', 'Caltech': 'CALTECH',\n",
    "        'CMU': 'CMU', 'KKI': 'KKI', 'NYU': 'NYU', 'Pitt': 'PITT', 'USM': 'USM'\n",
    "    }\n",
    "    \n",
    "    for idx, file_path in enumerate(roi_files):\n",
    "        if idx % 50 == 0:\n",
    "            print(f\"   Processing subject {idx+1}/{len(roi_files)}...\")\n",
    "        \n",
    "        try:\n",
    "            filename = Path(file_path).stem\n",
    "            parts = filename.replace('_rois_cc400', '').split('_')\n",
    "            \n",
    "            if len(parts) < 2:\n",
    "                continue\n",
    "            \n",
    "            site = parts[0]\n",
    "            subject_id_idx = 1\n",
    "            \n",
    "            if len(parts) > 2 and parts[1].isdigit() and len(parts[1]) == 1:\n",
    "                site = f\"{parts[0]}_{parts[1]}\"\n",
    "                subject_id_idx = 2\n",
    "            \n",
    "            if site in site_map:\n",
    "                site = site_map[site]\n",
    "            elif site.upper() in site_map.values():\n",
    "                site = site.upper()\n",
    "            \n",
    "            subject_id = None\n",
    "            for part in parts[subject_id_idx:]:\n",
    "                try:\n",
    "                    subject_id = int(part)\n",
    "                    break\n",
    "                except ValueError:\n",
    "                    continue\n",
    "            \n",
    "            if subject_id is None:\n",
    "                continue\n",
    "            \n",
    "            subject_row = pheno_df[\n",
    "                (pheno_df['SITE_ID'] == site) & \n",
    "                (pheno_df['SUB_ID'] == subject_id)\n",
    "            ]\n",
    "            \n",
    "            if not subject_row.empty:\n",
    "                dx_group = subject_row['DX_GROUP'].values[0]\n",
    "                \n",
    "                if dx_group in [1, 2]:\n",
    "                    try:\n",
    "                        ts = load_timeseries_1d(file_path)\n",
    "                    except (ValueError, Exception) as e:\n",
    "                        # Skip files with wrong dimensions or loading errors\n",
    "                        continue\n",
    "                    \n",
    "                    # Quality check: verify final shape is (196, 392)\n",
    "                    if ts.shape != (196, 392):\n",
    "                        continue\n",
    "                    \n",
    "                    # Quality check: no NaN/Inf values\n",
    "                    if np.any(np.isnan(ts)) or np.any(np.isinf(ts)):\n",
    "                        continue\n",
    "                    \n",
    "                    # Quality check: no constant columns (zero variance)\n",
    "                    col_std = np.std(ts, axis=0)\n",
    "                    if np.any(col_std < 1e-10):\n",
    "                        continue\n",
    "                    \n",
    "                    graph = graph_from_timeseries_enhanced(ts, k_values=k_values)\n",
    "                    graph.y = torch.tensor([dx_group - 1], dtype=torch.long)\n",
    "                    \n",
    "                    graphs.append(graph)\n",
    "                    labels.append(dx_group - 1)\n",
    "                    subjects.append(f\"{site}_{subject_id}\")\n",
    "        except Exception as e:\n",
    "            print(f\"   Error processing {file_path}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\nLoaded {len(graphs)} subjects\")\n",
    "    print(f\"   ASD: {labels.count(1)} | Control: {labels.count(0)}\")\n",
    "    \n",
    "    return graphs, labels, subjects\n",
    "\n",
    "print(\"Enhanced data loading functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f0ca20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ Installing PyG for PyTorch 2.8.0 + CUDA 126\n",
      "   Using pre-built wheels to avoid slow compilation...\n",
      "âœ… Dependencies installed.\n"
     ]
    }
   ],
   "source": [
    "# Install Dependencies (Optimized for Pre-built Wheels)\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "# Get PyTorch and CUDA versions\n",
    "torch_ver = torch.__version__.split('+')[0]\n",
    "cuda_ver = torch.version.cuda.replace('.', '') if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(f\"ðŸ”§ Installing PyG for PyTorch {torch_ver} + CUDA {cuda_ver}\")\n",
    "print(f\"   Using pre-built wheels to avoid slow compilation...\")\n",
    "\n",
    "# Install with correct wheel index\n",
    "wheel_url = f\"https://data.pyg.org/whl/torch-{torch_ver}+cu{cuda_ver}.html\"\n",
    "!pip install -q torch-geometric torch-scatter torch-sparse -f {wheel_url}\n",
    "\n",
    "print(\"âœ… Dependencies installed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5138ae50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Downloading Phenotype Data...\n",
      "âœ… Phenotype data ready.\n",
      "\n",
      "ðŸš€ Downloading rois_cc400 files from S3 (Parallel)...\n",
      "   Target: 1035 files\n",
      "   Starting download pool (max_workers=8)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1035/1035 [00:00<00:00, 41600.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Download Complete!\n",
      "   Success: 1035\n",
      "   Errors:  0\n",
      "   Data directory: abide_data/Outputs/cpac/nofilt_noglobal/rois_cc400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Download ABIDE Data (Reuse from BrainGAT)\n",
    "import os\n",
    "import urllib.request as request\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Config\n",
    "OUT_DIR = 'abide_data/Outputs/cpac/nofilt_noglobal/rois_cc400'\n",
    "PIPELINE = 'cpac'\n",
    "STRATEGY = 'nofilt_noglobal'\n",
    "DERIVATIVE = 'rois_cc400'\n",
    "EXTENSION = '.1D'\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# 1. Download Phenotype File\n",
    "print(\"ðŸš€ Downloading Phenotype Data...\")\n",
    "pheno_url = 'https://s3.amazonaws.com/fcp-indi/data/Projects/ABIDE_Initiative/Phenotypic_V1_0b_preprocessed1.csv'\n",
    "pheno_file = 'Phenotypic_V1_0b_preprocessed1.csv'\n",
    "if not os.path.exists(pheno_file):\n",
    "    request.urlretrieve(pheno_url, pheno_file)\n",
    "print(\"âœ… Phenotype data ready.\")\n",
    "\n",
    "# 2. Download .1D Files in Parallel\n",
    "print(f\"\\nðŸš€ Downloading {DERIVATIVE} files from S3 (Parallel)...\")\n",
    "\n",
    "df = pd.read_csv(pheno_file)\n",
    "file_ids = df['FILE_ID'].tolist()\n",
    "file_ids = [f for f in file_ids if f != 'no_filename']\n",
    "\n",
    "base_url = f'https://s3.amazonaws.com/fcp-indi/data/Projects/ABIDE_Initiative/Outputs/{PIPELINE}/{STRATEGY}/{DERIVATIVE}'\n",
    "\n",
    "def download_file(file_id):\n",
    "    filename = f\"{file_id}_{DERIVATIVE}{EXTENSION}\"\n",
    "    url = f\"{base_url}/{filename}\"\n",
    "    out_path = os.path.join(OUT_DIR, filename)\n",
    "    \n",
    "    if os.path.exists(out_path):\n",
    "        return \"Exists\"\n",
    "        \n",
    "    try:\n",
    "        request.urlretrieve(url, out_path)\n",
    "        return \"Downloaded\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n",
    "\n",
    "print(f\"   Target: {len(file_ids)} files\")\n",
    "print(\"   Starting download pool (max_workers=8)...\")\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=8) as executor:\n",
    "    results = list(tqdm(executor.map(download_file, file_ids), total=len(file_ids)))\n",
    "\n",
    "success = results.count(\"Downloaded\") + results.count(\"Exists\")\n",
    "errors = len(results) - success\n",
    "\n",
    "print(f\"\\nâœ… Download Complete!\")\n",
    "print(f\"   Success: {success}\")\n",
    "print(f\"   Errors:  {errors}\")\n",
    "print(f\"   Data directory: {OUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3d2c530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading functions defined (v2.0: stride=20 for 75% overlap)\n",
      "   Phase Sync Ablation: included in edges\n"
     ]
    }
   ],
   "source": [
    "# Enhanced Data Loading with Sliding Temporal Windows (v2.0: stride=20 for 75% overlap)\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# === v2.0: ABLATION CONFIGURATION ===\n",
    "# Set to True to exclude phase synchrony from spatial edge features\n",
    "# This forces the temporal branch to learn temporal dynamics independently\n",
    "EXCLUDE_PHASE_SYNC_FROM_EDGES = False  # Toggle for ablation study\n",
    "\n",
    "def load_timeseries_1d(path: str) -> np.ndarray:\n",
    "    \"\"\"Load .1D file as T x N array\"\"\"\n",
    "    arr = np.loadtxt(path)\n",
    "    if arr.shape[1] == 392:\n",
    "        pass\n",
    "    elif arr.shape[0] == 392:\n",
    "        arr = arr.T\n",
    "    else:\n",
    "        raise ValueError(f\"Expected 392 ROIs, got shape {arr.shape}\")\n",
    "    return arr\n",
    "\n",
    "def extract_temporal_windows(timeseries: np.ndarray, window_length: int = 80, stride: int = 20):\n",
    "    \"\"\"\n",
    "    Extract sliding windows from timeseries\n",
    "    \n",
    "    v2.0 Change: Default stride changed from 40 to 20 (75% overlap instead of 50%)\n",
    "    More windows per subject = more examples of brain state transitions\n",
    "    \"\"\"\n",
    "    T, N = timeseries.shape\n",
    "    if T < window_length:\n",
    "        return []\n",
    "    windows = []\n",
    "    for start in range(0, T - window_length + 1, stride):\n",
    "        end = start + window_length\n",
    "        windows.append(timeseries[start:end, :])\n",
    "    return windows\n",
    "\n",
    "def compute_partial_correlation(ts: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Compute partial correlation matrix\"\"\"\n",
    "    corr = np.corrcoef(ts, rowvar=False)\n",
    "    try:\n",
    "        corr_reg = corr + np.eye(corr.shape[0]) * 1e-6\n",
    "        precision = np.linalg.inv(corr_reg)\n",
    "        diag = np.sqrt(np.abs(np.diag(precision)))\n",
    "        diag = np.where(diag < 1e-10, 1e-10, diag)\n",
    "        partial = -precision / np.outer(diag, diag)\n",
    "        np.fill_diagonal(partial, 1.0)\n",
    "        partial = np.clip(partial, -1.0, 1.0)\n",
    "        partial = np.nan_to_num(partial, nan=0.0)\n",
    "        return partial\n",
    "    except np.linalg.LinAlgError:\n",
    "        return np.zeros_like(corr)\n",
    "\n",
    "def compute_mutual_information(ts: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Compute MI matrix via Spearman correlation\"\"\"\n",
    "    from scipy.stats import spearmanr\n",
    "    import warnings\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings('ignore')\n",
    "        mi_matrix, _ = spearmanr(ts, axis=0)\n",
    "    mi_matrix = np.abs(mi_matrix)\n",
    "    mi_matrix = np.nan_to_num(mi_matrix, nan=0.0)\n",
    "    max_val = np.max(mi_matrix)\n",
    "    if max_val > 1e-8:\n",
    "        mi_matrix = mi_matrix / max_val\n",
    "    return mi_matrix\n",
    "\n",
    "def compute_phase_synchrony(ts: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Compute phase synchronization via Hilbert transform\"\"\"\n",
    "    from scipy.signal import hilbert\n",
    "    analytic = hilbert(ts, axis=0)\n",
    "    phases = np.angle(analytic)\n",
    "    phase_diff = phases[:, :, np.newaxis] - phases[:, np.newaxis, :]\n",
    "    plv = np.abs(np.mean(np.exp(1j * phase_diff), axis=0))\n",
    "    return plv\n",
    "\n",
    "def build_multiscale_graphs(ts: np.ndarray, k_values=[10, 30, 100], exclude_phase_sync=False):\n",
    "    \"\"\"\n",
    "    Build multiple graphs at different scales\n",
    "    \n",
    "    v2.0 Change: Added exclude_phase_sync parameter for ablation study\n",
    "    When True, phase synchrony is replaced with zeros in edge features,\n",
    "    forcing the model to rely on temporal branch for temporal dynamics.\n",
    "    \n",
    "    Edge features: [Pearson, Partial, MI, Phase Sync (or 0 if excluded)]\n",
    "    \"\"\"\n",
    "    import warnings\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "        corr = np.corrcoef(ts, rowvar=False)\n",
    "        corr = np.nan_to_num(corr, nan=0.0)\n",
    "        corr = np.clip(corr, -1.0, 1.0)\n",
    "        partial = compute_partial_correlation(ts)\n",
    "        ts_down = ts[::4, :]\n",
    "        mi = compute_mutual_information(ts_down)\n",
    "        \n",
    "        # v2.0: Optionally exclude phase synchrony from spatial edges\n",
    "        if exclude_phase_sync:\n",
    "            # Replace with zeros - forces temporal branch to handle temporal dynamics\n",
    "            plv = np.zeros_like(corr)\n",
    "        else:\n",
    "            plv = compute_phase_synchrony(ts_down)\n",
    "    \n",
    "    N = corr.shape[0]\n",
    "    graphs = []\n",
    "    \n",
    "    for k in k_values:\n",
    "        np.fill_diagonal(corr, 0.0)\n",
    "        absC = np.abs(corr)\n",
    "        k_eff = min(k, max(1, N - 1))\n",
    "        edge_src, edge_dst, edge_feats = [], [], []\n",
    "        \n",
    "        for i in range(N):\n",
    "            nbrs = np.argpartition(absC[i], -k_eff)[-k_eff:]\n",
    "            for j in nbrs:\n",
    "                if i != j:\n",
    "                    edge_src.append(i)\n",
    "                    edge_dst.append(j)\n",
    "                    edge_feats.append([corr[i, j], partial[i, j], mi[i, j], plv[i, j]])\n",
    "        \n",
    "        # Make bidirectional and deduplicate\n",
    "        pairs = {}\n",
    "        for idx in range(len(edge_src)):\n",
    "            s, d = edge_src[idx], edge_dst[idx]\n",
    "            key = (min(s, d), max(s, d))\n",
    "            if key not in pairs:\n",
    "                pairs[key] = edge_feats[idx]\n",
    "        \n",
    "        final_edges = list(pairs.keys())\n",
    "        final_src = [e[0] for e in final_edges] + [e[1] for e in final_edges]\n",
    "        final_dst = [e[1] for e in final_edges] + [e[0] for e in final_edges]\n",
    "        final_attr = [pairs[e] for e in final_edges] * 2\n",
    "        \n",
    "        edge_index = torch.tensor([final_src, final_dst], dtype=torch.long)\n",
    "        edge_attr = torch.tensor(final_attr, dtype=torch.float)\n",
    "        graphs.append((edge_index, edge_attr))\n",
    "    \n",
    "    return graphs, corr\n",
    "\n",
    "def graph_from_timeseries_enhanced(timeseries: np.ndarray, k_values=[10, 30, 100], exclude_phase_sync=None):\n",
    "    \"\"\"\n",
    "    Build PyG Data object from timeseries window\n",
    "    \n",
    "    v2.0 Change: Added exclude_phase_sync parameter (defaults to global EXCLUDE_PHASE_SYNC_FROM_EDGES)\n",
    "    \"\"\"\n",
    "    if exclude_phase_sync is None:\n",
    "        exclude_phase_sync = EXCLUDE_PHASE_SYNC_FROM_EDGES\n",
    "    \n",
    "    ts_tensor = torch.tensor(timeseries.T, dtype=torch.float)  # (N, T)\n",
    "    graphs, corr = build_multiscale_graphs(timeseries, k_values, exclude_phase_sync=exclude_phase_sync)\n",
    "    x = torch.tensor(corr, dtype=torch.float)\n",
    "    \n",
    "    data = Data(x=x, timeseries=ts_tensor)\n",
    "    for i, (edge_idx, edge_attr) in enumerate(graphs):\n",
    "        setattr(data, f'edge_index_{i}', edge_idx)\n",
    "        setattr(data, f'edge_attr_{i}', edge_attr)\n",
    "    return data\n",
    "\n",
    "print(\"Data loading functions defined (v2.0: stride=20 for 75% overlap)\")\n",
    "print(f\"   Phase Sync Ablation: {'EXCLUDED from edges' if EXCLUDE_PHASE_SYNC_FROM_EDGES else 'included in edges'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e1b6686c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing 1035 .1D files...\n",
      "\n",
      "Sample file dimensions (first 10):\n",
      "  CMU_a_0050642_rois_cc400.1D: (236, 392)\n",
      "  CMU_a_0050646_rois_cc400.1D: (236, 392)\n",
      "  CMU_a_0050647_rois_cc400.1D: (202, 392)\n",
      "  CMU_a_0050649_rois_cc400.1D: (236, 392)\n",
      "  CMU_a_0050653_rois_cc400.1D: (236, 392)\n",
      "  CMU_a_0050654_rois_cc400.1D: (236, 392)\n",
      "  CMU_a_0050656_rois_cc400.1D: (236, 392)\n",
      "  CMU_a_0050659_rois_cc400.1D: (236, 392)\n",
      "  CMU_a_0050660_rois_cc400.1D: (236, 392)\n",
      "  CMU_a_0050663_rois_cc400.1D: (236, 392)\n",
      "\n",
      "Shape Distribution (all 1035 files):\n",
      "  176 Ã— 392:  227 files ( 21.9%)\n",
      "  196 Ã— 392:  158 files ( 15.3%)\n",
      "  296 Ã— 392:  140 files ( 13.5%)\n",
      "  116 Ã— 392:  134 files ( 12.9%)\n",
      "  236 Ã— 392:  103 files ( 10.0%)\n",
      "  146 Ã— 392:   84 files (  8.1%)\n",
      "  246 Ã— 392:   63 files (  6.1%)\n",
      "  152 Ã— 392:   42 files (  4.1%)\n",
      "  206 Ã— 392:   34 files (  3.3%)\n",
      "   78 Ã— 392:   26 files (  2.5%)\n",
      "\n",
      "Most common shape: (176, 392)\n",
      "   This will be our target dimension.\n"
     ]
    }
   ],
   "source": [
    "# DIAGNOSTIC: Check actual file dimensions\n",
    "import glob\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "roi_files = sorted(glob.glob('abide_data/Outputs/cpac/nofilt_noglobal/rois_cc400/*.1D'))\n",
    "print(f\"Analyzing {len(roi_files)} .1D files...\\n\")\n",
    "\n",
    "shapes = []\n",
    "for f in roi_files:\n",
    "    try:\n",
    "        arr = np.loadtxt(f)\n",
    "        shapes.append(arr.shape)\n",
    "    except:\n",
    "        shapes.append(None)\n",
    "\n",
    "print(\"Sample file dimensions (first 10):\")\n",
    "for f, s in zip(roi_files[:10], shapes[:10]):\n",
    "    print(f\"  {f.split('/')[-1]}: {s}\")\n",
    "\n",
    "print(f\"\\nShape Distribution (all {len(roi_files)} files):\")\n",
    "shape_counts = Counter(shapes)\n",
    "for shape, count in sorted(shape_counts.items(), key=lambda x: -x[1])[:10]:\n",
    "    if shape:\n",
    "        pct = 100 * count / len(roi_files)\n",
    "        print(f\"  {shape[0]:3d} Ã— {shape[1]:3d}: {count:4d} files ({pct:5.1f}%)\")\n",
    "\n",
    "# Find most common shape\n",
    "most_common_shape = shape_counts.most_common(1)[0][0]\n",
    "print(f\"\\nMost common shape: {most_common_shape}\")\n",
    "print(f\"   This will be our target dimension.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f468a711",
   "metadata": {},
   "source": [
    "## Model Architecture: Temporal-Spatial BrainGAT\n",
    "\n",
    "This model has three main components:\n",
    "\n",
    "1. **Temporal Branch**: Processes raw timeseries with 1D convolutions + temporal attention\n",
    "2. **Spatial Branch**: Multi-scale GAT on correlation graphs (3 scales: local, regional, global)\n",
    "3. **ROI Attention Pooling**: Learns which brain regions are important for classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e9b3b3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal branch defined (v2.0: Mean + Variance Pooling)\n"
     ]
    }
   ],
   "source": [
    "# Temporal Branch: 1D CNN + Temporal Attention + Mean/Variance Pooling\n",
    "\n",
    "class TemporalAttention(nn.Module):\n",
    "    \"\"\"Attention over time dimension\"\"\"\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.query = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.key = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.value = nn.Linear(hidden_dim, hidden_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: (batch*N, T, hidden)\n",
    "        Q = self.query(x)\n",
    "        K = self.key(x)\n",
    "        V = self.value(x)\n",
    "        \n",
    "        # Scaled dot-product attention\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / np.sqrt(Q.size(-1))\n",
    "        attn_weights = F.softmax(scores, dim=-1)\n",
    "        out = torch.matmul(attn_weights, V)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class TemporalBranch(nn.Module):\n",
    "    \"\"\"\n",
    "    Extract temporal features from fMRI timeseries\n",
    "    \n",
    "    v2.0 Changes:\n",
    "    - Replaced AdaptiveAvgPool1d with Mean + Std pooling (captures volatility)\n",
    "    - Output dimension is now hidden_dim * 2 (mean + std concatenated)\n",
    "    \"\"\"\n",
    "    def __init__(self, input_time_len=80, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # 1D Convolutions over time: (batch*N, 1, T) -> (batch*N, hidden, T)\n",
    "        self.conv1 = nn.Conv1d(1, hidden_dim, kernel_size=7, padding=3)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.conv2 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=5, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        \n",
    "        # Temporal Attention\n",
    "        self.temporal_attn = TemporalAttention(hidden_dim)\n",
    "        \n",
    "        # NOTE: Removed self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "        # Now using mean + std pooling in forward() for dynamic/variance features\n",
    "        \n",
    "    def forward(self, timeseries, batch):\n",
    "        # timeseries: (batch*N, T)\n",
    "        x = timeseries.unsqueeze(1)  # (batch*N, 1, T)\n",
    "        \n",
    "        # Conv layers\n",
    "        x = F.relu(self.bn1(self.conv1(x)))  # (batch*N, hidden, T)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))  # (batch*N, hidden, T)\n",
    "        \n",
    "        # Transpose for attention (batch*N, T, hidden)\n",
    "        x = x.transpose(1, 2)\n",
    "        \n",
    "        # Temporal attention\n",
    "        x = self.temporal_attn(x)  # (batch*N, T, hidden)\n",
    "        \n",
    "        # === v2.0: Mean + Variance Pooling (replaces AdaptiveAvgPool1d) ===\n",
    "        # This captures both average activation AND signal volatility/fluctuations\n",
    "        # ASD biomarkers often appear in the variance/bursting of signals\n",
    "        x = x.transpose(1, 2)  # (batch*N, hidden, T)\n",
    "        \n",
    "        # Mean pooling (average activation level)\n",
    "        mean_pool = x.mean(dim=-1)  # (batch*N, hidden)\n",
    "        \n",
    "        # Std pooling (signal volatility/fluctuations) \n",
    "        # Using std instead of var for better numerical stability\n",
    "        std_pool = x.std(dim=-1)  # (batch*N, hidden)\n",
    "        \n",
    "        # Concatenate mean and std features\n",
    "        temporal_feats = torch.cat([mean_pool, std_pool], dim=-1)  # (batch*N, hidden*2)\n",
    "        \n",
    "        # Pool over nodes to get graph-level features\n",
    "        x_graph = global_mean_pool(temporal_feats, batch)  # (batch, hidden*2)\n",
    "        \n",
    "        return x_graph\n",
    "    \n",
    "    @property\n",
    "    def output_dim(self):\n",
    "        \"\"\"Returns output dimension (hidden_dim * 2 for mean+std)\"\"\"\n",
    "        return self.hidden_dim * 2\n",
    "\n",
    "print(\"Temporal branch defined (v2.0: Mean + Variance Pooling)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf264131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-scale spatial branch defined\n"
     ]
    }
   ],
   "source": [
    "# Spatial Branch: Multi-Scale GAT with Rich Edge Features\n",
    "\n",
    "class MultiHeadGATLayerWithEdgeFeats(nn.Module):\n",
    "    \"\"\"GAT with 4D edge features\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, heads=4, dropout=0.3, concat=True):\n",
    "        super().__init__()\n",
    "        self.gat = GATConv(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            heads=heads,\n",
    "            dropout=dropout,\n",
    "            concat=concat,\n",
    "            edge_dim=4  # 4D edge features [corr, partial, MI, phase]\n",
    "        )\n",
    "        self.bn = nn.BatchNorm1d(out_channels * heads if concat else out_channels)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        x = self.gat(x, edge_index, edge_attr=edge_attr)\n",
    "        x = self.bn(x)\n",
    "        x = F.elu(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class MultiScaleSpatialBranch(nn.Module):\n",
    "    \"\"\"Multi-scale GAT (local, regional, global)\"\"\"\n",
    "    def __init__(self, in_channels, hidden_dim=32, num_scales=3, heads=4, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.num_scales = num_scales\n",
    "        \n",
    "        # Separate GAT for each scale\n",
    "        self.gats = nn.ModuleList([\n",
    "            nn.ModuleList([\n",
    "                MultiHeadGATLayerWithEdgeFeats(in_channels, hidden_dim, heads, dropout, concat=True),\n",
    "                MultiHeadGATLayerWithEdgeFeats(hidden_dim * heads, hidden_dim, heads, dropout, concat=False)\n",
    "            ]) for _ in range(num_scales)\n",
    "        ])\n",
    "        \n",
    "    def forward(self, x, edge_indices, edge_attrs, batch):\n",
    "        scale_features = []\n",
    "        \n",
    "        for i in range(self.num_scales):\n",
    "            h = x\n",
    "            for gat_layer in self.gats[i]:\n",
    "                h = gat_layer(h, edge_indices[i], edge_attrs[i])\n",
    "            \n",
    "            # Pool to graph level\n",
    "            h_mean = global_mean_pool(h, batch)\n",
    "            h_max = global_max_pool(h, batch)\n",
    "            h_graph = torch.cat([h_mean, h_max], dim=-1)\n",
    "            \n",
    "            scale_features.append(h_graph)\n",
    "        \n",
    "        # Concatenate multi-scale features\n",
    "        out = torch.cat(scale_features, dim=-1)\n",
    "        return out\n",
    "\n",
    "print(\"Multi-scale spatial branch defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "212dcd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal-Spatial BrainGAT defined (v2.0: LayerNorm + Learnable Scaling)\n"
     ]
    }
   ],
   "source": [
    "# Full Model: Temporal-Spatial BrainGAT (v2.0)\n",
    "\n",
    "class TemporalSpatialBrainGAT(nn.Module):\n",
    "    \"\"\"\n",
    "    Temporal-Spatial Graph Attention Network for fMRI\n",
    "    \n",
    "    v2.0 Changes:\n",
    "    - Branch Normalization: LayerNorm on each branch before fusion\n",
    "    - Learnable Branch Scaling: Î± (temporal) and Î² (spatial) scale factors\n",
    "    - Updated temporal_dim to account for mean+std pooling (temporal_dim * 2)\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 in_channels,\n",
    "                 hidden_dim=32,\n",
    "                 temporal_dim=64,\n",
    "                 num_scales=3,\n",
    "                 heads=4,\n",
    "                 dropout=0.5,\n",
    "                 num_classes=2):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_scales = num_scales\n",
    "        \n",
    "        # Temporal Branch (output: temporal_dim * 2 due to mean+std pooling)\n",
    "        self.temporal_branch = TemporalBranch(\n",
    "            input_time_len=80,\n",
    "            hidden_dim=temporal_dim\n",
    "        )\n",
    "        \n",
    "        # Spatial Branch\n",
    "        self.spatial_branch = MultiScaleSpatialBranch(\n",
    "            in_channels=in_channels,\n",
    "            hidden_dim=hidden_dim,\n",
    "            num_scales=num_scales,\n",
    "            heads=heads,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        # === v2.0: Calculate feature dimensions ===\n",
    "        # Temporal: temporal_dim * 2 (mean + std pooling)\n",
    "        temporal_out_dim = temporal_dim * 2\n",
    "        # Spatial: num_scales * hidden_dim * 2 (mean + max pooling per scale)\n",
    "        spatial_out_dim = num_scales * hidden_dim * 2\n",
    "        \n",
    "        # === v2.0: Branch Normalization (LayerNorm) ===\n",
    "        # Puts temporal and spatial features on \"level playing field\"\n",
    "        # Prevents the spatial branch from dominating due to higher signal-to-noise\n",
    "        self.temporal_norm = nn.LayerNorm(temporal_out_dim)\n",
    "        self.spatial_norm = nn.LayerNorm(spatial_out_dim)\n",
    "        \n",
    "        # === v2.0: Learnable Branch Scaling (Î± and Î²) ===\n",
    "        # Combined = (Î± Â· Temporal) âŠ• (Î² Â· Spatial)\n",
    "        # Monitor these during training to diagnose branch importance\n",
    "        self.temporal_scale = nn.Parameter(torch.ones(1))  # Î±\n",
    "        self.spatial_scale = nn.Parameter(torch.ones(1))   # Î²\n",
    "        \n",
    "        # Total dimension for classifier\n",
    "        total_dim = temporal_out_dim + spatial_out_dim\n",
    "        \n",
    "        # Fusion + Classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(total_dim, hidden_dim * 4),\n",
    "            nn.BatchNorm1d(hidden_dim * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(hidden_dim * 4, hidden_dim * 2),\n",
    "            nn.BatchNorm1d(hidden_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(hidden_dim * 2, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, data):\n",
    "        x = data.x\n",
    "        timeseries = data.timeseries\n",
    "        batch = data.batch if hasattr(data, 'batch') else torch.zeros(x.size(0), dtype=torch.long, device=x.device)\n",
    "        \n",
    "        # Extract multi-scale edge indices and attributes\n",
    "        edge_indices = [getattr(data, f'edge_index_{i}') for i in range(self.num_scales)]\n",
    "        edge_attrs = [getattr(data, f'edge_attr_{i}') for i in range(self.num_scales)]\n",
    "        \n",
    "        # Temporal features (now outputs temporal_dim * 2)\n",
    "        temporal_feats = self.temporal_branch(timeseries, batch)\n",
    "        \n",
    "        # Spatial features\n",
    "        spatial_feats = self.spatial_branch(x, edge_indices, edge_attrs, batch)\n",
    "        \n",
    "        # === v2.0: Apply LayerNorm to each branch ===\n",
    "        temporal_feats = self.temporal_norm(temporal_feats)\n",
    "        spatial_feats = self.spatial_norm(spatial_feats)\n",
    "        \n",
    "        # === v2.0: Apply learnable scaling ===\n",
    "        temporal_feats = self.temporal_scale * temporal_feats\n",
    "        spatial_feats = self.spatial_scale * spatial_feats\n",
    "        \n",
    "        # Fuse temporal + spatial\n",
    "        combined = torch.cat([temporal_feats, spatial_feats], dim=-1)\n",
    "        \n",
    "        # Classify\n",
    "        out = self.classifier(combined)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def get_branch_scales(self):\n",
    "        \"\"\"Return current branch scaling factors for monitoring\"\"\"\n",
    "        return {\n",
    "            'temporal_scale (Î±)': self.temporal_scale.item(),\n",
    "            'spatial_scale (Î²)': self.spatial_scale.item()\n",
    "        }\n",
    "\n",
    "print(\"Temporal-Spatial BrainGAT defined (v2.0: LayerNorm + Learnable Scaling)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baf8eed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 1: LOAD FULL TIMESERIES PER SUBJECT (NO WINDOWS YET)\n",
      "============================================================\n",
      "\n",
      "Loading cached subject data...\n",
      "Loaded 886 subjects from cache.\n",
      "   ASD: 459 | Control: 427\n",
      "\n",
      "============================================================\n",
      "STEP 2: SPLIT SUBJECTS (60% train, 20% val, 20% test)\n",
      "============================================================\n",
      "   Train: 531 subjects\n",
      "   Val:   177 subjects\n",
      "   Test:  178 subjects\n",
      "   Saved split indices to subject_splits.json\n",
      "\n",
      "============================================================\n",
      "STEP 3: GENERATE WINDOWS (v2.0: stride=20, 75% overlap)\n",
      "============================================================\n",
      "   Processing 531 TRAIN subjects...\n",
      "      50/531 subjects processed (286 windows so far)...\n",
      "      100/531 subjects processed (563 windows so far)...\n",
      "      150/531 subjects processed (885 windows so far)...\n",
      "      200/531 subjects processed (1173 windows so far)...\n",
      "      250/531 subjects processed (1479 windows so far)...\n",
      "      300/531 subjects processed (1770 windows so far)...\n",
      "      350/531 subjects processed (2050 windows so far)...\n",
      "      400/531 subjects processed (2393 windows so far)...\n",
      "      450/531 subjects processed (2685 windows so far)...\n",
      "      500/531 subjects processed (3017 windows so far)...\n",
      "      TRAIN: 3201 windows from 531 subjects [Done]\n",
      "   Processing 177 VAL subjects...\n",
      "      50/177 subjects processed (365 windows so far)...\n",
      "      100/177 subjects processed (654 windows so far)...\n",
      "      150/177 subjects processed (928 windows so far)...\n",
      "      VAL: 1093 windows from 177 subjects [Done]\n",
      "   Processing 178 TEST subjects...\n",
      "      50/178 subjects processed (298 windows so far)...\n",
      "      100/178 subjects processed (578 windows so far)...\n",
      "      150/178 subjects processed (900 windows so far)...\n",
      "      TEST: 1062 windows from 178 subjects [Done]\n",
      "\n",
      "FINAL WINDOW COUNTS:\n",
      "   Train: 3201 windows from 531 subjects\n",
      "   Val:   1093 windows from 177 subjects\n",
      "   Test:  1062 windows from 178 subjects\n",
      "\n",
      "   Note: v2.0 stride=20 produces ~2x more windows than v1.0 stride=40 (capped per subject here)\n",
      "\n",
      "DataLoaders ready.\n"
     ]
    }
   ],
   "source": [
    "# Subject-Level Data Loading & Splitting (NO DATA LEAKAGE)\n",
    "\"\"\"\n",
    "v2.0 pipeline for subject-level loading and splitting.\n",
    "To keep memory usage reasonable on local machines, we cap the number of\n",
    "subjects and windows per subject used to build graphs.\n",
    "\"\"\"\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "data_dir = 'abide_data/Outputs/cpac/nofilt_noglobal/rois_cc400/'\n",
    "phenotype_file = 'Phenotypic_V1_0b_preprocessed1.csv'\n",
    "\n",
    "# Safety limits for local runs (adjust if you have more memory)\n",
    "MAX_SUBJECTS = 80              # cap total subjects to avoid OOM\n",
    "MAX_WINDOWS_PER_SUBJECT = 10   # cap temporal windows per subject\n",
    "\n",
    "# Download phenotype file if missing\n",
    "if not os.path.exists(phenotype_file):\n",
    "    import urllib.request as request\n",
    "    pheno_url = 'https://s3.amazonaws.com/fcp-indi/data/Projects/ABIDE_Initiative/Phenotypic_V1_0b_preprocessed1.csv'\n",
    "    request.urlretrieve(pheno_url, phenotype_file)\n",
    "    print(\"Downloaded phenotype file\")\n",
    "\n",
    "pheno_df = pd.read_csv(phenotype_file)\n",
    "roi_files = sorted(glob.glob(f'{data_dir}/*.1D'))\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"STEP 1: LOAD FULL TIMESERIES PER SUBJECT (NO WINDOWS YET)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Site mapping\n",
    "site_map = {\n",
    "    'MaxMun': 'MAX_MUN', 'Leuven_1': 'LEUVEN_1', 'Leuven_2': 'LEUVEN_2',\n",
    "    'UCLA_1': 'UCLA_1', 'UCLA_2': 'UCLA_2', 'UM_1': 'UM_1', 'UM_2': 'UM_2',\n",
    "    'Trinity': 'TRINITY', 'Yale': 'YALE', 'Olin': 'OLIN', 'OHSU': 'OHSU',\n",
    "    'SBL': 'SBL', 'SDSU': 'SDSU', 'Stanford': 'STANFORD', 'Caltech': 'CALTECH',\n",
    "    'CMU': 'CMU', 'KKI': 'KKI', 'NYU': 'NYU', 'Pitt': 'PITT', 'USM': 'USM'\n",
    "}\n",
    "\n",
    "CACHE_FILE = 'subject_data_cache.pkl'\n",
    "\n",
    "if os.path.exists(CACHE_FILE):\n",
    "    print(\"\\nLoading cached subject data...\")\n",
    "    with open(CACHE_FILE, 'rb') as f:\n",
    "        subject_data = pickle.load(f)\n",
    "    print(f\"Loaded {len(subject_data)} subjects from cache.\")\n",
    "    asd_count = sum(1 for v in subject_data.values() if v['label'] == 1)\n",
    "    ctrl_count = len(subject_data) - asd_count\n",
    "    print(f\"   ASD: {asd_count} | Control: {ctrl_count}\")\n",
    "else:\n",
    "    # Load raw timeseries per subject (NO windowing yet)\n",
    "    subject_data = {}  # {subject_id: {'timeseries': ts, 'label': label}}\n",
    "\n",
    "    for idx, file_path in enumerate(roi_files):\n",
    "        # Hard cap on subjects to avoid running out of memory\n",
    "        if len(subject_data) >= MAX_SUBJECTS:\n",
    "            print(f\"Reached MAX_SUBJECTS={MAX_SUBJECTS}, stopping subject loading.\")\n",
    "            break\n",
    "\n",
    "        if idx % 100 == 0:\n",
    "            print(f\"   Loading subject {idx+1}/{len(roi_files)}...\")\n",
    "        try:\n",
    "            filename = Path(file_path).stem\n",
    "            parts = filename.replace('_rois_cc400', '').split('_')\n",
    "            if len(parts) < 2:\n",
    "                continue\n",
    "\n",
    "            site = parts[0]\n",
    "            subject_id_idx = 1\n",
    "            if len(parts) > 2 and parts[1].isdigit() and len(parts[1]) == 1:\n",
    "                site = f\"{parts[0]}_{parts[1]}\"\n",
    "                subject_id_idx = 2\n",
    "\n",
    "            if site in site_map:\n",
    "                site = site_map[site]\n",
    "            elif site.upper() in site_map.values():\n",
    "                site = site.upper()\n",
    "\n",
    "            subject_id = None\n",
    "            for part in parts[subject_id_idx:]:\n",
    "                try:\n",
    "                    subject_id = int(part)\n",
    "                    break\n",
    "                except ValueError:\n",
    "                    continue\n",
    "\n",
    "            if subject_id is None:\n",
    "                continue\n",
    "\n",
    "            subject_row = pheno_df[(pheno_df['SITE_ID'] == site) & (pheno_df['SUB_ID'] == subject_id)]\n",
    "            if subject_row.empty:\n",
    "                continue\n",
    "\n",
    "            dx_group = subject_row['DX_GROUP'].values[0]\n",
    "            if dx_group not in [1, 2]:\n",
    "                continue\n",
    "\n",
    "            ts = load_timeseries_1d(file_path)\n",
    "            if np.any(np.isnan(ts)) or np.any(np.isinf(ts)):\n",
    "                continue\n",
    "            if np.any(np.std(ts, axis=0) < 1e-10):\n",
    "                continue\n",
    "            if ts.shape[0] < 80:\n",
    "                continue\n",
    "\n",
    "            subj_key = f\"{site}_{subject_id}\"\n",
    "            subject_data[subj_key] = {\n",
    "                'timeseries': ts,\n",
    "                'label': dx_group - 1,  # 0=Control, 1=ASD\n",
    "            }\n",
    "        except Exception:\n",
    "            # Skip any subject that fails to load/parse\n",
    "            continue\n",
    "\n",
    "    print(f\"\\nLoaded {len(subject_data)} subjects\")\n",
    "    asd_count = sum(1 for v in subject_data.values() if v['label'] == 1)\n",
    "    ctrl_count = len(subject_data) - asd_count\n",
    "    print(f\"   ASD: {asd_count} | Control: {ctrl_count}\")\n",
    "\n",
    "    # Save cache\n",
    "    print(\"\\nSaving subject data to cache...\")\n",
    "    with open(CACHE_FILE, 'wb') as f:\n",
    "        pickle.dump(subject_data, f)\n",
    "    print(f\"Saved to {CACHE_FILE}\")\n",
    "\n",
    "# STEP 2: SPLIT AT SUBJECT LEVEL\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 2: SPLIT SUBJECTS (60% train, 20% val, 20% test)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "subjects = list(subject_data.keys())\n",
    "labels = [subject_data[s]['label'] for s in subjects]\n",
    "\n",
    "train_subjects, temp_subjects, _, temp_labels = train_test_split(\n",
    "    subjects, labels, test_size=0.4, random_state=42, stratify=labels\n",
    ")\n",
    "val_subjects, test_subjects, _, _ = train_test_split(\n",
    "    temp_subjects, temp_labels, test_size=0.5, random_state=42, stratify=temp_labels\n",
    ")\n",
    "\n",
    "print(f\"   Train: {len(train_subjects)} subjects\")\n",
    "print(f\"   Val:   {len(val_subjects)} subjects\")\n",
    "print(f\"   Test:  {len(test_subjects)} subjects\")\n",
    "\n",
    "# Save split indices\n",
    "split_info = {\n",
    "    'train_subjects': train_subjects,\n",
    "    'val_subjects': val_subjects,\n",
    "    'test_subjects': test_subjects,\n",
    "}\n",
    "with open('subject_splits.json', 'w') as f:\n",
    "    json.dump(split_info, f, indent=2)\n",
    "print(\"   Saved split indices to subject_splits.json\")\n",
    "\n",
    "# STEP 3: GENERATE WINDOWS AFTER SPLITTING\n",
    "# === v2.0: Updated stride from 40 to 20 (75% overlap instead of 50%) ===\n",
    "# More windows per subject = more examples of brain state transitions\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"STEP 3: GENERATE WINDOWS (v2.0: stride=20, 75% overlap)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "WINDOW_LENGTH = 80\n",
    "STRIDE = 20  # v2.0: Changed from 40 to 20 for 75% overlap\n",
    "K_VALUES = [10, 30, 100]\n",
    "\n",
    "def generate_windows_for_subjects(subject_list, subject_data, set_name=\"\"):\n",
    "    \"\"\"Generate windowed graphs for a list of subjects with progress tracking\"\"\"\n",
    "    graphs = []\n",
    "    labels = []\n",
    "    subject_ids = []\n",
    "    \n",
    "    print(f\"   Processing {len(subject_list)} {set_name} subjects...\")\n",
    "    for idx, subj in enumerate(subject_list):\n",
    "        if idx % 50 == 0 and idx > 0:\n",
    "            print(f\"      {idx}/{len(subject_list)} subjects processed ({len(graphs)} windows so far)...\")\n",
    "        \n",
    "        ts = subject_data[subj]['timeseries']\n",
    "        label = subject_data[subj]['label']\n",
    "        windows = extract_temporal_windows(ts, WINDOW_LENGTH, STRIDE)\n",
    "        \n",
    "        # Cap number of windows per subject to control memory usage\n",
    "        for window in windows[:MAX_WINDOWS_PER_SUBJECT]:\n",
    "            graph = graph_from_timeseries_enhanced(window, k_values=K_VALUES)\n",
    "            graph.y = torch.tensor([label], dtype=torch.long)\n",
    "            graphs.append(graph)\n",
    "            labels.append(label)\n",
    "            subject_ids.append(subj)\n",
    "    \n",
    "    print(f\"      {set_name}: {len(graphs)} windows from {len(subject_list)} subjects [Done]\")\n",
    "    return graphs, labels, subject_ids\n",
    "\n",
    "train_graphs, train_labels, train_subject_ids = generate_windows_for_subjects(train_subjects, subject_data, \"TRAIN\")\n",
    "val_graphs, val_labels, val_subject_ids = generate_windows_for_subjects(val_subjects, subject_data, \"VAL\")\n",
    "test_graphs, test_labels, test_subject_ids = generate_windows_for_subjects(test_subjects, subject_data, \"TEST\")\n",
    "\n",
    "print(\"\\nFINAL WINDOW COUNTS:\")\n",
    "print(f\"   Train: {len(train_graphs)} windows from {len(train_subjects)} subjects\")\n",
    "print(f\"   Val:   {len(val_graphs)} windows from {len(val_subjects)} subjects\")\n",
    "print(f\"   Test:  {len(test_graphs)} windows from {len(test_subjects)} subjects\")\n",
    "print(\"\\n   Note: v2.0 stride=20 produces ~2x more windows than v1.0 stride=40 (capped per subject here)\")\n",
    "\n",
    "# Create DataLoaders\n",
    "from torch_geometric.loader import DataLoader as PyGDataLoader\n",
    "BATCH_SIZE = 4\n",
    "# drop_last=True prevents BatchNorm errors when last batch has only 1 sample\n",
    "train_loader = PyGDataLoader(train_graphs, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "val_loader = PyGDataLoader(val_graphs, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)\n",
    "test_loader = PyGDataLoader(test_graphs, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)  # Keep all for final eval\n",
    "\n",
    "print(\"\\nDataLoaders ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcd8ce3",
   "metadata": {},
   "source": [
    "## CRITICAL FIX: Data Leakage Resolved\n",
    "\n",
    "**Previous Issue**: Windows from the same subject appeared in both training and validation sets, leading to inflated 95% accuracy (data leakage).\n",
    "\n",
    "**Fix Applied**: Subject-level splitting ensures no subject appears in multiple sets.\n",
    "\n",
    "**New Structure**:\n",
    "- Train: 60% of subjects\n",
    "- Validation: 15% of subjects  \n",
    "- Test1 (Public): 12.5% of subjects\n",
    "- Test2 (Hold-out): 12.5% of subjects\n",
    "\n",
    "**Expected Real Accuracy**: 60-75% (much more realistic for ASD classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7dda26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "EXISTING TRAINED MODEL FOUND (from input)\n",
      "============================================================\n",
      "  Model: ./braingat_best.pth\n",
      "  Config: ./training_config.json\n",
      "  Config: {'lr': 0.0005, 'hidden_dim': 32, 'temporal_dim': 64, 'dropout': 0.5, 'weight_decay': 0.0001, 'heads': 4, 'label_smoothing': 0.1, 'window_length': 80, 'stride': 20}\n",
      "  Model loaded successfully.\n",
      "  Branch Scales: Î±=0.9396, Î²=1.0561\n",
      "  Best Val Accuracy: 63.64%\n",
      "\n",
      "Skipping training. Proceeding to evaluation.\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# KAGGLE-OPTIMIZED: Train Final Model with Protocol Settings (v2.0)\n",
    "import gc\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ============================================================\n",
    "# CHECK FOR EXISTING TRAINED MODEL\n",
    "# ============================================================\n",
    "KAGGLE_INPUT_DIR = '/kaggle/input/complete-path'\n",
    "KAGGLE_WORKING_DIR = '/kaggle/working'\n",
    "LOCAL_DIR = '.'\n",
    "\n",
    "# Auto-detect environment and set paths\n",
    "if os.path.exists(KAGGLE_INPUT_DIR):\n",
    "    INPUT_DIR = KAGGLE_INPUT_DIR\n",
    "    WORKING_DIR = KAGGLE_WORKING_DIR\n",
    "else:\n",
    "    INPUT_DIR = LOCAL_DIR\n",
    "    WORKING_DIR = LOCAL_DIR\n",
    "\n",
    "# Check input directory first (uploaded pre-trained model)\n",
    "BEST_MODEL_PATH = os.path.join(INPUT_DIR, 'braingat_best.pth')\n",
    "CONFIG_PATH = os.path.join(INPUT_DIR, 'training_config.json')\n",
    "\n",
    "# Then check working directory (from current session)\n",
    "WORKING_MODEL_PATH = os.path.join(WORKING_DIR, 'braingat_best.pth')\n",
    "WORKING_CONFIG_PATH = os.path.join(WORKING_DIR, 'training_config.json')\n",
    "CHECKPOINT_PATH = os.path.join(WORKING_DIR, 'braingat_checkpoint.pth')\n",
    "\n",
    "# Check if training already completed\n",
    "SKIP_TRAINING = False\n",
    "if os.path.exists(BEST_MODEL_PATH) and os.path.exists(CONFIG_PATH):\n",
    "    print(\"=\"*60)\n",
    "    print(\"EXISTING TRAINED MODEL FOUND (from input)\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"  Model: {BEST_MODEL_PATH}\")\n",
    "    print(f\"  Config: {CONFIG_PATH}\")\n",
    "    \n",
    "    with open(CONFIG_PATH, 'r') as f:\n",
    "        config = json.load(f)\n",
    "    print(f\"  Config: {config}\")\n",
    "    \n",
    "    # Load the model\n",
    "    final_model = TemporalSpatialBrainGAT(\n",
    "        in_channels=392,\n",
    "        hidden_dim=config.get('hidden_dim', 32),\n",
    "        temporal_dim=config.get('temporal_dim', 64),\n",
    "        num_scales=3,\n",
    "        heads=config.get('heads', 4),\n",
    "        dropout=config.get('dropout', 0.5),\n",
    "        num_classes=2\n",
    "    ).to(device)\n",
    "    final_model.load_state_dict(torch.load(BEST_MODEL_PATH, map_location=device))\n",
    "    print(\"  Model loaded successfully.\")\n",
    "    \n",
    "    # === v2.0: Print branch scales ===\n",
    "    if hasattr(final_model, 'get_branch_scales'):\n",
    "        scales = final_model.get_branch_scales()\n",
    "        print(f\"  Branch Scales: Î±={scales['temporal_scale (Î±)']:.4f}, Î²={scales['spatial_scale (Î²)']:.4f}\")\n",
    "    \n",
    "    # Try to load history for plotting\n",
    "    if os.path.exists(CHECKPOINT_PATH):\n",
    "        ckpt = torch.load(CHECKPOINT_PATH, map_location=device)\n",
    "        history = ckpt.get('history', None)\n",
    "        best_val_acc = ckpt.get('best_val_acc', 0.0)\n",
    "        print(f\"  Best Val Accuracy: {best_val_acc:.2f}%\")\n",
    "    else:\n",
    "        history = None\n",
    "        best_val_acc = 0.0\n",
    "    \n",
    "    SKIP_TRAINING = True\n",
    "    print(\"\\nSkipping training. Proceeding to evaluation.\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "if not SKIP_TRAINING:\n",
    "    # Memory cleanup\n",
    "    if 'final_model' in globals():\n",
    "        del final_model\n",
    "    if 'optimizer' in globals():\n",
    "        del optimizer\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # Configuration (with label smoothing per protocol)\n",
    "    config = {\n",
    "        'lr': 5e-4,\n",
    "        'hidden_dim': 32,\n",
    "        'temporal_dim': 64,\n",
    "        'dropout': 0.5,\n",
    "        'weight_decay': 1e-4,\n",
    "        'heads': 4,\n",
    "        'label_smoothing': 0.1  # Protocol requirement\n",
    "    }\n",
    "\n",
    "    print(\"=\"*60)\n",
    "    print(\"FINAL TRAINING (PROTOCOL SETTINGS v2.0)\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Config: {json.dumps(config, indent=2)}\")\n",
    "\n",
    "    # Initialize model\n",
    "    final_model = TemporalSpatialBrainGAT(\n",
    "        in_channels=392,\n",
    "        hidden_dim=config['hidden_dim'],\n",
    "        temporal_dim=config['temporal_dim'],\n",
    "        num_scales=3,\n",
    "        heads=config['heads'],\n",
    "        dropout=config['dropout'],\n",
    "        num_classes=2\n",
    "    ).to(device)\n",
    "\n",
    "    params = sum(p.numel() for p in final_model.parameters())\n",
    "    print(f\"Parameters: {params:,}\")\n",
    "    \n",
    "    # === v2.0: Print initial branch scales ===\n",
    "    if hasattr(final_model, 'get_branch_scales'):\n",
    "        scales = final_model.get_branch_scales()\n",
    "        print(f\"Initial Branch Scales: Î±={scales['temporal_scale (Î±)']:.4f}, Î²={scales['spatial_scale (Î²)']:.4f}\")\n",
    "\n",
    "    # Class weights\n",
    "    num_ctrl = train_labels.count(0)\n",
    "    num_asd = train_labels.count(1)\n",
    "    w_ctrl = len(train_labels) / (2 * num_ctrl)\n",
    "    w_asd = len(train_labels) / (2 * num_asd)\n",
    "    class_weights = torch.tensor([w_ctrl, w_asd], dtype=torch.float).to(device)\n",
    "    print(f\"Class weights: Control={w_ctrl:.2f}, ASD={w_asd:.2f}\")\n",
    "\n",
    "    # Loss with label smoothing (PROTOCOL REQUIREMENT)\n",
    "    criterion = torch.nn.CrossEntropyLoss(weight=class_weights, label_smoothing=config['label_smoothing'])\n",
    "    print(f\"Label smoothing: {config['label_smoothing']}\")\n",
    "\n",
    "    optimizer = torch.optim.Adam(final_model.parameters(), lr=config['lr'], weight_decay=config['weight_decay'])\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=10)\n",
    "    scaler = torch.amp.GradScaler('cuda')\n",
    "\n",
    "    # Checkpointing paths (save to working directory)\n",
    "    CHECKPOINT_PATH_LOCAL = os.path.join(WORKING_DIR, 'braingat_checkpoint.pth')\n",
    "    BEST_MODEL_PATH_LOCAL = os.path.join(WORKING_DIR, 'braingat_best.pth')\n",
    "    CONFIG_PATH_LOCAL = os.path.join(WORKING_DIR, 'training_config.json')\n",
    "\n",
    "    # Save config\n",
    "    with open(CONFIG_PATH_LOCAL, 'w') as f:\n",
    "        json.dump({**config, 'window_length': WINDOW_LENGTH, 'stride': STRIDE}, f, indent=2)\n",
    "    print(f\"Saved config to {CONFIG_PATH_LOCAL}\")\n",
    "\n",
    "    # Training settings (PROTOCOL REQUIREMENTS)\n",
    "    TOTAL_EPOCHS = 80\n",
    "    PATIENCE = 20\n",
    "    ACCUM_STEPS = 8\n",
    "\n",
    "    # === v2.0: Added branch scale tracking to history ===\n",
    "    history = {\n",
    "        'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': [],\n",
    "        'temporal_scale': [], 'spatial_scale': []  # v2.0: Track branch importance\n",
    "    }\n",
    "    best_val_acc = 0.0\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    start_epoch = 1\n",
    "\n",
    "    # Resume if checkpoint exists\n",
    "    if os.path.exists(CHECKPOINT_PATH_LOCAL):\n",
    "        print(f\"\\nResuming from {CHECKPOINT_PATH_LOCAL}...\")\n",
    "        ckpt = torch.load(CHECKPOINT_PATH_LOCAL)\n",
    "        final_model.load_state_dict(ckpt['model_state_dict'])\n",
    "        optimizer.load_state_dict(ckpt['optimizer_state_dict'])\n",
    "        scheduler.load_state_dict(ckpt['scheduler_state_dict'])\n",
    "        start_epoch = ckpt['epoch'] + 1\n",
    "        best_val_acc = ckpt['best_val_acc']\n",
    "        history = ckpt['history']\n",
    "        # Ensure new keys exist for old checkpoints\n",
    "        if 'temporal_scale' not in history:\n",
    "            history['temporal_scale'] = []\n",
    "        if 'spatial_scale' not in history:\n",
    "            history['spatial_scale'] = []\n",
    "        patience_counter = ckpt.get('patience_counter', 0)\n",
    "        print(f\"   Starting from epoch {start_epoch}, best acc: {best_val_acc:.2f}%\")\n",
    "    else:\n",
    "        print(\"\\nStarting fresh training...\")\n",
    "\n",
    "    print(f\"\\nConfig: {TOTAL_EPOCHS} epochs, patience={PATIENCE}, batch={BATCH_SIZE}x{ACCUM_STEPS}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    try:\n",
    "        for epoch in range(start_epoch, TOTAL_EPOCHS + 1):\n",
    "            # TRAIN\n",
    "            final_model.train()\n",
    "            total_loss, correct, total = 0, 0, 0\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            for i, data in enumerate(train_loader):\n",
    "                data = data.to(device)\n",
    "                with torch.amp.autocast('cuda'):\n",
    "                    out = final_model(data)\n",
    "                    loss = criterion(out, data.y) / ACCUM_STEPS\n",
    "                \n",
    "                scaler.scale(loss).backward()\n",
    "                \n",
    "                if (i + 1) % ACCUM_STEPS == 0 or (i + 1) == len(train_loader):\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                    optimizer.zero_grad()\n",
    "                \n",
    "                total_loss += loss.item() * ACCUM_STEPS * data.num_graphs\n",
    "                correct += (out.argmax(dim=1) == data.y).sum().item()\n",
    "                total += data.num_graphs\n",
    "            \n",
    "            train_loss = total_loss / total\n",
    "            train_acc = 100.0 * correct / total\n",
    "            \n",
    "            # VALIDATE\n",
    "            final_model.eval()\n",
    "            val_loss, val_correct, val_total = 0, 0, 0\n",
    "            with torch.no_grad():\n",
    "                for data in val_loader:\n",
    "                    data = data.to(device)\n",
    "                    with torch.amp.autocast('cuda'):\n",
    "                        out = final_model(data)\n",
    "                        loss = criterion(out, data.y)\n",
    "                    if not torch.isnan(loss):\n",
    "                        val_loss += loss.item() * data.num_graphs\n",
    "                    val_correct += (out.argmax(dim=1) == data.y).sum().item()\n",
    "                    val_total += data.num_graphs\n",
    "            \n",
    "            val_loss = val_loss / val_total if val_total > 0 else float('inf')\n",
    "            val_acc = 100.0 * val_correct / val_total if val_total > 0 else 0.0\n",
    "            \n",
    "            scheduler.step(val_loss)\n",
    "            \n",
    "            # === v2.0: Get current branch scales ===\n",
    "            if hasattr(final_model, 'get_branch_scales'):\n",
    "                scales = final_model.get_branch_scales()\n",
    "                alpha = scales['temporal_scale (Î±)']\n",
    "                beta = scales['spatial_scale (Î²)']\n",
    "            else:\n",
    "                alpha, beta = 1.0, 1.0\n",
    "            \n",
    "            # History (including branch scales)\n",
    "            history['train_loss'].append(train_loss)\n",
    "            history['val_loss'].append(val_loss)\n",
    "            history['train_acc'].append(train_acc)\n",
    "            history['val_acc'].append(val_acc)\n",
    "            history['temporal_scale'].append(alpha)\n",
    "            history['spatial_scale'].append(beta)\n",
    "            \n",
    "            # Best model check\n",
    "            is_best = val_acc > best_val_acc\n",
    "            if is_best:\n",
    "                best_val_acc = val_acc\n",
    "                torch.save(final_model.state_dict(), BEST_MODEL_PATH_LOCAL)\n",
    "                patience_counter = 0\n",
    "            \n",
    "            # Early stopping (loss-based)\n",
    "            if val_loss < best_val_loss - 0.001:\n",
    "                best_val_loss = val_loss\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            # Save checkpoint\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': final_model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'scheduler_state_dict': scheduler.state_dict(),\n",
    "                'best_val_acc': best_val_acc,\n",
    "                'history': history,\n",
    "                'patience_counter': patience_counter\n",
    "            }, CHECKPOINT_PATH_LOCAL)\n",
    "            \n",
    "            # Print progress (including branch scales every 10 epochs)\n",
    "            if epoch % 5 == 0 or is_best:\n",
    "                status = \"* BEST\" if is_best else f\"(p:{patience_counter}/{PATIENCE})\"\n",
    "                print(f\"E{epoch:03d} | Train: {train_acc:.1f}% | Val: {val_acc:.1f}% | Loss: {val_loss:.4f} | LR: {optimizer.param_groups[0]['lr']:.1e} {status}\")\n",
    "            \n",
    "            # === v2.0: Print branch scales every 10 epochs to monitor temporal branch importance ===\n",
    "            if epoch % 10 == 0:\n",
    "                print(f\"       Branch Scales: Î±(temporal)={alpha:.4f}, Î²(spatial)={beta:.4f}\")\n",
    "                if alpha < 0.1:\n",
    "                    print(f\"       âš ï¸  WARNING: Temporal scale is low. Consider checking data preprocessing or window length.\")\n",
    "            \n",
    "            if patience_counter >= PATIENCE:\n",
    "                print(f\"\\nEarly stopping at epoch {epoch}\")\n",
    "                break\n",
    "            \n",
    "            if epoch % 20 == 0:\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nInterrupted - checkpoint saved!\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"TRAINING COMPLETE\")\n",
    "    print(f\"Best Validation Accuracy: {best_val_acc:.2f}%\")\n",
    "    \n",
    "    # === v2.0: Print final branch scales ===\n",
    "    if hasattr(final_model, 'get_branch_scales'):\n",
    "        scales = final_model.get_branch_scales()\n",
    "        print(f\"Final Branch Scales: Î±(temporal)={scales['temporal_scale (Î±)']:.4f}, Î²(spatial)={scales['spatial_scale (Î²)']:.4f}\")\n",
    "        if scales['temporal_scale (Î±)'] < 0.1:\n",
    "            print(\"âš ï¸  Temporal branch has low weight - consider:\")\n",
    "            print(\"   1. Enable EXCLUDE_PHASE_SYNC_FROM_EDGES = True for ablation\")\n",
    "            print(\"   2. Check if window length (80) captures meaningful dynamics\")\n",
    "            print(\"   3. Verify temporal preprocessing is correct\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    # Load best model\n",
    "    if os.path.exists(BEST_MODEL_PATH_LOCAL):\n",
    "        final_model.load_state_dict(torch.load(BEST_MODEL_PATH_LOCAL))\n",
    "        print(f\"Loaded best model from {BEST_MODEL_PATH_LOCAL}\")\n",
    "\n",
    "# Plot training curves (works for both loaded and fresh training)\n",
    "if history is not None and len(history.get('train_loss', [])) > 0:\n",
    "    # === v2.0: Added branch scale plot ===\n",
    "    has_scales = 'temporal_scale' in history and len(history['temporal_scale']) > 0\n",
    "    n_plots = 3 if has_scales else 2\n",
    "    \n",
    "    fig, axes = plt.subplots(1, n_plots, figsize=(6 * n_plots, 5))\n",
    "    \n",
    "    # Loss plot\n",
    "    axes[0].plot(history['train_loss'], label='Train')\n",
    "    axes[0].plot(history['val_loss'], label='Val')\n",
    "    axes[0].set_title('Loss')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Accuracy plot\n",
    "    axes[1].plot(history['train_acc'], label='Train')\n",
    "    axes[1].plot(history['val_acc'], label='Val')\n",
    "    axes[1].set_title(f'Accuracy (Best: {best_val_acc:.1f}%)')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Branch scales plot (v2.0)\n",
    "    if has_scales:\n",
    "        axes[2].plot(history['temporal_scale'], label='Î± (Temporal)', color='blue')\n",
    "        axes[2].plot(history['spatial_scale'], label='Î² (Spatial)', color='orange')\n",
    "        axes[2].axhline(y=1.0, color='gray', linestyle='--', alpha=0.5, label='Initial (1.0)')\n",
    "        axes[2].set_title('Branch Scaling Factors')\n",
    "        axes[2].set_xlabel('Epoch')\n",
    "        axes[2].set_ylabel('Scale')\n",
    "        axes[2].legend()\n",
    "        axes[2].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.savefig('training_curves.png', dpi=150)\n",
    "else:\n",
    "    print(\"No training history available for plotting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2bee6013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "SAVING ALL OUTPUTS\n",
      "============================================================\n",
      "  [OK] braingat_best.pth (in working)\n",
      "  [OK] braingat_checkpoint.pth (in working)\n",
      "  [OK] training_config.json (in working)\n",
      "  [OK] subject_splits.json (in working)\n",
      "  [OK] subject_level_results.json (in working)\n",
      "  [OK] training_curves.png (in working)\n",
      "  [--] sweep_results.json not found\n",
      "  [--] ablation_results.json not found\n",
      "\n",
      "Saved 6/8 files\n",
      "\n",
      "============================================================\n",
      "RESULTS SUMMARY\n",
      "============================================================\n",
      "Window params: length=80, stride=20\n",
      "Config: {\n",
      "  \"lr\": 0.0005,\n",
      "  \"hidden_dim\": 32,\n",
      "  \"temporal_dim\": 64,\n",
      "  \"dropout\": 0.5,\n",
      "  \"weight_decay\": 0.0001,\n",
      "  \"heads\": 4,\n",
      "  \"label_smoothing\": 0.1,\n",
      "  \"window_length\": 80,\n",
      "  \"stride\": 20\n",
      "}\n",
      "\n",
      "Window-level metrics:\n",
      "  Best validation accuracy: 63.64%\n",
      "\n",
      "Pipeline complete.\n"
     ]
    }
   ],
   "source": [
    "# Save All Outputs\n",
    "import shutil\n",
    "import os\n",
    "import json\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"SAVING ALL OUTPUTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Determine directories\n",
    "KAGGLE_WORKING = '/kaggle/working'\n",
    "KAGGLE_INPUT = '/kaggle/input/complete-path'\n",
    "USE_KAGGLE = os.path.exists(KAGGLE_WORKING)\n",
    "\n",
    "# List of output files to check\n",
    "output_files = [\n",
    "    'braingat_best.pth',\n",
    "    'braingat_checkpoint.pth',\n",
    "    'training_config.json',\n",
    "    'subject_splits.json',\n",
    "    'subject_level_results.json',\n",
    "    'training_curves.png',\n",
    "    'sweep_results.json',\n",
    "    'ablation_results.json'\n",
    "]\n",
    "\n",
    "# Check files in working directory (no need to copy, just verify)\n",
    "saved_count = 0\n",
    "for f in output_files:\n",
    "    if USE_KAGGLE:\n",
    "        # On Kaggle: check both input and working directories\n",
    "        working_path = os.path.join(KAGGLE_WORKING, f)\n",
    "        input_path = os.path.join(KAGGLE_INPUT, f) if os.path.exists(KAGGLE_INPUT) else None\n",
    "        \n",
    "        if os.path.exists(working_path):\n",
    "            print(f\"  [OK] {f} (in working)\")\n",
    "            saved_count += 1\n",
    "        elif input_path and os.path.exists(input_path):\n",
    "            print(f\"  [OK] {f} (in input)\")\n",
    "            saved_count += 1\n",
    "        else:\n",
    "            print(f\"  [--] {f} not found\")\n",
    "    else:\n",
    "        # Local: check current directory\n",
    "        if os.path.exists(f):\n",
    "            print(f\"  [OK] {f} (local)\")\n",
    "            saved_count += 1\n",
    "        else:\n",
    "            print(f\"  [--] {f} not found\")\n",
    "\n",
    "print(f\"\\nSaved {saved_count}/{len(output_files)} files\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RESULTS SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Print summary based on available results\n",
    "if 'config' in dir():\n",
    "    print(f\"Window params: length={WINDOW_LENGTH}, stride={STRIDE}\")\n",
    "    print(f\"Config: {json.dumps(config, indent=2)}\")\n",
    "\n",
    "if 'best_val_acc' in dir():\n",
    "    print(f\"\\nWindow-level metrics:\")\n",
    "    print(f\"  Best validation accuracy: {best_val_acc:.2f}%\")\n",
    "\n",
    "if 'val_results' in dir() and 'test_results' in dir():\n",
    "    print(f\"\\nSubject-level metrics:\")\n",
    "    print(f\"  Validation accuracy: {val_results['accuracy']:.2f}%\")\n",
    "    print(f\"  Validation AUC: {val_results['auc']:.3f}\")\n",
    "    print(f\"  Test accuracy: {test_results['accuracy']:.2f}%\")\n",
    "    print(f\"  Test AUC: {test_results['auc']:.3f}\")\n",
    "\n",
    "print(\"\\nPipeline complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2ebf1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "SUBJECT-LEVEL EVALUATION\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "SUBJECT-LEVEL RESULTS: Validation\n",
      "============================================================\n",
      "Subjects evaluated: 177\n",
      "Subject-Level Accuracy: 62.15%\n",
      "Subject-Level AUC: 0.692\n",
      "\n",
      "Confusion Matrix:\n",
      "              Pred Control  Pred ASD\n",
      "True Control        51          34\n",
      "True ASD            33          59\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Control      0.607     0.600     0.604        85\n",
      "         ASD      0.634     0.641     0.638        92\n",
      "\n",
      "    accuracy                          0.621       177\n",
      "   macro avg      0.621     0.621     0.621       177\n",
      "weighted avg      0.621     0.621     0.621       177\n",
      "\n",
      "\n",
      "============================================================\n",
      "SUBJECT-LEVEL RESULTS: Test\n",
      "============================================================\n",
      "Subjects evaluated: 178\n",
      "Subject-Level Accuracy: 66.85%\n",
      "Subject-Level AUC: 0.725\n",
      "\n",
      "Confusion Matrix:\n",
      "              Pred Control  Pred ASD\n",
      "True Control        49          37\n",
      "True ASD            22          70\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Control      0.690     0.570     0.624        86\n",
      "         ASD      0.654     0.761     0.704        92\n",
      "\n",
      "    accuracy                          0.669       178\n",
      "   macro avg      0.672     0.665     0.664       178\n",
      "weighted avg      0.672     0.669     0.665       178\n",
      "\n",
      "\n",
      "Saved results to subject_level_results.json\n"
     ]
    }
   ],
   "source": [
    "# Subject-Level Evaluation (CRITICAL - Protocol Requirement)\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_auc_score\n",
    "import numpy as np\n",
    "\n",
    "def evaluate_subject_level(model, loader, subject_ids, subject_data, set_name=\"Test\"):\n",
    "    \"\"\"\n",
    "    Aggregate window predictions to subject level.\n",
    "    Returns subject-level metrics (not window-level).\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Collect window-level predictions\n",
    "    window_preds = []\n",
    "    window_probs = []\n",
    "    window_labels = []\n",
    "    window_subjects = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, data in enumerate(loader):\n",
    "            data = data.to(device)\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                out = model(data)\n",
    "            \n",
    "            probs = torch.softmax(out, dim=1)\n",
    "            preds = out.argmax(dim=1)\n",
    "            \n",
    "            # Get subject IDs for this batch\n",
    "            start_idx = batch_idx * BATCH_SIZE\n",
    "            end_idx = start_idx + data.num_graphs\n",
    "            batch_subjects = subject_ids[start_idx:end_idx]\n",
    "            \n",
    "            window_preds.extend(preds.cpu().numpy())\n",
    "            window_probs.extend(probs[:, 1].cpu().numpy())  # P(ASD)\n",
    "            window_labels.extend(data.y.cpu().numpy())\n",
    "            window_subjects.extend(batch_subjects)\n",
    "    \n",
    "    # Aggregate to subject level\n",
    "    subject_preds = {}\n",
    "    subject_probs = {}\n",
    "    subject_labels = {}\n",
    "    \n",
    "    for subj, pred, prob, label in zip(window_subjects, window_preds, window_probs, window_labels):\n",
    "        if subj not in subject_preds:\n",
    "            subject_preds[subj] = []\n",
    "            subject_probs[subj] = []\n",
    "            subject_labels[subj] = label\n",
    "        subject_preds[subj].append(pred)\n",
    "        subject_probs[subj].append(prob)\n",
    "    \n",
    "    # Compute subject-level predictions (mean probability)\n",
    "    final_subjects = list(subject_preds.keys())\n",
    "    final_labels = [subject_labels[s] for s in final_subjects]\n",
    "    final_probs = [np.mean(subject_probs[s]) for s in final_subjects]\n",
    "    final_preds = [1 if p > 0.5 else 0 for p in final_probs]\n",
    "    \n",
    "    # Metrics\n",
    "    acc = accuracy_score(final_labels, final_preds) * 100\n",
    "    try:\n",
    "        auc = roc_auc_score(final_labels, final_probs)\n",
    "    except:\n",
    "        auc = 0.5\n",
    "    \n",
    "    cm = confusion_matrix(final_labels, final_preds)\n",
    "    report = classification_report(final_labels, final_preds, target_names=['Control', 'ASD'], digits=3)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"SUBJECT-LEVEL RESULTS: {set_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"Subjects evaluated: {len(final_subjects)}\")\n",
    "    print(f\"Subject-Level Accuracy: {acc:.2f}%\")\n",
    "    print(f\"Subject-Level AUC: {auc:.3f}\")\n",
    "    print(f\"\\nConfusion Matrix:\")\n",
    "    print(f\"              Pred Control  Pred ASD\")\n",
    "    print(f\"True Control      {cm[0,0]:4d}        {cm[0,1]:4d}\")\n",
    "    print(f\"True ASD          {cm[1,0]:4d}        {cm[1,1]:4d}\")\n",
    "    print(f\"\\nClassification Report:\")\n",
    "    print(report)\n",
    "    \n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'auc': auc,\n",
    "        'confusion_matrix': cm,\n",
    "        'subjects': final_subjects,\n",
    "        'predictions': final_preds,\n",
    "        'probabilities': final_probs,\n",
    "        'labels': final_labels\n",
    "    }\n",
    "\n",
    "# Evaluate on validation and test sets\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUBJECT-LEVEL EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "val_results = evaluate_subject_level(final_model, val_loader, val_subject_ids, subject_data, \"Validation\")\n",
    "test_results = evaluate_subject_level(final_model, test_loader, test_subject_ids, subject_data, \"Test\")\n",
    "\n",
    "# Save results\n",
    "results_summary = {\n",
    "    'validation': {'accuracy': val_results['accuracy'], 'auc': val_results['auc']},\n",
    "    'test': {'accuracy': test_results['accuracy'], 'auc': test_results['auc']}\n",
    "}\n",
    "with open('subject_level_results.json', 'w') as f:\n",
    "    json.dump(results_summary, f, indent=2)\n",
    "print(f\"\\nSaved results to subject_level_results.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29ff1218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Running locally - loading from .\n",
      "Loaded config: {'lr': 0.0005, 'hidden_dim': 32, 'temporal_dim': 64, 'dropout': 0.5, 'weight_decay': 0.0001, 'heads': 4, 'label_smoothing': 0.1, 'window_length': 80, 'stride': 20}\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for TemporalSpatialBrainGAT:\n\tUnexpected key(s) in state_dict: \"temporal_scale\", \"spatial_scale\", \"temporal_norm.weight\", \"temporal_norm.bias\", \"spatial_norm.weight\", \"spatial_norm.bias\". \n\tsize mismatch for classifier.0.weight: copying a param with shape torch.Size([128, 320]) from checkpoint, the shape in current model is torch.Size([128, 256]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_184/3762918324.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBEST_MODEL_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBEST_MODEL_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Loaded best model from {BEST_MODEL_PATH}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;32melif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCHECKPOINT_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2623\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2624\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   2625\u001b[0m                 \"Error(s) in loading state_dict for {}:\\n\\t{}\".format(\n\u001b[1;32m   2626\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\\t\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for TemporalSpatialBrainGAT:\n\tUnexpected key(s) in state_dict: \"temporal_scale\", \"spatial_scale\", \"temporal_norm.weight\", \"temporal_norm.bias\", \"spatial_norm.weight\", \"spatial_norm.bias\". \n\tsize mismatch for classifier.0.weight: copying a param with shape torch.Size([128, 320]) from checkpoint, the shape in current model is torch.Size([128, 256])."
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# POST-TRAINING IMPORTS & MODEL LOADING (Run this cell first!)\n",
    "# ============================================================\n",
    "# Use this cell when resuming a Kaggle session to load the trained model\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GATConv, global_mean_pool, global_max_pool\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader as PyGDataLoader\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, roc_auc_score\n",
    "from pathlib import Path\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# ============================================================\n",
    "# KAGGLE PATHS (change these if running locally)\n",
    "# ============================================================\n",
    "KAGGLE_INPUT_DIR = '/kaggle/input/complete-path'\n",
    "KAGGLE_WORKING_DIR = '/kaggle/working'\n",
    "LOCAL_DIR = '.'\n",
    "\n",
    "# Auto-detect environment\n",
    "if os.path.exists(KAGGLE_INPUT_DIR):\n",
    "    INPUT_DIR = KAGGLE_INPUT_DIR\n",
    "    WORKING_DIR = KAGGLE_WORKING_DIR\n",
    "    print(f\"Running on Kaggle - loading from {INPUT_DIR}\")\n",
    "else:\n",
    "    INPUT_DIR = LOCAL_DIR\n",
    "    WORKING_DIR = LOCAL_DIR\n",
    "    print(f\"Running locally - loading from {INPUT_DIR}\")\n",
    "\n",
    "# File paths (load pre-trained from input, save new results to working)\n",
    "BEST_MODEL_PATH = os.path.join(INPUT_DIR, 'braingat_best.pth')\n",
    "CHECKPOINT_PATH = os.path.join(INPUT_DIR, 'braingat_checkpoint.pth')\n",
    "CONFIG_PATH = os.path.join(INPUT_DIR, 'training_config.json')\n",
    "SPLITS_PATH = os.path.join(INPUT_DIR, 'subject_splits.json')\n",
    "CACHE_PATH = os.path.join(WORKING_DIR, 'subject_data_cache.pkl')\n",
    "RESULTS_PATH = os.path.join(WORKING_DIR, 'subject_level_results.json')\n",
    "\n",
    "# ============================================================\n",
    "# LOAD CONFIGURATION\n",
    "# ============================================================\n",
    "if os.path.exists(CONFIG_PATH):\n",
    "    with open(CONFIG_PATH, 'r') as f:\n",
    "        config = json.load(f)\n",
    "    print(f\"Loaded config: {config}\")\n",
    "else:\n",
    "    # Default config\n",
    "    config = {\n",
    "        'lr': 5e-4, 'hidden_dim': 32, 'temporal_dim': 64,\n",
    "        'dropout': 0.5, 'weight_decay': 1e-4, 'heads': 4,\n",
    "        'label_smoothing': 0.1, 'window_length': 80, 'stride': 40\n",
    "    }\n",
    "    print(f\"WARNING: Config not found, using defaults\")\n",
    "\n",
    "WINDOW_LENGTH = config.get('window_length', 80)\n",
    "STRIDE = config.get('stride', 40)\n",
    "BATCH_SIZE = 4\n",
    "K_VALUES = [10, 30, 100]\n",
    "\n",
    "# ============================================================\n",
    "# MODEL ARCHITECTURE (must match training)\n",
    "# ============================================================\n",
    "class TemporalAttention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super().__init__()\n",
    "        self.query = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.key = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.value = nn.Linear(hidden_dim, hidden_dim)\n",
    "    def forward(self, x):\n",
    "        Q, K, V = self.query(x), self.key(x), self.value(x)\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / np.sqrt(Q.size(-1))\n",
    "        return torch.matmul(F.softmax(scores, dim=-1), V)\n",
    "\n",
    "class TemporalBranch(nn.Module):\n",
    "    def __init__(self, input_time_len=80, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(1, hidden_dim, kernel_size=7, padding=3)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.conv2 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=5, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.temporal_attn = TemporalAttention(hidden_dim)\n",
    "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
    "    def forward(self, timeseries, batch):\n",
    "        x = timeseries.unsqueeze(1)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.temporal_attn(x)\n",
    "        x = x.transpose(1, 2)\n",
    "        x = self.pool(x).squeeze(-1)\n",
    "        return global_mean_pool(x, batch)\n",
    "\n",
    "class MultiHeadGATLayerWithEdgeFeats(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, heads=4, dropout=0.3, concat=True):\n",
    "        super().__init__()\n",
    "        self.gat = GATConv(in_channels, out_channels, heads=heads, dropout=dropout, concat=concat, edge_dim=4)\n",
    "        self.bn = nn.BatchNorm1d(out_channels * heads if concat else out_channels)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        x = self.gat(x, edge_index, edge_attr=edge_attr)\n",
    "        return self.dropout(F.elu(self.bn(x)))\n",
    "\n",
    "class MultiScaleSpatialBranch(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_dim=32, num_scales=3, heads=4, dropout=0.5):\n",
    "        super().__init__()\n",
    "        self.num_scales = num_scales\n",
    "        self.gats = nn.ModuleList([\n",
    "            nn.ModuleList([\n",
    "                MultiHeadGATLayerWithEdgeFeats(in_channels, hidden_dim, heads, dropout, concat=True),\n",
    "                MultiHeadGATLayerWithEdgeFeats(hidden_dim * heads, hidden_dim, heads, dropout, concat=False)\n",
    "            ]) for _ in range(num_scales)\n",
    "        ])\n",
    "    def forward(self, x, edge_indices, edge_attrs, batch):\n",
    "        scale_features = []\n",
    "        for i in range(self.num_scales):\n",
    "            h = x\n",
    "            for gat_layer in self.gats[i]:\n",
    "                h = gat_layer(h, edge_indices[i], edge_attrs[i])\n",
    "            h_mean, h_max = global_mean_pool(h, batch), global_max_pool(h, batch)\n",
    "            scale_features.append(torch.cat([h_mean, h_max], dim=-1))\n",
    "        return torch.cat(scale_features, dim=-1)\n",
    "\n",
    "class TemporalSpatialBrainGAT(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_dim=32, temporal_dim=64, num_scales=3, heads=4, dropout=0.5, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.num_scales = num_scales\n",
    "        self.temporal_branch = TemporalBranch(input_time_len=80, hidden_dim=temporal_dim)\n",
    "        self.spatial_branch = MultiScaleSpatialBranch(in_channels, hidden_dim, num_scales, heads, dropout)\n",
    "        total_dim = num_scales * hidden_dim * 2 + temporal_dim\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(total_dim, hidden_dim * 4), nn.BatchNorm1d(hidden_dim * 4), nn.ReLU(), nn.Dropout(0.5),\n",
    "            nn.Linear(hidden_dim * 4, hidden_dim * 2), nn.BatchNorm1d(hidden_dim * 2), nn.ReLU(), nn.Dropout(0.5),\n",
    "            nn.Linear(hidden_dim * 2, num_classes)\n",
    "        )\n",
    "    def forward(self, data):\n",
    "        x, timeseries = data.x, data.timeseries\n",
    "        batch = data.batch if hasattr(data, 'batch') else torch.zeros(x.size(0), dtype=torch.long, device=x.device)\n",
    "        edge_indices = [getattr(data, f'edge_index_{i}') for i in range(self.num_scales)]\n",
    "        edge_attrs = [getattr(data, f'edge_attr_{i}') for i in range(self.num_scales)]\n",
    "        temporal_feats = self.temporal_branch(timeseries, batch)\n",
    "        spatial_feats = self.spatial_branch(x, edge_indices, edge_attrs, batch)\n",
    "        return self.classifier(torch.cat([temporal_feats, spatial_feats], dim=-1))\n",
    "\n",
    "# ============================================================\n",
    "# LOAD TRAINED MODEL\n",
    "# ============================================================\n",
    "model = TemporalSpatialBrainGAT(\n",
    "    in_channels=392,\n",
    "    hidden_dim=config.get('hidden_dim', 32),\n",
    "    temporal_dim=config.get('temporal_dim', 64),\n",
    "    num_scales=3,\n",
    "    heads=config.get('heads', 4),\n",
    "    dropout=config.get('dropout', 0.5),\n",
    "    num_classes=2\n",
    ").to(device)\n",
    "\n",
    "if os.path.exists(BEST_MODEL_PATH):\n",
    "    model.load_state_dict(torch.load(BEST_MODEL_PATH, map_location=device))\n",
    "    print(f\"Loaded best model from {BEST_MODEL_PATH}\")\n",
    "elif os.path.exists(CHECKPOINT_PATH):\n",
    "    ckpt = torch.load(CHECKPOINT_PATH, map_location=device)\n",
    "    model.load_state_dict(ckpt['model_state_dict'])\n",
    "    print(f\"Loaded checkpoint (epoch {ckpt['epoch']}) from {CHECKPOINT_PATH}\")\n",
    "else:\n",
    "    print(\"ERROR: No trained model found. Run training first.\")\n",
    "\n",
    "# ============================================================\n",
    "# LOAD SUBJECT SPLITS\n",
    "# ============================================================\n",
    "if os.path.exists(SPLITS_PATH):\n",
    "    with open(SPLITS_PATH, 'r') as f:\n",
    "        split_info = json.load(f)\n",
    "    train_subjects = split_info['train_subjects']\n",
    "    val_subjects = split_info['val_subjects']\n",
    "    test_subjects = split_info['test_subjects']\n",
    "    print(f\"Loaded splits: {len(train_subjects)} train, {len(val_subjects)} val, {len(test_subjects)} test\")\n",
    "else:\n",
    "    print(\"WARNING: Subject splits not found\")\n",
    "\n",
    "# ============================================================\n",
    "# LOAD PREVIOUS RESULTS (if available)\n",
    "# ============================================================\n",
    "if os.path.exists(RESULTS_PATH):\n",
    "    with open(RESULTS_PATH, 'r') as f:\n",
    "        prev_results = json.load(f)\n",
    "    print(f\"\\nPrevious Results:\")\n",
    "    print(f\"   Val Accuracy: {prev_results['validation']['accuracy']:.2f}%\")\n",
    "    print(f\"   Val AUC: {prev_results['validation']['auc']:.3f}\")\n",
    "    print(f\"   Test Accuracy: {prev_results['test']['accuracy']:.2f}%\")\n",
    "    print(f\"   Test AUC: {prev_results['test']['auc']:.3f}\")\n",
    "\n",
    "print(\"\\nPost-training setup complete. Model ready for inference.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0462983e",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization Strategy\n",
    "\n",
    "### Phase 2: Sanity Sweep (Small Grid)\n",
    "\n",
    "Before exploring architectural changes, we establish a strong baseline through a focused hyperparameter sweep. This is not an exhaustive grid search but a sanity check on key regularization parameters.\n",
    "\n",
    "| Parameter | Values | Rationale |\n",
    "|-----------|--------|-----------|\n",
    "| Learning rate | {1e-3, 3e-4} | Bracket around default 5e-4 |\n",
    "| Weight decay | {1e-4, 5e-4} | L2 regularization strength |\n",
    "| Label smoothing | {0.05, 0.1} | Calibration vs confidence |\n",
    "| Dropout | {0.3, 0.5} | Regularization intensity |\n",
    "\n",
    "**Total configurations**: 2 x 2 x 2 x 2 = 16 runs\n",
    "\n",
    "**Estimated time**: ~40 min per run x 16 = ~10-11 hours (fits in Kaggle session)\n",
    "\n",
    "### Phase 3: Architectural Hypotheses (After Phase 2)\n",
    "\n",
    "Only after establishing optimal regularization:\n",
    "\n",
    "1. **Window length sensitivity**: {60, 80, 100} TR\n",
    "   - Shorter windows: More samples, less temporal context\n",
    "   - Longer windows: Richer dynamics, fewer samples\n",
    "\n",
    "2. **Stride sensitivity**: {20, 40} TR\n",
    "   - stride=20: 75% overlap, 4x more windows\n",
    "   - stride=40: 50% overlap (current baseline)\n",
    "\n",
    "3. **Temporal module ablation**:\n",
    "   - Full model (temporal + spatial)\n",
    "   - Spatial only (remove temporal branch)\n",
    "   - Temporal only (remove GAT)\n",
    "\n",
    "4. **Multi-scale ablation**:\n",
    "   - Full hierarchy: k={10, 30, 100}\n",
    "   - Single scale: k=30 only\n",
    "   - Two scales: k={10, 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67ca20d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sweep resume not forced; leaving sweep_results.json intact.\n"
     ]
    }
   ],
   "source": [
    "# Optional helper: ONLY use this if you explicitly want to force re-running Phase 2.\n",
    "# By default (FORCE_RESUME_SWEEP=0), this does nothing so you can safely \"Run all\".\n",
    "\n",
    "import os\n",
    "\n",
    "FORCE_RESUME_SWEEP = int(os.environ.get('FORCE_RESUME_SWEEP', '0'))\n",
    "\n",
    "if FORCE_RESUME_SWEEP and os.path.exists('sweep_results.json'):\n",
    "    os.rename('sweep_results.json', 'sweep_results_incomplete.json')\n",
    "    print(\"Renamed sweep_results.json -> sweep_results_incomplete.json (forced sweep resume)\")\n",
    "else:\n",
    "    print(\"Sweep resume not forced; leaving sweep_results.json intact.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c753339",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707e105d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PHASE 2: HYPERPARAMETER SANITY SWEEP\n",
      "======================================================================\n",
      "Search space: {'lr': [0.001, 0.0003], 'weight_decay': [0.0001, 0.0005], 'label_smoothing': [0.05, 0.1], 'dropout': [0.3, 0.5]}\n",
      "Fixed params: hidden_dim=32, temporal_dim=64\n",
      "Total configurations: 16\n",
      "Epochs per config: 60 (patience=20)\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sweep Progress:   0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[1/16] Config: lr=1e-03, wd=1e-04, ls=0.05, do=0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sweep Progress:   0%|          | 0/16 [40:03<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_184/2187669869.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    174\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m                     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accum_steps'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_184/3762918324.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0medge_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'edge_index_{i}'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_scales\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0medge_attrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'edge_attr_{i}'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_scales\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mtemporal_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemporal_branch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeseries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0mspatial_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspatial_branch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_attrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtemporal_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspatial_feats\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1771\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1773\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1774\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1775\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1782\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1784\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1785\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1786\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_184/3762918324.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, timeseries, batch)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mglobal_mean_pool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mMultiHeadGATLayerWithEdgeFeats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/nn/pool/glob.py\u001b[0m in \u001b[0;36mglobal_mean_pool\u001b[0;34m(x, batch, size)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/utils/_scatter.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(src, index, dim, dim_size, reduce)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mdim_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;31m# For now, we maintain various different code paths, based on whether\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# PHASE 2: HYPERPARAMETER SANITY SWEEP\n",
    "# ============================================================\n",
    "# Small grid search over regularization parameters\n",
    "# 16 configurations, ~40 min each = ~10-11 hours total\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import itertools\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ============================================================\n",
    "# CHECK FOR EXISTING SWEEP RESULTS\n",
    "# ============================================================\n",
    "KAGGLE_DIR = '/kaggle/working'\n",
    "LOCAL_DIR = '.'\n",
    "BASE_DIR = KAGGLE_DIR if os.path.exists(KAGGLE_DIR) else LOCAL_DIR\n",
    "\n",
    "SWEEP_RESULTS_PATH = os.path.join(BASE_DIR, 'sweep_results.json')\n",
    "\n",
    "# Define search space first to know total configs\n",
    "PARAM_GRID = {\n",
    "    'lr': [1e-3, 3e-4],\n",
    "    'weight_decay': [1e-4, 5e-4],\n",
    "    'label_smoothing': [0.05, 0.1],\n",
    "    'dropout': [0.3, 0.5]\n",
    "}\n",
    "param_names = list(PARAM_GRID.keys())\n",
    "param_values = list(PARAM_GRID.values())\n",
    "all_configs = list(itertools.product(*param_values))\n",
    "TOTAL_CONFIGS = len(all_configs)\n",
    "\n",
    "SKIP_SWEEP = False\n",
    "if os.path.exists(SWEEP_RESULTS_PATH):\n",
    "    print(\"=\"*70)\n",
    "    print(\"EXISTING SWEEP RESULTS FOUND\")\n",
    "    print(\"=\"*70)\n",
    "    with open(SWEEP_RESULTS_PATH, 'r') as f:\n",
    "        sweep_data = json.load(f)\n",
    "    \n",
    "    sweep_results = sweep_data['results']\n",
    "    best_config = sweep_data['best_config']\n",
    "    best_overall_acc = sweep_data['best_val_acc']\n",
    "    \n",
    "    print(f\"Configurations tested: {len(sweep_results)}/{TOTAL_CONFIGS}\")\n",
    "    print(f\"Best Val Accuracy: {best_overall_acc:.2f}%\")\n",
    "    print(f\"Best Config:\")\n",
    "    print(f\"  lr: {best_config['lr']}\")\n",
    "    print(f\"  weight_decay: {best_config['weight_decay']}\")\n",
    "    print(f\"  label_smoothing: {best_config['label_smoothing']}\")\n",
    "    print(f\"  dropout: {best_config['dropout']}\")\n",
    "    \n",
    "    # Show all results sorted\n",
    "    import pandas as pd\n",
    "    df = pd.DataFrame(sweep_results).sort_values('best_val_acc', ascending=False)\n",
    "    print(\"\\nAll results (sorted by val acc):\")\n",
    "    print(df.to_string(index=False))\n",
    "    \n",
    "    # Check if sweep is complete\n",
    "    if len(sweep_results) >= TOTAL_CONFIGS:\n",
    "        SKIP_SWEEP = True\n",
    "        print(\"\\nSweep complete! All configurations tested.\")\n",
    "        print(\"=\"*70)\n",
    "    else:\n",
    "        print(f\"\\nSweep incomplete! Resuming from config {len(sweep_results)+1}...\")\n",
    "        print(\"=\"*70)\n",
    "        # Treat as partial results\n",
    "        completed_indices = {r['config_idx'] for r in sweep_results}\n",
    "        sweep_start_time = time.time() - sweep_data.get('total_time_hours', 0) * 3600\n",
    "\n",
    "if not SKIP_SWEEP:\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    # Fixed parameters\n",
    "    FIXED_PARAMS = {\n",
    "        'hidden_dim': 32,\n",
    "        'temporal_dim': 64,\n",
    "        'heads': 4,\n",
    "        'epochs': 60,\n",
    "        'patience': 20,\n",
    "        'batch_size': 4,\n",
    "        'accum_steps': 8\n",
    "    }\n",
    "\n",
    "    print(\"=\"*70)\n",
    "    print(\"PHASE 2: HYPERPARAMETER SANITY SWEEP\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Search space: {PARAM_GRID}\")\n",
    "    print(f\"Fixed params: hidden_dim={FIXED_PARAMS['hidden_dim']}, temporal_dim={FIXED_PARAMS['temporal_dim']}\")\n",
    "    print(f\"Total configurations: {len(all_configs)}\")\n",
    "    print(f\"Epochs per config: {FIXED_PARAMS['epochs']} (patience={FIXED_PARAMS['patience']})\")\n",
    "    print(\"=\"*70)\n",
    "\n",
    "    # Results storage - check if resuming from incomplete sweep_results.json\n",
    "    PARTIAL_RESULTS_PATH = os.path.join(BASE_DIR, 'sweep_partial.json')\n",
    "    if 'completed_indices' not in dir():\n",
    "        # Not resuming from incomplete sweep_results.json, check for partial file\n",
    "        if os.path.exists(PARTIAL_RESULTS_PATH):\n",
    "            print(\"\\nFound partial results from previous run. Resuming...\")\n",
    "            with open(PARTIAL_RESULTS_PATH, 'r') as f:\n",
    "                partial_data = json.load(f)\n",
    "            sweep_results = partial_data['results']\n",
    "            best_overall_acc = partial_data.get('best_val_acc', 0.0)\n",
    "            best_config = partial_data.get('best_config', None)\n",
    "            completed_indices = {r['config_idx'] for r in sweep_results}\n",
    "            print(f\"Completed {len(completed_indices)}/{len(all_configs)} configs. Resuming from config {len(completed_indices)+1}\")\n",
    "            sweep_start_time = time.time() - partial_data.get('elapsed_time', 0)\n",
    "        else:\n",
    "            sweep_results = []\n",
    "            best_overall_acc = 0.0\n",
    "            best_config = None\n",
    "            completed_indices = set()\n",
    "            sweep_start_time = time.time()\n",
    "\n",
    "    # Class weights (compute once)\n",
    "    num_ctrl = sum(1 for s in train_subjects if subject_data[s]['label'] == 0)\n",
    "    num_asd = sum(1 for s in train_subjects if subject_data[s]['label'] == 1)\n",
    "    total_samples = num_ctrl + num_asd\n",
    "    w_ctrl = total_samples / (2 * num_ctrl)\n",
    "    w_asd = total_samples / (2 * num_asd)\n",
    "    class_weights = torch.tensor([w_ctrl, w_asd], dtype=torch.float).to(device)\n",
    "\n",
    "    # Use manual iteration to update progress properly\n",
    "    sweep_pbar = tqdm(total=len(all_configs), desc=\"Overall Sweep\", position=0)\n",
    "    sweep_pbar.update(len(completed_indices))  # Set to already completed configs\n",
    "    \n",
    "    for config_idx, config_values in enumerate(all_configs):\n",
    "        # Skip if already completed\n",
    "        if config_idx in completed_indices:\n",
    "            continue\n",
    "        \n",
    "        # Build config dict\n",
    "        config = dict(zip(param_names, config_values))\n",
    "        config.update(FIXED_PARAMS)\n",
    "        \n",
    "        sweep_pbar.set_description(f\"Config {config_idx+1}/{len(all_configs)} [lr={config['lr']:.0e}, do={config['dropout']}]\")\n",
    "        tqdm.write(f\"\\n[{config_idx+1}/{len(all_configs)}] Config: lr={config['lr']:.0e}, wd={config['weight_decay']:.0e}, \"\n",
    "                   f\"ls={config['label_smoothing']}, do={config['dropout']}\")\n",
    "        \n",
    "        # Clean up previous model\n",
    "        if 'model' in dir():\n",
    "            del model\n",
    "        torch.cuda.empty_cache()\n",
    "        gc.collect()\n",
    "        \n",
    "        # Initialize model\n",
    "        model = TemporalSpatialBrainGAT(\n",
    "            in_channels=392,\n",
    "            hidden_dim=config['hidden_dim'],\n",
    "            temporal_dim=config['temporal_dim'],\n",
    "            num_scales=3,\n",
    "            heads=config['heads'],\n",
    "            dropout=config['dropout'],\n",
    "            num_classes=2\n",
    "        ).to(device)\n",
    "        \n",
    "        criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=config['label_smoothing'])\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=config['lr'], weight_decay=config['weight_decay'])\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config['epochs'], eta_min=1e-6)\n",
    "        scaler = torch.amp.GradScaler('cuda')\n",
    "        # Training loop\n",
    "        best_val_acc = 0.0\n",
    "        patience_counter = 0\n",
    "        config_start_time = time.time()\n",
    "        \n",
    "        pbar = tqdm(range(1, config['epochs'] + 1), desc=f\"Config {config_idx+1}/{len(all_configs)}\", position=1, leave=False)\n",
    "        for epoch in pbar:\n",
    "            # Train\n",
    "            model.train()\n",
    "            correct, total = 0, 0\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            for i, data in enumerate(train_loader):\n",
    "                data = data.to(device)\n",
    "                with torch.amp.autocast('cuda'):\n",
    "                    out = model(data)\n",
    "                    loss = criterion(out, data.y) / config['accum_steps']\n",
    "                \n",
    "                scaler.scale(loss).backward()\n",
    "                \n",
    "                if (i + 1) % config['accum_steps'] == 0 or (i + 1) == len(train_loader):\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                    optimizer.zero_grad()\n",
    "                \n",
    "                correct += (out.argmax(dim=1) == data.y).sum().item()\n",
    "                total += data.num_graphs\n",
    "            \n",
    "            train_acc = 100.0 * correct / total\n",
    "            \n",
    "            # Validate\n",
    "            model.eval()\n",
    "            val_correct, val_total = 0, 0\n",
    "            with torch.no_grad():\n",
    "                for data in val_loader:\n",
    "                    data = data.to(device)\n",
    "                    with torch.amp.autocast('cuda'):\n",
    "                        out = model(data)\n",
    "                    val_correct += (out.argmax(dim=1) == data.y).sum().item()\n",
    "                    val_total += data.num_graphs\n",
    "            val_acc = 100.0 * val_correct / val_total\n",
    "            scheduler.step()\n",
    "            \n",
    "            # Update progress bar\n",
    "            pbar.set_postfix({'train_acc': f'{train_acc:.1f}%', 'val_acc': f'{val_acc:.1f}%', 'best': f'{best_val_acc:.1f}%', 'patience': f'{patience_counter}/{config[\"patience\"]}'}, refresh=True)\n",
    "            \n",
    "            # Early stopping\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                patience_counter = 0\n",
    "                # Save best model for this config\n",
    "                torch.save(model.state_dict(), f'sweep_best_{config_idx}.pth')\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "            \n",
    "            if patience_counter >= config['patience']:\n",
    "                pbar.close()\n",
    "                break\n",
    "    \n",
    "        config_time = time.time() - config_start_time\n",
    "        \n",
    "        # Record results\n",
    "        result = {\n",
    "            'config_idx': config_idx,\n",
    "            'lr': config['lr'],\n",
    "            'weight_decay': config['weight_decay'],\n",
    "            'label_smoothing': config['label_smoothing'],\n",
    "            'dropout': config['dropout'],\n",
    "            'best_val_acc': best_val_acc,\n",
    "            'final_epoch': epoch,\n",
    "            'time_minutes': config_time / 60\n",
    "        }\n",
    "        sweep_results.append(result)\n",
    "        \n",
    "        tqdm.write(f\"    Best Val Acc: {best_val_acc:.2f}% (epoch {epoch}, {config_time/60:.1f} min)\")\n",
    "        \n",
    "        # Track overall best\n",
    "        if best_val_acc > best_overall_acc:\n",
    "            best_overall_acc = best_val_acc\n",
    "            best_config = config.copy()\n",
    "            best_config_idx = config_idx\n",
    "            tqdm.write(f\"    ** NEW OVERALL BEST **\")\n",
    "        \n",
    "        # Update overall sweep progress\n",
    "        sweep_pbar.update(1)\n",
    "        \n",
    "        # Save partial results after each config (resume capability)\n",
    "        partial_output = {\n",
    "            'results': sweep_results,\n",
    "            'best_config': best_config,\n",
    "            'best_val_acc': best_overall_acc,\n",
    "            'elapsed_time': time.time() - sweep_start_time\n",
    "        }\n",
    "        with open(PARTIAL_RESULTS_PATH, 'w') as f:\n",
    "            json.dump(partial_output, f, indent=2)\n",
    "    \n",
    "    sweep_pbar.close()\n",
    "\n",
    "    total_time = time.time() - sweep_start_time\n",
    "\n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"SWEEP COMPLETE\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Total time: {total_time/3600:.2f} hours\")\n",
    "    print(f\"\\nBest configuration (Val Acc: {best_overall_acc:.2f}%):\")\n",
    "    print(f\"  lr: {best_config['lr']}\")\n",
    "    print(f\"  weight_decay: {best_config['weight_decay']}\")\n",
    "    print(f\"  label_smoothing: {best_config['label_smoothing']}\")\n",
    "    print(f\"  dropout: {best_config['dropout']}\")\n",
    "\n",
    "    # Save results\n",
    "    import pandas as pd\n",
    "    sweep_results_df = pd.DataFrame(sweep_results)\n",
    "    sweep_results_df = sweep_results_df.sort_values('best_val_acc', ascending=False)\n",
    "    print(\"\\nAll results (sorted by val acc):\")\n",
    "    print(sweep_results_df.to_string(index=False))\n",
    "\n",
    "    # Save to file (both local and Kaggle)\n",
    "    sweep_output = {\n",
    "        'results': sweep_results,\n",
    "        'best_config': best_config,\n",
    "        'best_val_acc': best_overall_acc,\n",
    "        'total_time_hours': total_time / 3600\n",
    "    }\n",
    "    print(\"\\nSaved to sweep_results.json\")\n",
    "    with open('sweep_results.json', 'w') as f:\n",
    "        json.dump(sweep_output, f, indent=2)\n",
    "    print(\"\\nSaved to sweep_results.json\")\n",
    "    \n",
    "    # Also save to Kaggle if available\n",
    "    if os.path.exists('/kaggle/working'):\n",
    "        with open('/kaggle/working/sweep_results.json', 'w') as f:\n",
    "            json.dump(sweep_output, f, indent=2)\n",
    "        print(\"Saved to /kaggle/working/sweep_results.json\")\n",
    "    \n",
    "    # Clean up partial results file\n",
    "    if os.path.exists(PARTIAL_RESULTS_PATH):\n",
    "        os.remove(PARTIAL_RESULTS_PATH)\n",
    "        print(\"Removed partial results file (sweep complete)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce95652",
   "metadata": {},
   "source": [
    "## Phase 3: Architectural Ablations\n",
    "\n",
    "Run these experiments AFTER Phase 2 is complete and the optimal regularization parameters are established. Each ablation isolates one architectural decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "339c828e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Sweep results not found. Using default hyperparameters.\n",
      "\n",
      "======================================================================\n",
      "ABLATION 1: Window Length Sensitivity\n",
      "======================================================================\n",
      "\n",
      "--- Window Length = 60 TR ---\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_184/188700752.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;31m# Regenerate windows with new length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m     \u001b[0mtrain_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregenerate_windows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_subjects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m     \u001b[0mval_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregenerate_windows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_subjects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_184/188700752.py\u001b[0m in \u001b[0;36mregenerate_windows\u001b[0;34m(subject_list, wl, stride)\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mwindows\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mwl\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Ensure correct length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m                 \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_from_timeseries_enhanced\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK_VALUES\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m                 \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                 \u001b[0mgraphs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_184/2342465817.py\u001b[0m in \u001b[0;36mgraph_from_timeseries_enhanced\u001b[0;34m(timeseries, k_values)\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;34m\"\"\"Build enhanced graph with temporal features + multi-scale spatial graphs\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mts_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m     \u001b[0mgraphs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_multiscale_graphs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeseries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_184/2342465817.py\u001b[0m in \u001b[0;36mbuild_multiscale_graphs\u001b[0;34m(ts, k_values)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0mpairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpairs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0mpairs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge_attr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# PHASE 3: ARCHITECTURAL ABLATIONS\n",
    "# ============================================================\n",
    "# Run after Phase 2 sweep is complete\n",
    "# Uses best hyperparameters from sweep\n",
    "\n",
    "import os\n",
    "import gc\n",
    "import json\n",
    "import time\n",
    "\n",
    "# ============================================================\n",
    "# HELPERS (resume-safe + incremental saving)\n",
    "# ============================================================\n",
    "KAGGLE_DIR = '/kaggle/working'\n",
    "LOCAL_DIR = '.'\n",
    "BASE_DIR = KAGGLE_DIR if os.path.exists(KAGGLE_DIR) else LOCAL_DIR\n",
    "ABLATION_RESULTS_PATH = os.path.join(BASE_DIR, 'ablation_results.json')\n",
    "\n",
    "def _coerce_key_int_str(d: dict, key: str):\n",
    "    # Accept both int and str keys from older runs\n",
    "    if key in d:\n",
    "        return d[key]\n",
    "    try:\n",
    "        k_int = int(key)\n",
    "        if k_int in d:\n",
    "            return d[k_int]\n",
    "    except Exception:\n",
    "        pass\n",
    "    return None\n",
    "\n",
    "def save_ablation_results(results: dict):\n",
    "    # Always save to BASE_DIR and also to local working dir if different\n",
    "    with open(os.path.join(BASE_DIR, 'ablation_results.json'), 'w') as f:\n",
    "        json.dump(results, f, indent=2)\n",
    "    if BASE_DIR != LOCAL_DIR:\n",
    "        with open(os.path.join(LOCAL_DIR, 'ablation_results.json'), 'w') as f:\n",
    "            json.dump(results, f, indent=2)\n",
    "\n",
    "def require_var(name: str):\n",
    "    if name not in globals():\n",
    "        raise RuntimeError(f\"Required variable '{name}' is missing. Run the earlier setup cells before Phase 3.\")\n",
    "\n",
    "for _v in [\n",
    "    'torch', 'nn', 'device',\n",
    "    'TemporalSpatialBrainGAT', 'TemporalBranch',\n",
    "    'train_subjects', 'val_subjects', 'subject_data',\n",
    "    'extract_temporal_windows', 'graph_from_timeseries_enhanced', 'K_VALUES',\n",
    "    'PyGDataLoader', 'BATCH_SIZE', 'class_weights',\n",
    "    'train_loader', 'val_loader'\n",
    "]:\n",
    "    require_var(_v)\n",
    "\n",
    "# ============================================================\n",
    "# LOAD/RESUME EXISTING RESULTS (do NOT skip; resume missing)\n",
    "# ============================================================\n",
    "ablation_results = {\n",
    "    'window_length': {},\n",
    "    'temporal_ablation': {},\n",
    "    'multi_scale': {}\n",
    "}\n",
    "\n",
    "if os.path.exists(ABLATION_RESULTS_PATH):\n",
    "    print(\"=\"*70)\n",
    "    print(\"EXISTING (PARTIAL) ABLATION RESULTS FOUND â€” RESUMING\")\n",
    "    print(\"=\"*70)\n",
    "    with open(ABLATION_RESULTS_PATH, 'r') as f:\n",
    "        existing = json.load(f)\n",
    "    if isinstance(existing, dict):\n",
    "        ablation_results['window_length'].update(existing.get('window_length', {}) or {})\n",
    "        ablation_results['temporal_ablation'].update(existing.get('temporal_ablation', {}) or {})\n",
    "        ablation_results['multi_scale'].update(existing.get('multi_scale', {}) or {})\n",
    "\n",
    "# ============================================================\n",
    "# Load best config from sweep (or use defaults if sweep not run)\n",
    "# ============================================================\n",
    "SWEEP_PATH = os.path.join(BASE_DIR, 'sweep_results.json')\n",
    "BEST_HP = None\n",
    "full_model_acc = None\n",
    "\n",
    "if os.path.exists(SWEEP_PATH):\n",
    "    with open(SWEEP_PATH, 'r') as f:\n",
    "        sweep_data = json.load(f)\n",
    "    BEST_HP = sweep_data.get('best_config')\n",
    "    full_model_acc = sweep_data.get('best_val_acc')\n",
    "    print(f\"Using best hyperparameters from sweep: {BEST_HP}\")\n",
    "elif os.path.exists(os.path.join(LOCAL_DIR, 'sweep_results.json')):\n",
    "    with open(os.path.join(LOCAL_DIR, 'sweep_results.json'), 'r') as f:\n",
    "        sweep_data = json.load(f)\n",
    "    BEST_HP = sweep_data.get('best_config')\n",
    "    full_model_acc = sweep_data.get('best_val_acc')\n",
    "    print(f\"Using best hyperparameters from sweep: {BEST_HP}\")\n",
    "else:\n",
    "    BEST_HP = {\n",
    "        'lr': 3e-4,\n",
    "        'weight_decay': 5e-4,\n",
    "        'label_smoothing': 0.1,\n",
    "        'dropout': 0.5,\n",
    "        'hidden_dim': 32,\n",
    "        'temporal_dim': 64,\n",
    "        'heads': 4,\n",
    "        'epochs': 60,\n",
    "        'patience': 20,\n",
    "    }\n",
    "    print(\"WARNING: Sweep results not found. Using default hyperparameters.\")\n",
    "\n",
    "if full_model_acc is None:\n",
    "    # Fall back to any existing stored full_model metric\n",
    "    full_model_acc = ablation_results.get('temporal_ablation', {}).get('full_model')\n",
    "\n",
    "# ============================================================\n",
    "# ABLATION 1: Window Length Sensitivity\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ABLATION 1: Window Length Sensitivity\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "WINDOW_LENGTHS = [60, 80, 100]\n",
    "window_results = ablation_results.get('window_length', {}) or {}\n",
    "\n",
    "def regenerate_windows(subject_list, wl, stride):\n",
    "    graphs, labels, subj_ids = [], [], []\n",
    "    for subj in subject_list:\n",
    "        ts = subject_data[subj]['timeseries']\n",
    "        label = subject_data[subj]['label']\n",
    "        windows = extract_temporal_windows(ts, wl, stride)\n",
    "        for w in windows:\n",
    "            if w.shape[0] == wl:  # Ensure correct length\n",
    "                g = graph_from_timeseries_enhanced(w, k_values=K_VALUES)\n",
    "                g.y = torch.tensor([label], dtype=torch.long)\n",
    "                graphs.append(g)\n",
    "                labels.append(label)\n",
    "                subj_ids.append(subj)\n",
    "    return graphs, labels, subj_ids\n",
    "\n",
    "for wl in WINDOW_LENGTHS:\n",
    "    wl_key = str(wl)\n",
    "    existing_acc = _coerce_key_int_str(window_results, wl_key)\n",
    "    if existing_acc is not None:\n",
    "        print(f\"\\n--- Window Length = {wl} TR ---\")\n",
    "        print(f\"  [SKIP] already have result: {float(existing_acc):.2f}%\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n--- Window Length = {wl} TR ---\")\n",
    "    # Maintain 50% overlap for this ablation\n",
    "    stride = wl // 2\n",
    "\n",
    "    # Regenerate windows with new length\n",
    "    train_g, _, _ = regenerate_windows(train_subjects, wl, stride)\n",
    "    val_g, _, _ = regenerate_windows(val_subjects, wl, stride)\n",
    "\n",
    "    print(f\"  Train: {len(train_g)} windows, Val: {len(val_g)} windows\")\n",
    "    if len(train_g) < max(8, BATCH_SIZE) or len(val_g) < max(8, BATCH_SIZE):\n",
    "        print(\"  [WARN] too few windows to run a stable ablation; recording as NaN\")\n",
    "        window_results[wl_key] = float('nan')\n",
    "        ablation_results['window_length'] = window_results\n",
    "        save_ablation_results(ablation_results)\n",
    "        continue\n",
    "\n",
    "    tr_loader = PyGDataLoader(train_g, batch_size=BATCH_SIZE, shuffle=True, drop_last=False)\n",
    "    vl_loader = PyGDataLoader(val_g, batch_size=BATCH_SIZE, shuffle=False, drop_last=False)\n",
    "\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    model_abl = TemporalSpatialBrainGAT(\n",
    "        in_channels=392,\n",
    "        hidden_dim=BEST_HP['hidden_dim'],\n",
    "        temporal_dim=BEST_HP['temporal_dim'],\n",
    "        num_scales=3,\n",
    "        heads=BEST_HP['heads'],\n",
    "        dropout=BEST_HP['dropout'],\n",
    "        num_classes=2\n",
    "    ).to(device)\n",
    "\n",
    "    # Update temporal branch for new window length\n",
    "    model_abl.temporal_branch = TemporalBranch(input_time_len=wl, hidden_dim=BEST_HP['temporal_dim']).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=BEST_HP['label_smoothing'])\n",
    "    optimizer = torch.optim.AdamW(model_abl.parameters(), lr=BEST_HP['lr'], weight_decay=BEST_HP['weight_decay'])\n",
    "    scaler = torch.amp.GradScaler('cuda')\n",
    "\n",
    "    best_val = 0.0\n",
    "    for epoch in range(1, 41):  # Reduced epochs for ablation\n",
    "        model_abl.train()\n",
    "        optimizer.zero_grad()\n",
    "        for i, data in enumerate(tr_loader):\n",
    "            data = data.to(device)\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                out = model_abl(data)\n",
    "                loss = criterion(out, data.y) / 8\n",
    "            scaler.scale(loss).backward()\n",
    "            if (i + 1) % 8 == 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "        model_abl.eval()\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for data in vl_loader:\n",
    "                data = data.to(device)\n",
    "                out = model_abl(data)\n",
    "                correct += (out.argmax(1) == data.y).sum().item()\n",
    "                total += data.num_graphs\n",
    "        val_acc = 100.0 * correct / total if total > 0 else 0.0\n",
    "        if val_acc > best_val:\n",
    "            best_val = val_acc\n",
    "\n",
    "    window_results[wl_key] = float(best_val)\n",
    "    ablation_results['window_length'] = window_results\n",
    "    print(f\"  Best Val Acc: {best_val:.2f}%\")\n",
    "    save_ablation_results(ablation_results)\n",
    "\n",
    "    del model_abl, tr_loader, vl_loader, train_g, val_g\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "print(\"\\n--- Window Length Summary ---\")\n",
    "for wl in WINDOW_LENGTHS:\n",
    "    k = str(wl)\n",
    "    acc = _coerce_key_int_str(window_results, k)\n",
    "    if acc is None:\n",
    "        print(f\"  {wl} TR: [missing]\")\n",
    "    else:\n",
    "        try:\n",
    "            print(f\"  {wl} TR: {float(acc):.2f}%\")\n",
    "        except Exception:\n",
    "            print(f\"  {wl} TR: {acc}\")\n",
    "\n",
    "# ============================================================\n",
    "# ABLATION 2: Temporal Module Ablation\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ABLATION 2: Temporal Module Ablation\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "class SpatialOnlyBrainGAT(nn.Module):\n",
    "    \"\"\"Baseline without temporal branch\"\"\"\n",
    "    def __init__(self, in_channels, hidden_dim=32, num_scales=3, heads=4, dropout=0.5, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.num_scales = num_scales\n",
    "        self.spatial_branch = MultiScaleSpatialBranch(in_channels, hidden_dim, num_scales, heads, dropout)\n",
    "        total_dim = num_scales * hidden_dim * 2  # No temporal\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(total_dim, hidden_dim * 4), nn.BatchNorm1d(hidden_dim * 4), nn.ReLU(), nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim * 4, hidden_dim * 2), nn.BatchNorm1d(hidden_dim * 2), nn.ReLU(), nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim * 2, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, data):\n",
    "        x = data.x\n",
    "        batch = data.batch if hasattr(data, 'batch') else torch.zeros(x.size(0), dtype=torch.long, device=x.device)\n",
    "        edge_indices = [getattr(data, f'edge_index_{i}') for i in range(self.num_scales)]\n",
    "        edge_attrs = [getattr(data, f'edge_attr_{i}') for i in range(self.num_scales)]\n",
    "        spatial_feats = self.spatial_branch(x, edge_indices, edge_attrs, batch)\n",
    "        return self.classifier(spatial_feats)\n",
    "\n",
    "temp_abl = ablation_results.get('temporal_ablation', {}) or {}\n",
    "have_spatial_only = temp_abl.get('spatial_only') is not None\n",
    "have_full = temp_abl.get('full_model') is not None or (full_model_acc is not None)\n",
    "\n",
    "if not have_spatial_only:\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    model_spatial = SpatialOnlyBrainGAT(\n",
    "        in_channels=392,\n",
    "        hidden_dim=BEST_HP['hidden_dim'],\n",
    "        num_scales=3,\n",
    "        heads=BEST_HP['heads'],\n",
    "        dropout=BEST_HP['dropout'],\n",
    "        num_classes=2\n",
    "    ).to(device)\n",
    "\n",
    "    print(f\"Spatial-only params: {sum(p.numel() for p in model_spatial.parameters()):,}\")\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=BEST_HP['label_smoothing'])\n",
    "    optimizer = torch.optim.AdamW(model_spatial.parameters(), lr=BEST_HP['lr'], weight_decay=BEST_HP['weight_decay'])\n",
    "    scaler = torch.amp.GradScaler('cuda')\n",
    "\n",
    "    best_spatial_val = 0.0\n",
    "    for epoch in range(1, 41):\n",
    "        model_spatial.train()\n",
    "        optimizer.zero_grad()\n",
    "        for i, data in enumerate(train_loader):\n",
    "            data = data.to(device)\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                out = model_spatial(data)\n",
    "                loss = criterion(out, data.y) / 8\n",
    "            scaler.scale(loss).backward()\n",
    "            if (i + 1) % 8 == 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "        model_spatial.eval()\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for data in val_loader:\n",
    "                data = data.to(device)\n",
    "                out = model_spatial(data)\n",
    "                correct += (out.argmax(1) == data.y).sum().item()\n",
    "                total += data.num_graphs\n",
    "        val_acc = 100.0 * correct / total if total > 0 else 0.0\n",
    "        if val_acc > best_spatial_val:\n",
    "            best_spatial_val = val_acc\n",
    "\n",
    "    temp_abl['spatial_only'] = float(best_spatial_val)\n",
    "    ablation_results['temporal_ablation'] = temp_abl\n",
    "    print(f\"Spatial-only Best Val Acc: {best_spatial_val:.2f}%\")\n",
    "    save_ablation_results(ablation_results)\n",
    "else:\n",
    "    print(f\"[SKIP] Spatial-only already present: {float(temp_abl.get('spatial_only')):.2f}%\")\n",
    "\n",
    "if temp_abl.get('full_model') is None and full_model_acc is not None:\n",
    "    temp_abl['full_model'] = float(full_model_acc)\n",
    "    ablation_results['temporal_ablation'] = temp_abl\n",
    "    save_ablation_results(ablation_results)\n",
    "\n",
    "# ============================================================\n",
    "# ABLATION 3: Multi-Scale Ablation\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ABLATION 3: Multi-Scale Ablation\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "scale_configs = {\n",
    "    'single_k30': [30],\n",
    "    'two_scale': [10, 100],\n",
    "    'full': [10, 30, 100],\n",
    "}\n",
    "\n",
    "scale_results = ablation_results.get('multi_scale', {}) or {}\n",
    "\n",
    "for scale_name, k_vals in scale_configs.items():\n",
    "    if scale_name in scale_results:\n",
    "        print(f\"\\n--- {scale_name}: k={k_vals} ---\")\n",
    "        print(f\"  [SKIP] already have result: {float(scale_results[scale_name]):.2f}%\")\n",
    "        continue\n",
    "\n",
    "    print(f\"\\n--- {scale_name}: k={k_vals} ---\")\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    model_scale = TemporalSpatialBrainGAT(\n",
    "        in_channels=392,\n",
    "        hidden_dim=BEST_HP['hidden_dim'],\n",
    "        temporal_dim=BEST_HP['temporal_dim'],\n",
    "        num_scales=len(k_vals),\n",
    "        heads=BEST_HP['heads'],\n",
    "        dropout=BEST_HP['dropout'],\n",
    "        num_classes=2,\n",
    "    ).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights, label_smoothing=BEST_HP['label_smoothing'])\n",
    "    optimizer = torch.optim.AdamW(model_scale.parameters(), lr=BEST_HP['lr'], weight_decay=BEST_HP['weight_decay'])\n",
    "    scaler = torch.amp.GradScaler('cuda')\n",
    "\n",
    "    # Note: This uses pre-generated graphs with k=[10,30,100] and simply slices scales\n",
    "    best_scale_val = 0.0\n",
    "    for epoch in range(1, 41):\n",
    "        model_scale.train()\n",
    "        optimizer.zero_grad()\n",
    "        for i, data in enumerate(train_loader):\n",
    "            data = data.to(device)\n",
    "            with torch.amp.autocast('cuda'):\n",
    "                out = model_scale(data)\n",
    "                loss = criterion(out, data.y) / 8\n",
    "            scaler.scale(loss).backward()\n",
    "            if (i + 1) % 8 == 0:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "        model_scale.eval()\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for data in val_loader:\n",
    "                data = data.to(device)\n",
    "                out = model_scale(data)\n",
    "                correct += (out.argmax(1) == data.y).sum().item()\n",
    "                total += data.num_graphs\n",
    "        val_acc = 100.0 * correct / total if total > 0 else 0.0\n",
    "        if val_acc > best_scale_val:\n",
    "            best_scale_val = val_acc\n",
    "\n",
    "    scale_results[scale_name] = float(best_scale_val)\n",
    "    ablation_results['multi_scale'] = scale_results\n",
    "    print(f\"  Best Val Acc: {best_scale_val:.2f}%\")\n",
    "    save_ablation_results(ablation_results)\n",
    "\n",
    "# ============================================================\n",
    "# FINAL SUMMARY (what's currently available)\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PHASE 3 ABLATION SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n1. Window Length Sensitivity:\")\n",
    "for wl in WINDOW_LENGTHS:\n",
    "    k = str(wl)\n",
    "    acc = _coerce_key_int_str(ablation_results.get('window_length', {}), k)\n",
    "    if acc is None:\n",
    "        print(f\"   {wl} TR: [missing]\")\n",
    "    else:\n",
    "        print(f\"   {wl} TR: {float(acc):.2f}%\")\n",
    "\n",
    "print(\"\\n2. Temporal Module Contribution:\")\n",
    "full_v = ablation_results.get('temporal_ablation', {}).get('full_model')\n",
    "spatial_v = ablation_results.get('temporal_ablation', {}).get('spatial_only')\n",
    "print(f\"   Full model: {float(full_v) if full_v is not None else float('nan'):.2f}%\")\n",
    "print(f\"   Spatial only: {float(spatial_v) if spatial_v is not None else float('nan'):.2f}%\")\n",
    "if (full_v is not None) and (spatial_v is not None):\n",
    "    print(f\"   Temporal contribution: {float(full_v) - float(spatial_v):+.2f}%\")\n",
    "\n",
    "print(\"\\n3. Multi-Scale Contribution:\")\n",
    "for name in ['single_k30', 'two_scale', 'full']:\n",
    "    acc = ablation_results.get('multi_scale', {}).get(name)\n",
    "    if acc is None:\n",
    "        print(f\"   {name}: [missing]\")\n",
    "    else:\n",
    "        print(f\"   {name}: {float(acc):.2f}%\")\n",
    "\n",
    "print(f\"\\nSaved to {ABLATION_RESULTS_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b20056e",
   "metadata": {},
   "source": [
    "# ðŸ“Š TODO: Professor Requirements Implementation\n",
    "\n",
    "## ðŸŽ¯ Missing Components for Final Report\n",
    "\n",
    "The following sections need to be implemented for the final internship report submission:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. ðŸ§  fMRI Response Visualization (ASD vs Healthy Controls)\n",
    "\n",
    "**Status:** âš ï¸ TO BE IMPLEMENTED\n",
    "\n",
    "**Requirements:**\n",
    "- Visualization of ASD and healthy control fMRI response images\n",
    "- Temporal signal comparisons between groups\n",
    "- ROI-level activation patterns\n",
    "\n",
    "**Implementation Plan:**\n",
    "```python\n",
    "# TODO: Add the following visualization functions:\n",
    "\n",
    "def visualize_fmri_timeseries_comparison():\n",
    "    \"\"\"\n",
    "    Create side-by-side plots showing:\n",
    "    - Representative fMRI time series for ASD subjects\n",
    "    - Representative fMRI time series for healthy controls\n",
    "    - Highlight key ROIs showing group differences\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def plot_group_connectivity_matrices():\n",
    "    \"\"\"\n",
    "    Generate connectivity matrix visualizations:\n",
    "    - Average correlation matrix for ASD group\n",
    "    - Average correlation matrix for control group  \n",
    "    - Difference map (ASD - Control)\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def create_temporal_dynamics_animation():\n",
    "    \"\"\"\n",
    "    Create animated plots showing temporal evolution:\n",
    "    - Window-based connectivity changes over time\n",
    "    - Group-level differences in temporal patterns\n",
    "    \"\"\"\n",
    "    pass\n",
    "```\n",
    "\n",
    "**Required Libraries:**\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from matplotlib.animation import FuncAnimation\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bae4c7a",
   "metadata": {},
   "source": [
    "### 2. ðŸ“ˆ Results Section with Graphs and Tables\n",
    "\n",
    "**Status:** âš ï¸ TO BE IMPLEMENTED\n",
    "\n",
    "**Requirements:**\n",
    "- Training/validation curves\n",
    "- Confusion matrices for all test sets\n",
    "- Performance comparison tables\n",
    "- Hyperparameter sensitivity analysis\n",
    "\n",
    "**Implementation Plan:**\n",
    "```python\n",
    "# TODO: Add comprehensive results visualization\n",
    "\n",
    "def plot_training_curves(train_losses, val_losses, train_accs, val_accs):\n",
    "    \"\"\"\n",
    "    Create professional training curves plot:\n",
    "    - Loss curves (train vs validation)\n",
    "    - Accuracy curves (train vs validation)  \n",
    "    - Save as high-quality figures for report\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def create_confusion_matrices(y_true_val, y_pred_val, y_true_test1, y_pred_test1, y_true_test2, y_pred_test2):\n",
    "    \"\"\"\n",
    "    Generate confusion matrices for triple validation:\n",
    "    - Validation set confusion matrix\n",
    "    - Test1 set confusion matrix\n",
    "    - Test2 set confusion matrix\n",
    "    - Combined subplot with consistent formatting\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def generate_performance_table():\n",
    "    \"\"\"\n",
    "    Create comprehensive performance metrics table:\n",
    "    - Accuracy, Precision, Recall, F1-Score, AUC-ROC\n",
    "    - Across Validation, Test1, Test2 sets\n",
    "    - Export as LaTeX table format\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def plot_hyperparameter_heatmap(grid_search_results):\n",
    "    \"\"\"\n",
    "    Visualize hyperparameter search results:\n",
    "    - Heatmap of validation accuracy vs hyperparameters\n",
    "    - Identify optimal parameter combinations\n",
    "    \"\"\"\n",
    "    pass\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41cef4f0",
   "metadata": {},
   "source": [
    "### 3. ðŸ™ GitHub Repository Setup\n",
    "\n",
    "**Status:** âš ï¸ TO BE COMPLETED  \n",
    "\n",
    "**Requirements:**\n",
    "- Upload complete codebase to GitHub\n",
    "- Ensure reproducibility and documentation\n",
    "- Add link to final report\n",
    "\n",
    "**Action Items:**\n",
    "1. **Repository Structure:**\n",
    "   ```\n",
    "   ABIDE-BrainGAT-Evolution/\n",
    "   â”œâ”€â”€ notebooks/\n",
    "   â”‚   â””â”€â”€ BrainGAT_Evolution.ipynb\n",
    "   â”œâ”€â”€ docs/\n",
    "   â”‚   â”œâ”€â”€ internship_report_aniruddha_roy.pdf\n",
    "   â”‚   â”œâ”€â”€ BrainGAT_Evolution_Architecture.md\n",
    "   â”‚   â””â”€â”€ DATA_LEAKAGE_FIX.md\n",
    "   â”œâ”€â”€ models/\n",
    "   â”‚   â””â”€â”€ saved_models/\n",
    "   â”œâ”€â”€ data/\n",
    "   â”‚   â””â”€â”€ abide_preprocessing/\n",
    "   â”œâ”€â”€ visualizations/\n",
    "   â”‚   â”œâ”€â”€ training_curves.png\n",
    "   â”‚   â”œâ”€â”€ confusion_matrices.png\n",
    "   â”‚   â”œâ”€â”€ fmri_timeseries_comparison.png\n",
    "   â”‚   â””â”€â”€ connectivity_matrices.png\n",
    "   â”œâ”€â”€ environment.yml\n",
    "   â”œâ”€â”€ requirements.txt\n",
    "   â””â”€â”€ README.md\n",
    "   ```\n",
    "\n",
    "2. **Documentation Requirements:**\n",
    "   - Comprehensive README with setup instructions\n",
    "   - Installation and environment setup guide\n",
    "   - Usage examples and tutorials\n",
    "   - Citation information\n",
    "\n",
    "3. **Repository Link for Report:**\n",
    "   ```latex\n",
    "   \\textbf{Repository:} \\texttt{https://github.com/[USERNAME]/ABIDE-BrainGAT-Evolution}\n",
    "   ```\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸš€ Implementation Priority\n",
    "\n",
    "1. **High Priority (Before Final Run):**\n",
    "   - fMRI visualization functions\n",
    "   - Results plotting infrastructure\n",
    "   - Performance metrics calculation\n",
    "\n",
    "2. **Medium Priority (After Final Run):**\n",
    "   - Complete results section with actual numbers\n",
    "   - GitHub repository setup and documentation\n",
    "\n",
    "3. **Final Steps:**\n",
    "   - Generate all figures and tables\n",
    "   - Update report with GitHub link\n",
    "   - Ensure reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bd7ca119",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Visualization functions ready for implementation!\n",
      "ðŸ”„ Run these after final model training to generate all required figures.\n"
     ]
    }
   ],
   "source": [
    "# ðŸ“Š IMPLEMENTATION TEMPLATE: Visualization Functions\n",
    "# These functions can be implemented after the final training run\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "def setup_plot_style():\n",
    "    \"\"\"Setup publication-quality plot style\"\"\"\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    plt.rcParams.update({\n",
    "        'figure.figsize': (12, 8),\n",
    "        'font.size': 12,\n",
    "        'axes.titlesize': 14,\n",
    "        'axes.labelsize': 12,\n",
    "        'xtick.labelsize': 10,\n",
    "        'ytick.labelsize': 10,\n",
    "        'legend.fontsize': 10,\n",
    "        'figure.dpi': 300,\n",
    "        'savefig.dpi': 300,\n",
    "        'savefig.bbox': 'tight'\n",
    "    })\n",
    "\n",
    "def visualize_fmri_timeseries_comparison(asd_data, control_data, roi_names=None, n_rois=10, save_path=None):\n",
    "    \"\"\"\n",
    "    Create comparison plots of fMRI time series between ASD and control groups\n",
    "    \n",
    "    Args:\n",
    "        asd_data: Shape (n_subjects_asd, n_timepoints, n_rois)\n",
    "        control_data: Shape (n_subjects_control, n_timepoints, n_rois) \n",
    "        roi_names: List of ROI names (optional)\n",
    "        n_rois: Number of ROIs to visualize\n",
    "        save_path: Path to save figure\n",
    "    \"\"\"\n",
    "    setup_plot_style()\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 1, figsize=(15, 10))\n",
    "    \n",
    "    # Select representative subjects and ROIs\n",
    "    asd_subject = asd_data[0]  # First ASD subject\n",
    "    control_subject = control_data[0]  # First control subject\n",
    "    \n",
    "    # Plot ASD time series\n",
    "    for i in range(min(n_rois, asd_subject.shape[1])):\n",
    "        axes[0].plot(asd_subject[:, i], alpha=0.7, linewidth=0.8)\n",
    "    axes[0].set_title('ASD Subject - fMRI Time Series', fontsize=14, fontweight='bold')\n",
    "    axes[0].set_ylabel('Signal Intensity (z-score)', fontsize=12)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot Control time series  \n",
    "    for i in range(min(n_rois, control_subject.shape[1])):\n",
    "        axes[1].plot(control_subject[:, i], alpha=0.7, linewidth=0.8)\n",
    "    axes[1].set_title('Healthy Control Subject - fMRI Time Series', fontsize=14, fontweight='bold')\n",
    "    axes[1].set_xlabel('Time Points (TRs)', fontsize=12)\n",
    "    axes[1].set_ylabel('Signal Intensity (z-score)', fontsize=12)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"fMRI time series comparison saved to: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def plot_connectivity_matrices(asd_corr_matrices, control_corr_matrices, save_path=None):\n",
    "    \"\"\"\n",
    "    Plot average connectivity matrices and difference map\n",
    "    \n",
    "    Args:\n",
    "        asd_corr_matrices: List of correlation matrices for ASD subjects\n",
    "        control_corr_matrices: List of correlation matrices for control subjects\n",
    "        save_path: Path to save figure\n",
    "    \"\"\"\n",
    "    setup_plot_style()\n",
    "    \n",
    "    # Calculate group averages\n",
    "    asd_avg = np.mean(asd_corr_matrices, axis=0)\n",
    "    control_avg = np.mean(control_corr_matrices, axis=0)\n",
    "    diff_matrix = asd_avg - control_avg\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    # ASD connectivity\n",
    "    im1 = axes[0].imshow(asd_avg, cmap='RdBu_r', vmin=-1, vmax=1)\n",
    "    axes[0].set_title('ASD Group - Average Connectivity', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_xlabel('ROI Index')\n",
    "    axes[0].set_ylabel('ROI Index')\n",
    "    plt.colorbar(im1, ax=axes[0], fraction=0.046, pad=0.04)\n",
    "    \n",
    "    # Control connectivity\n",
    "    im2 = axes[1].imshow(control_avg, cmap='RdBu_r', vmin=-1, vmax=1)\n",
    "    axes[1].set_title('Control Group - Average Connectivity', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_xlabel('ROI Index')\n",
    "    plt.colorbar(im2, ax=axes[1], fraction=0.046, pad=0.04)\n",
    "    \n",
    "    # Difference map\n",
    "    vmax_diff = np.max(np.abs(diff_matrix))\n",
    "    im3 = axes[2].imshow(diff_matrix, cmap='RdBu_r', vmin=-vmax_diff, vmax=vmax_diff)\n",
    "    axes[2].set_title('Difference Map (ASD - Control)', fontsize=12, fontweight='bold')\n",
    "    axes[2].set_xlabel('ROI Index')\n",
    "    plt.colorbar(im3, ax=axes[2], fraction=0.046, pad=0.04)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"Connectivity matrices saved to: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def plot_training_curves(train_losses, val_losses, train_accs, val_accs, save_path=None):\n",
    "    \"\"\"\n",
    "    Plot training and validation curves\n",
    "    \n",
    "    Args:\n",
    "        train_losses: List of training losses per epoch\n",
    "        val_losses: List of validation losses per epoch\n",
    "        train_accs: List of training accuracies per epoch\n",
    "        val_accs: List of validation accuracies per epoch\n",
    "        save_path: Path to save figure\n",
    "    \"\"\"\n",
    "    setup_plot_style()\n",
    "    \n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Loss curves\n",
    "    ax1.plot(epochs, train_losses, 'b-', linewidth=2, label='Training Loss')\n",
    "    ax1.plot(epochs, val_losses, 'r-', linewidth=2, label='Validation Loss')\n",
    "    ax1.set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Accuracy curves\n",
    "    ax2.plot(epochs, train_accs, 'b-', linewidth=2, label='Training Accuracy')\n",
    "    ax2.plot(epochs, val_accs, 'r-', linewidth=2, label='Validation Accuracy')\n",
    "    ax2.set_title('Training and Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy (%)')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"Training curves saved to: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def create_confusion_matrices(y_true_sets, y_pred_sets, set_names, save_path=None):\n",
    "    \"\"\"\n",
    "    Create confusion matrices for multiple test sets\n",
    "    \n",
    "    Args:\n",
    "        y_true_sets: List of true labels for each set\n",
    "        y_pred_sets: List of predicted labels for each set  \n",
    "        set_names: List of set names ['Validation', 'Test1', 'Test2']\n",
    "        save_path: Path to save figure\n",
    "    \"\"\"\n",
    "    setup_plot_style()\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    \n",
    "    for i, (y_true, y_pred, name) in enumerate(zip(y_true_sets, y_pred_sets, set_names)):\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        \n",
    "        sns.heatmap(cm_normalized, annot=True, fmt='.3f', cmap='Blues', \n",
    "                   ax=axes[i], cbar_kws={'shrink': 0.8})\n",
    "        axes[i].set_title(f'{name} Set', fontsize=12, fontweight='bold')\n",
    "        axes[i].set_xlabel('Predicted Label')\n",
    "        axes[i].set_ylabel('True Label')\n",
    "        axes[i].set_xticklabels(['Control', 'ASD'])\n",
    "        axes[i].set_yticklabels(['Control', 'ASD'])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "        print(f\"Confusion matrices saved to: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# TODO: Call these functions after final training run with actual data\n",
    "print(\"ðŸ“Š Visualization functions ready for implementation!\")\n",
    "print(\"ðŸ”„ Run these after final model training to generate all required figures.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
