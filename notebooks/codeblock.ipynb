{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41e59b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GRUCell import added successfully!\n"
     ]
    }
   ],
   "source": [
    "# Fix Missing Import\n",
    "from torch.nn import GRUCell\n",
    "print(\"✅ GRUCell import added successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c30b6fc",
   "metadata": {},
   "source": [
    "# Advanced Brain GNN Models for Neuroimaging Analysis\n",
    "\n",
    "Implementation of five state-of-the-art Graph Neural Network architectures for brain connectivity analysis:\n",
    "\n",
    "1. **BrainGNN** - ROI-aware convolutions with interpretable pooling for biomarker discovery\n",
    "2. **Local-to-Global GNN (LG-GNN)** - Hierarchical learning from ROI to subject relationships\n",
    "3. **Dynamic Multi-Site GCN (DG-DMSGCN)** - Multi-site adaptation with temporal features\n",
    "4. **IFC-GNN** - Temporal functional connectivity interactions with deep feature selection\n",
    "5. **RAGNN** - Hemispheric asymmetry learning for EEG-based analysis\n",
    "\n",
    "Each model addresses specific challenges in brain connectivity analysis and neurological disorder classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26d47ebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moew/Documents/ABIDE/.venv-py312/lib/python3.12/site-packages/torch_geometric/typing.py:68: UserWarning: An issue occurred while importing 'pyg-lib'. Disabling its usage. Stacktrace: /home/moew/Documents/ABIDE/.venv-py312/lib/python3.12/site-packages/libpyg.so: undefined symbol: _ZN3c1010Dispatcher17runRecordFunctionERN2at14RecordFunctionESt17reference_wrapperIKNS_14FunctionSchemaEENS_11DispatchKeyE\n",
      "  warnings.warn(f\"An issue occurred while importing 'pyg-lib'. \"\n",
      "/home/moew/Documents/ABIDE/.venv-py312/lib/python3.12/site-packages/torch_geometric/typing.py:86: UserWarning: An issue occurred while importing 'torch-scatter'. Disabling its usage. Stacktrace: /home/moew/Documents/ABIDE/.venv-py312/lib/python3.12/site-packages/torch_scatter/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-scatter'. \"\n",
      "/home/moew/Documents/ABIDE/.venv-py312/lib/python3.12/site-packages/torch_geometric/typing.py:97: UserWarning: An issue occurred while importing 'torch-cluster'. Disabling its usage. Stacktrace: /home/moew/Documents/ABIDE/.venv-py312/lib/python3.12/site-packages/torch_cluster/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-cluster'. \"\n",
      "/home/moew/Documents/ABIDE/.venv-py312/lib/python3.12/site-packages/torch_geometric/typing.py:124: UserWarning: An issue occurred while importing 'torch-sparse'. Disabling its usage. Stacktrace: /home/moew/Documents/ABIDE/.venv-py312/lib/python3.12/site-packages/torch_sparse/_version_cuda.so: undefined symbol: _ZN5torch3jit17parseSchemaOrNameERKSs\n",
      "  warnings.warn(f\"An issue occurred while importing 'torch-sparse'. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "PyTorch version: 2.5.1+cu121\n",
      "CUDA available: True\n",
      "CUDA version: 12.1\n",
      "GPU: NVIDIA GeForce RTX 2050\n"
     ]
    }
   ],
   "source": [
    "# Core Dependencies and Imports\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import GRUCell\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool, global_max_pool, GATConv, SAGEConv\n",
    "from torch_geometric.data import Data, Batch\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set device and random seeds for reproducibility\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5105715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enhanced data loading utilities defined successfully!\n",
      "Now supports both connectivity matrices and time series data!\n"
     ]
    }
   ],
   "source": [
    "# Data Loading and Preprocessing Functions\n",
    "class ABIDEDataset(Dataset):\n",
    "    \"\"\"ABIDE Dataset for brain connectivity analysis\"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir: str, phenotypic_file: str = None):\n",
    "        self.data_dir = data_dir\n",
    "        self.phenotypic_file = phenotypic_file\n",
    "        self.connectivity_matrices = []\n",
    "        self.time_series_data = []  # Store original time series\n",
    "        self.labels = []\n",
    "        self.subjects = []\n",
    "        self.sites = []\n",
    "        self.demographic_features = []\n",
    "        self.load_data()\n",
    "        \n",
    "    def load_data(self):\n",
    "        \"\"\"Load time series data and compute connectivity matrices\"\"\"\n",
    "        print(\"Loading ABIDE time series data...\")\n",
    "        \n",
    "        # Load phenotypic data if available\n",
    "        phenotypic_data = None\n",
    "        if self.phenotypic_file and os.path.exists(self.phenotypic_file):\n",
    "            phenotypic_data = pd.read_csv(self.phenotypic_file)\n",
    "            print(f\"Loaded phenotypic data with {len(phenotypic_data)} subjects\")\n",
    "        \n",
    "        # Process ROI time series files\n",
    "        roi_dir = os.path.join(self.data_dir, 'Outputs', 'cpac', 'nofilt_noglobal', 'rois_cc400')\n",
    "        if not os.path.exists(roi_dir):\n",
    "            raise FileNotFoundError(f\"ROI directory not found: {roi_dir}\")\n",
    "            \n",
    "        roi_files = [f for f in os.listdir(roi_dir) if f.endswith('.1D')]\n",
    "        print(f\"Found {len(roi_files)} time series files\")\n",
    "        \n",
    "        for roi_file in roi_files:\n",
    "            try:\n",
    "                # Extract subject information from filename\n",
    "                parts = roi_file.replace('_rois_cc400.1D', '').split('_')\n",
    "                if len(parts) >= 2:\n",
    "                    site = parts[0]\n",
    "                    subject_id = '_'.join(parts[1:])\n",
    "                else:\n",
    "                    site = 'Unknown'\n",
    "                    subject_id = parts[0]\n",
    "                \n",
    "                # Load time series data\n",
    "                file_path = os.path.join(roi_dir, roi_file)\n",
    "                time_series = np.loadtxt(file_path)\n",
    "                \n",
    "                # Handle different data formats\n",
    "                if time_series.ndim == 1:\n",
    "                    # Single time point - reshape to (1, n_rois)\n",
    "                    time_series = time_series.reshape(1, -1)\n",
    "                \n",
    "                # Calculate connectivity matrix from time series\n",
    "                # time_series shape: (n_timepoints, n_rois)\n",
    "                connectivity_matrix = np.corrcoef(time_series.T)  # Correlation between ROIs\n",
    "                \n",
    "                # Handle NaN values that might occur with constant time series\n",
    "                connectivity_matrix = np.nan_to_num(connectivity_matrix, nan=0.0)\n",
    "                \n",
    "                # Ensure diagonal is 1\n",
    "                np.fill_diagonal(connectivity_matrix, 1.0)\n",
    "                \n",
    "                # Get phenotypic information\n",
    "                dx_group = 1  # Default: ASD\n",
    "                age = 25.0    # Default age\n",
    "                sex = 1       # Default: Male\n",
    "                \n",
    "                if phenotypic_data is not None:\n",
    "                    # Try to match subject\n",
    "                    subject_matches = phenotypic_data[\n",
    "                        (phenotypic_data['SITE_ID'] == site) & \n",
    "                        (phenotypic_data['SUB_ID'].astype(str) == subject_id)\n",
    "                    ]\n",
    "                    if not subject_matches.empty:\n",
    "                        subject_info = subject_matches.iloc[0]\n",
    "                        dx_group = subject_info.get('DX_GROUP', 1)\n",
    "                        age = subject_info.get('AGE_AT_SCAN', 25.0)\n",
    "                        sex = subject_info.get('SEX', 1)\n",
    "                \n",
    "                # Store data\n",
    "                self.connectivity_matrices.append(connectivity_matrix)\n",
    "                self.time_series_data.append(time_series)  # Store original time series\n",
    "                self.labels.append(dx_group - 1)  # Convert to 0/1\n",
    "                self.subjects.append(f\"{site}_{subject_id}\")\n",
    "                self.sites.append(site)\n",
    "                self.demographic_features.append([age, sex])\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {roi_file}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        print(f\"Successfully loaded {len(self.connectivity_matrices)} subjects\")\n",
    "        print(f\"Time series shape: {self.time_series_data[0].shape if self.time_series_data else 'N/A'}\")\n",
    "        print(f\"Connectivity matrix shape: {self.connectivity_matrices[0].shape if self.connectivity_matrices else 'N/A'}\")\n",
    "        print(f\"Label distribution: {np.bincount(self.labels)}\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.connectivity_matrices)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        connectivity = torch.FloatTensor(self.connectivity_matrices[idx])\n",
    "        time_series = torch.FloatTensor(self.time_series_data[idx])\n",
    "        label = torch.LongTensor([self.labels[idx]])\n",
    "        demographics = torch.FloatTensor(self.demographic_features[idx])\n",
    "        site = self.sites[idx]\n",
    "        \n",
    "        return {\n",
    "            'connectivity': connectivity,\n",
    "            'time_series': time_series,  # Original time series data\n",
    "            'label': label,\n",
    "            'demographics': demographics,\n",
    "            'site': site,\n",
    "            'subject': self.subjects[idx]\n",
    "        }\n",
    "\n",
    "def create_graph_from_connectivity(connectivity_matrix, threshold=0.3):\n",
    "    \"\"\"Create PyTorch Geometric graph from connectivity matrix\"\"\"\n",
    "    n_nodes = connectivity_matrix.shape[0]\n",
    "    \n",
    "    # Apply threshold and create adjacency matrix\n",
    "    adj_matrix = (np.abs(connectivity_matrix) > threshold).astype(float)\n",
    "    \n",
    "    # Get edge indices\n",
    "    edge_index = np.where(adj_matrix)\n",
    "    edge_index = torch.LongTensor(np.vstack(edge_index))\n",
    "    \n",
    "    # Edge weights\n",
    "    edge_weights = connectivity_matrix[edge_index[0], edge_index[1]]\n",
    "    edge_attr = torch.FloatTensor(edge_weights).unsqueeze(1)\n",
    "    \n",
    "    # Node features (ROI indices and connectivity statistics)\n",
    "    node_features = []\n",
    "    for i in range(n_nodes):\n",
    "        roi_connectivity = connectivity_matrix[i]\n",
    "        features = [\n",
    "            i / n_nodes,  # Normalized ROI index\n",
    "            np.mean(roi_connectivity),  # Mean connectivity\n",
    "            np.std(roi_connectivity),   # Std connectivity\n",
    "            np.sum(roi_connectivity > threshold)  # Degree\n",
    "        ]\n",
    "        node_features.append(features)\n",
    "    \n",
    "    node_features = torch.FloatTensor(node_features)\n",
    "    \n",
    "    return Data(x=node_features, edge_index=edge_index, edge_attr=edge_attr)\n",
    "\n",
    "def create_graph_from_timeseries(time_series, connectivity_matrix, threshold=0.3):\n",
    "    \"\"\"Create enhanced graph using both time series and connectivity information\"\"\"\n",
    "    n_timepoints, n_rois = time_series.shape\n",
    "    \n",
    "    # Apply threshold and create adjacency matrix\n",
    "    adj_matrix = (np.abs(connectivity_matrix) > threshold).astype(float)\n",
    "    \n",
    "    # Get edge indices\n",
    "    edge_index = np.where(adj_matrix)\n",
    "    edge_index = torch.LongTensor(np.vstack(edge_index))\n",
    "    \n",
    "    # Edge weights from connectivity\n",
    "    edge_weights = connectivity_matrix[edge_index[0], edge_index[1]]\n",
    "    edge_attr = torch.FloatTensor(edge_weights).unsqueeze(1)\n",
    "    \n",
    "    # Enhanced node features using time series statistics\n",
    "    node_features = []\n",
    "    for i in range(n_rois):\n",
    "        roi_timeseries = time_series[:, i]\n",
    "        roi_connectivity = connectivity_matrix[i]\n",
    "        \n",
    "        # Time series features\n",
    "        mean_signal = np.mean(roi_timeseries)\n",
    "        std_signal = np.std(roi_timeseries)\n",
    "        max_signal = np.max(roi_timeseries)\n",
    "        min_signal = np.min(roi_timeseries)\n",
    "        \n",
    "        # Connectivity features\n",
    "        mean_connectivity = np.mean(roi_connectivity)\n",
    "        std_connectivity = np.std(roi_connectivity)\n",
    "        degree = np.sum(roi_connectivity > threshold)\n",
    "        \n",
    "        features = [\n",
    "            i / n_rois,  # Normalized ROI index\n",
    "            mean_signal,\n",
    "            std_signal,\n",
    "            max_signal,\n",
    "            min_signal,\n",
    "            mean_connectivity,\n",
    "            std_connectivity,\n",
    "            degree / n_rois  # Normalized degree\n",
    "        ]\n",
    "        node_features.append(features)\n",
    "    \n",
    "    node_features = torch.FloatTensor(node_features)\n",
    "    \n",
    "    return Data(x=node_features, edge_index=edge_index, edge_attr=edge_attr)\n",
    "\n",
    "print(\"Enhanced data loading utilities defined successfully!\")\n",
    "print(\"Now supports both connectivity matrices and time series data!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4db874f",
   "metadata": {},
   "source": [
    "## Model 1: BrainGNN - ROI-aware Graph Neural Network\n",
    "\n",
    "BrainGNN introduces ROI-aware convolutions and interpretable pooling specifically designed for brain connectivity analysis. It focuses on identifying disease-relevant biomarkers through specialized graph operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a34e8a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BrainGNN model defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# BrainGNN Components\n",
    "\n",
    "class ROIAwareConv(nn.Module):\n",
    "    \"\"\"ROI-aware convolution for brain connectivity\"\"\"\n",
    "    \n",
    "    def __init__(self, in_features, out_features, n_rois=400):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.n_rois = n_rois\n",
    "        \n",
    "        # ROI-specific transformations\n",
    "        self.roi_linear = nn.Linear(in_features, out_features)\n",
    "        self.roi_attention = nn.MultiheadAttention(out_features, num_heads=8, batch_first=True)\n",
    "        \n",
    "        # Graph convolution\n",
    "        self.graph_conv = GCNConv(in_features, out_features)\n",
    "        \n",
    "        # Combination layer\n",
    "        self.combine = nn.Linear(out_features * 2, out_features)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, x, edge_index, batch=None):\n",
    "        # ROI-aware processing\n",
    "        roi_features = self.roi_linear(x)\n",
    "        roi_attended, _ = self.roi_attention(roi_features.unsqueeze(0), \n",
    "                                           roi_features.unsqueeze(0), \n",
    "                                           roi_features.unsqueeze(0))\n",
    "        roi_attended = roi_attended.squeeze(0)\n",
    "        \n",
    "        # Graph convolution\n",
    "        graph_features = self.graph_conv(x, edge_index)\n",
    "        \n",
    "        # Combine features\n",
    "        combined = torch.cat([roi_attended, graph_features], dim=1)\n",
    "        output = self.combine(combined)\n",
    "        output = F.relu(output)\n",
    "        output = self.dropout(output)\n",
    "        \n",
    "        return output\n",
    "\n",
    "class BiomarkerPooling(nn.Module):\n",
    "    \"\"\"Interpretable pooling for biomarker discovery\"\"\"\n",
    "    \n",
    "    def __init__(self, in_features, pool_ratio=0.5):\n",
    "        super().__init__()\n",
    "        self.pool_ratio = pool_ratio\n",
    "        self.score_layer = nn.Linear(in_features, 1)\n",
    "        self.feature_transform = nn.Linear(in_features, in_features)\n",
    "        \n",
    "    def forward(self, x, batch=None):\n",
    "        if batch is None:\n",
    "            batch = torch.zeros(x.size(0), dtype=torch.long, device=x.device)\n",
    "        \n",
    "        # Calculate importance scores\n",
    "        scores = self.score_layer(x).squeeze(-1)\n",
    "        \n",
    "        # Get top-k nodes (biomarkers)\n",
    "        batch_size = batch.max().item() + 1\n",
    "        pooled_features = []\n",
    "        biomarker_indices = []\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            mask = (batch == i)\n",
    "            node_scores = scores[mask]\n",
    "            node_features = x[mask]\n",
    "            \n",
    "            k = max(1, int(self.pool_ratio * node_features.size(0)))\n",
    "            top_k_indices = torch.topk(node_scores, k)[1]\n",
    "            \n",
    "            # Pool top-k features\n",
    "            selected_features = node_features[top_k_indices]\n",
    "            pooled = torch.mean(selected_features, dim=0)\n",
    "            \n",
    "            pooled_features.append(pooled)\n",
    "            biomarker_indices.append(top_k_indices)\n",
    "        \n",
    "        pooled_features = torch.stack(pooled_features)\n",
    "        return pooled_features, biomarker_indices\n",
    "\n",
    "class BrainGNN(nn.Module):\n",
    "    \"\"\"BrainGNN for brain connectivity analysis\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim=4, hidden_dim=128, num_classes=2, n_rois=400):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.n_rois = n_rois\n",
    "        \n",
    "        # ROI-aware convolutions\n",
    "        self.conv1 = ROIAwareConv(input_dim, hidden_dim, n_rois)\n",
    "        self.conv2 = ROIAwareConv(hidden_dim, hidden_dim, n_rois)\n",
    "        self.conv3 = ROIAwareConv(hidden_dim, hidden_dim, n_rois)\n",
    "        \n",
    "        # Biomarker pooling\n",
    "        self.biomarker_pool = BiomarkerPooling(hidden_dim, pool_ratio=0.3)\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(hidden_dim // 2, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Batch normalization\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.bn3 = nn.BatchNorm1d(hidden_dim)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        \n",
    "        # ROI-aware convolutions with residual connections\n",
    "        x1 = self.conv1(x, edge_index, batch)\n",
    "        x1 = self.bn1(x1)\n",
    "        \n",
    "        x2 = self.conv2(x1, edge_index, batch)\n",
    "        x2 = self.bn2(x2)\n",
    "        x2 = x2 + x1  # Residual connection\n",
    "        \n",
    "        x3 = self.conv3(x2, edge_index, batch)\n",
    "        x3 = self.bn3(x3)\n",
    "        x3 = x3 + x2  # Residual connection\n",
    "        \n",
    "        # Biomarker pooling\n",
    "        pooled_features, biomarker_indices = self.biomarker_pool(x3, batch)\n",
    "        \n",
    "        # Classification\n",
    "        output = self.classifier(pooled_features)\n",
    "        \n",
    "        return {\n",
    "            'logits': output,\n",
    "            'biomarker_indices': biomarker_indices,\n",
    "            'features': pooled_features\n",
    "        }\n",
    "\n",
    "print(\"BrainGNN model defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a81960d1",
   "metadata": {},
   "source": [
    "## Model 2: Local-to-Global GNN (LG-GNN)\n",
    "\n",
    "LG-GNN implements hierarchical learning that captures both local ROI interactions and global brain network patterns through a multi-scale architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39eb92b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local-to-Global GNN model defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Local-to-Global GNN Components\n",
    "\n",
    "class LocalConvBlock(nn.Module):\n",
    "    \"\"\"Local convolution for capturing immediate ROI interactions\"\"\"\n",
    "    \n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.conv = GCNConv(in_features, out_features)\n",
    "        self.local_attention = nn.MultiheadAttention(out_features, num_heads=4, batch_first=True)\n",
    "        self.norm = nn.LayerNorm(out_features)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x, edge_index, batch=None):\n",
    "        # Local graph convolution\n",
    "        x_conv = self.conv(x, edge_index)\n",
    "        x_conv = F.relu(x_conv)\n",
    "        \n",
    "        # Local attention\n",
    "        if batch is not None:\n",
    "            # Group by batch for attention\n",
    "            batch_size = batch.max().item() + 1\n",
    "            attended_features = []\n",
    "            \n",
    "            for i in range(batch_size):\n",
    "                mask = (batch == i)\n",
    "                batch_features = x_conv[mask].unsqueeze(0)\n",
    "                attended, _ = self.local_attention(batch_features, batch_features, batch_features)\n",
    "                attended_features.append(attended.squeeze(0))\n",
    "            \n",
    "            x_attended = torch.cat(attended_features, dim=0)\n",
    "        else:\n",
    "            x_attended, _ = self.local_attention(x_conv.unsqueeze(0), x_conv.unsqueeze(0), x_conv.unsqueeze(0))\n",
    "            x_attended = x_attended.squeeze(0)\n",
    "        \n",
    "        # Residual connection and normalization\n",
    "        output = self.norm(x_attended + x_conv)\n",
    "        output = self.dropout(output)\n",
    "        \n",
    "        return output\n",
    "\n",
    "class GlobalConvBlock(nn.Module):\n",
    "    \"\"\"Global convolution for capturing brain-wide patterns\"\"\"\n",
    "    \n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.conv = GATConv(in_features, out_features, heads=8, concat=False)\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.global_transform = nn.Linear(out_features, out_features)\n",
    "        self.norm = nn.LayerNorm(out_features)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, x, edge_index, batch=None):\n",
    "        # Global graph attention\n",
    "        x_global = self.conv(x, edge_index)\n",
    "        x_global = F.relu(x_global)\n",
    "        \n",
    "        # Global context aggregation\n",
    "        if batch is not None:\n",
    "            batch_size = batch.max().item() + 1\n",
    "            global_context = []\n",
    "            \n",
    "            for i in range(batch_size):\n",
    "                mask = (batch == i)\n",
    "                batch_features = x_global[mask]\n",
    "                # Average pooling for global context\n",
    "                global_vec = torch.mean(batch_features, dim=0, keepdim=True)\n",
    "                global_context.extend([global_vec] * batch_features.size(0))\n",
    "            \n",
    "            global_context = torch.cat(global_context, dim=0)\n",
    "        else:\n",
    "            global_context = torch.mean(x_global, dim=0, keepdim=True).expand_as(x_global)\n",
    "        \n",
    "        # Transform global context\n",
    "        global_context = self.global_transform(global_context)\n",
    "        \n",
    "        # Combine local and global information\n",
    "        output = self.norm(x_global + global_context)\n",
    "        output = self.dropout(output)\n",
    "        \n",
    "        return output\n",
    "\n",
    "class HierarchicalPooling(nn.Module):\n",
    "    \"\"\"Hierarchical pooling from local to global representations\"\"\"\n",
    "    \n",
    "    def __init__(self, in_features, reduction_factor=4):\n",
    "        super().__init__()\n",
    "        self.reduction_factor = reduction_factor\n",
    "        self.local_pool = nn.Linear(in_features, in_features // reduction_factor)\n",
    "        self.global_pool = nn.Linear(in_features, in_features // reduction_factor)\n",
    "        self.combine = nn.Linear(in_features // reduction_factor * 2, in_features)\n",
    "        self.attention = nn.MultiheadAttention(in_features, num_heads=4, batch_first=True)\n",
    "        \n",
    "    def forward(self, local_features, global_features, batch=None):\n",
    "        # Pool local and global features\n",
    "        local_pooled = self.local_pool(local_features)\n",
    "        global_pooled = self.global_pool(global_features)\n",
    "        \n",
    "        # Combine features\n",
    "        combined = torch.cat([local_pooled, global_pooled], dim=1)\n",
    "        combined = self.combine(combined)\n",
    "        combined = F.relu(combined)\n",
    "        \n",
    "        # Apply attention for final representation\n",
    "        if batch is not None:\n",
    "            batch_size = batch.max().item() + 1\n",
    "            final_features = []\n",
    "            \n",
    "            for i in range(batch_size):\n",
    "                mask = (batch == i)\n",
    "                batch_features = combined[mask].unsqueeze(0)\n",
    "                attended, _ = self.attention(batch_features, batch_features, batch_features)\n",
    "                # Global pooling for final representation\n",
    "                pooled = torch.mean(attended.squeeze(0), dim=0)\n",
    "                final_features.append(pooled)\n",
    "            \n",
    "            return torch.stack(final_features)\n",
    "        else:\n",
    "            attended, _ = self.attention(combined.unsqueeze(0), combined.unsqueeze(0), combined.unsqueeze(0))\n",
    "            return torch.mean(attended.squeeze(0), dim=0, keepdim=True)\n",
    "\n",
    "class LGGNN(nn.Module):\n",
    "    \"\"\"Local-to-Global Graph Neural Network\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim=4, hidden_dim=128, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        # Local processing layers\n",
    "        self.local_conv1 = LocalConvBlock(input_dim, hidden_dim)\n",
    "        self.local_conv2 = LocalConvBlock(hidden_dim, hidden_dim)\n",
    "        \n",
    "        # Global processing layers\n",
    "        self.global_conv1 = GlobalConvBlock(hidden_dim, hidden_dim)\n",
    "        self.global_conv2 = GlobalConvBlock(hidden_dim, hidden_dim)\n",
    "        \n",
    "        # Hierarchical pooling\n",
    "        self.hierarchical_pool = HierarchicalPooling(hidden_dim)\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim // 4, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        \n",
    "        # Local feature extraction\n",
    "        local_1 = self.local_conv1(x, edge_index, batch)\n",
    "        local_2 = self.local_conv2(local_1, edge_index, batch)\n",
    "        \n",
    "        # Global feature extraction\n",
    "        global_1 = self.global_conv1(local_2, edge_index, batch)\n",
    "        global_2 = self.global_conv2(global_1, edge_index, batch)\n",
    "        \n",
    "        # Hierarchical pooling\n",
    "        pooled_features = self.hierarchical_pool(local_2, global_2, batch)\n",
    "        \n",
    "        # Classification\n",
    "        output = self.classifier(pooled_features)\n",
    "        \n",
    "        return {\n",
    "            'logits': output,\n",
    "            'local_features': local_2,\n",
    "            'global_features': global_2,\n",
    "            'pooled_features': pooled_features\n",
    "        }\n",
    "\n",
    "print(\"Local-to-Global GNN model defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84af6648",
   "metadata": {},
   "source": [
    "## Model 3: Dynamic Multi-Site GCN (DG-DMSGCN)\n",
    "\n",
    "DG-DMSGCN addresses multi-site variability in neuroimaging data through dynamic graph construction and site-adaptive mechanisms with temporal feature modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d63e44cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dynamic Multi-Site GCN model defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Dynamic Multi-Site GCN Components\n",
    "\n",
    "class DynamicGraphConstruction(nn.Module):\n",
    "    \"\"\"Dynamic graph construction for adaptive connectivity\"\"\"\n",
    "    \n",
    "    def __init__(self, node_features, hidden_dim=64, top_k=20):\n",
    "        super().__init__()\n",
    "        self.node_features = node_features\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.top_k = top_k\n",
    "        \n",
    "        self.feature_transform = nn.Sequential(\n",
    "            nn.Linear(node_features, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        \n",
    "        self.edge_predictor = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, node_features, batch=None):\n",
    "        \"\"\"Construct dynamic graphs based on node features\"\"\"\n",
    "        # Transform node features\n",
    "        transformed_features = self.feature_transform(node_features)\n",
    "        \n",
    "        if batch is None:\n",
    "            batch = torch.zeros(node_features.size(0), dtype=torch.long, device=node_features.device)\n",
    "        \n",
    "        batch_size = batch.max().item() + 1\n",
    "        edge_indices = []\n",
    "        edge_weights = []\n",
    "        \n",
    "        for b in range(batch_size):\n",
    "            mask = (batch == b)\n",
    "            batch_features = transformed_features[mask]\n",
    "            n_nodes = batch_features.size(0)\n",
    "            \n",
    "            # Compute pairwise features\n",
    "            edge_scores = []\n",
    "            edges = []\n",
    "            \n",
    "            for i in range(n_nodes):\n",
    "                for j in range(i + 1, n_nodes):\n",
    "                    # Concatenate node features\n",
    "                    edge_feature = torch.cat([batch_features[i], batch_features[j]], dim=0)\n",
    "                    score = self.edge_predictor(edge_feature)\n",
    "                    edge_scores.append(score)\n",
    "                    edges.append([i, j])\n",
    "            \n",
    "            if edges:\n",
    "                edge_scores = torch.stack(edge_scores).squeeze()\n",
    "                edges = torch.tensor(edges, device=node_features.device)\n",
    "                \n",
    "                # Select top-k edges\n",
    "                k = min(self.top_k, len(edges))\n",
    "                top_k_indices = torch.topk(edge_scores, k)[1]\n",
    "                selected_edges = edges[top_k_indices]\n",
    "                selected_weights = edge_scores[top_k_indices]\n",
    "                \n",
    "                # Add reverse edges\n",
    "                reverse_edges = torch.stack([selected_edges[:, 1], selected_edges[:, 0]], dim=1)\n",
    "                all_edges = torch.cat([selected_edges, reverse_edges], dim=0)\n",
    "                all_weights = torch.cat([selected_weights, selected_weights], dim=0)\n",
    "                \n",
    "                # Adjust indices for batch\n",
    "                batch_offset = torch.sum(batch < b).item()\n",
    "                all_edges = all_edges + batch_offset\n",
    "                \n",
    "                edge_indices.append(all_edges.t())\n",
    "                edge_weights.append(all_weights)\n",
    "        \n",
    "        if edge_indices:\n",
    "            edge_index = torch.cat(edge_indices, dim=1)\n",
    "            edge_weight = torch.cat(edge_weights, dim=0)\n",
    "        else:\n",
    "            edge_index = torch.empty((2, 0), dtype=torch.long, device=node_features.device)\n",
    "            edge_weight = torch.empty(0, device=node_features.device)\n",
    "        \n",
    "        return edge_index, edge_weight\n",
    "\n",
    "class SiteAdaptiveLayer(nn.Module):\n",
    "    \"\"\"Site-adaptive normalization and feature transformation\"\"\"\n",
    "    \n",
    "    def __init__(self, features_dim, num_sites=10):\n",
    "        super().__init__()\n",
    "        self.features_dim = features_dim\n",
    "        self.num_sites = num_sites\n",
    "        \n",
    "        # Site-specific parameters\n",
    "        self.site_embeddings = nn.Embedding(num_sites, features_dim)\n",
    "        self.site_scales = nn.Embedding(num_sites, features_dim)\n",
    "        self.site_shifts = nn.Embedding(num_sites, features_dim)\n",
    "        \n",
    "        # Adaptive transformation\n",
    "        self.adaptive_transform = nn.Sequential(\n",
    "            nn.Linear(features_dim * 2, features_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(features_dim, features_dim)\n",
    "        )\n",
    "        \n",
    "        # Initialize parameters\n",
    "        nn.init.ones_(self.site_scales.weight)\n",
    "        nn.init.zeros_(self.site_shifts.weight)\n",
    "        \n",
    "    def forward(self, x, site_indices):\n",
    "        \"\"\"Apply site-adaptive transformation\"\"\"\n",
    "        # Get site-specific parameters\n",
    "        site_emb = self.site_embeddings(site_indices)\n",
    "        site_scale = self.site_scales(site_indices)\n",
    "        site_shift = self.site_shifts(site_indices)\n",
    "        \n",
    "        # Site-adaptive normalization\n",
    "        normalized_x = x * site_scale + site_shift\n",
    "        \n",
    "        # Combine with site embeddings\n",
    "        combined = torch.cat([normalized_x, site_emb], dim=-1)\n",
    "        adapted_x = self.adaptive_transform(combined)\n",
    "        \n",
    "        return adapted_x\n",
    "\n",
    "class TemporalFeatureExtractor(nn.Module):\n",
    "    \"\"\"Extract temporal features from connectivity patterns\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, hidden_dim=64, sequence_length=10):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.sequence_length = sequence_length\n",
    "        \n",
    "        # Temporal convolutions\n",
    "        self.temporal_conv1 = nn.Conv1d(input_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "        self.temporal_conv2 = nn.Conv1d(hidden_dim, hidden_dim, kernel_size=3, padding=1)\n",
    "        \n",
    "        # LSTM for temporal modeling\n",
    "        self.lstm = nn.LSTM(hidden_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        # Output projection\n",
    "        self.output_proj = nn.Linear(hidden_dim * 2, input_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"Extract temporal features\"\"\"\n",
    "        batch_size, n_nodes, features = x.shape\n",
    "        \n",
    "        # Reshape for temporal processing\n",
    "        x_temp = x.transpose(1, 2)  # (batch, features, nodes)\n",
    "        \n",
    "        # Temporal convolutions\n",
    "        temp_conv1 = F.relu(self.temporal_conv1(x_temp))\n",
    "        temp_conv2 = F.relu(self.temporal_conv2(temp_conv1))\n",
    "        \n",
    "        # Prepare for LSTM (treat nodes as sequence)\n",
    "        temp_conv2 = temp_conv2.transpose(1, 2)  # (batch, nodes, hidden)\n",
    "        \n",
    "        # LSTM processing\n",
    "        lstm_out, _ = self.lstm(temp_conv2)\n",
    "        \n",
    "        # Project back to original dimension\n",
    "        temporal_features = self.output_proj(lstm_out)\n",
    "        \n",
    "        return temporal_features\n",
    "\n",
    "class DGDMSGCN(nn.Module):\n",
    "    \"\"\"Dynamic Multi-Site Graph Convolutional Network\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim=4, hidden_dim=128, num_classes=2, num_sites=10):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.num_sites = num_sites\n",
    "        \n",
    "        # Dynamic graph construction\n",
    "        self.dynamic_graph = DynamicGraphConstruction(input_dim, hidden_dim//2)\n",
    "        \n",
    "        # Site-adaptive layers\n",
    "        self.site_adaptive1 = SiteAdaptiveLayer(hidden_dim, num_sites)\n",
    "        self.site_adaptive2 = SiteAdaptiveLayer(hidden_dim, num_sites)\n",
    "        \n",
    "        # Temporal feature extraction\n",
    "        self.temporal_extractor = TemporalFeatureExtractor(input_dim, hidden_dim//2)\n",
    "        \n",
    "        # Graph convolution layers\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.conv3 = GCNConv(hidden_dim, hidden_dim)\n",
    "        \n",
    "        # Multi-scale pooling\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool1d(1)\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim // 2, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Site encoding\n",
    "        self.site_encoder = nn.Embedding(num_sites, 16)\n",
    "        \n",
    "    def encode_sites(self, sites):\n",
    "        \"\"\"Encode site names to indices\"\"\"\n",
    "        site_names = list(set(sites))\n",
    "        site_to_idx = {site: idx % self.num_sites for idx, site in enumerate(site_names)}\n",
    "        return torch.tensor([site_to_idx.get(site, 0) for site in sites], \n",
    "                          dtype=torch.long, device=next(self.parameters()).device)\n",
    "    \n",
    "    def forward(self, data, sites):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        \n",
    "        # Encode sites\n",
    "        site_indices = self.encode_sites(sites)\n",
    "        \n",
    "        # Extract temporal features\n",
    "        batch_size = batch.max().item() + 1\n",
    "        temporal_features = []\n",
    "        \n",
    "        for b in range(batch_size):\n",
    "            mask = (batch == b)\n",
    "            batch_x = x[mask].unsqueeze(0)\n",
    "            temp_feat = self.temporal_extractor(batch_x)\n",
    "            temporal_features.append(temp_feat.squeeze(0))\n",
    "        \n",
    "        x_temporal = torch.cat(temporal_features, dim=0)\n",
    "        \n",
    "        # Dynamic graph construction\n",
    "        dynamic_edge_index, dynamic_edge_weight = self.dynamic_graph(x_temporal, batch)\n",
    "        \n",
    "        # Combine original and dynamic edges\n",
    "        combined_edge_index = torch.cat([edge_index, dynamic_edge_index], dim=1)\n",
    "        \n",
    "        # Graph convolutions with site adaptation\n",
    "        x1 = F.relu(self.conv1(x_temporal, combined_edge_index))\n",
    "        x1_adapted = self.site_adaptive1(x1, site_indices[batch])\n",
    "        \n",
    "        x2 = F.relu(self.conv2(x1_adapted, combined_edge_index))\n",
    "        x2_adapted = self.site_adaptive2(x2, site_indices[batch])\n",
    "        \n",
    "        x3 = F.relu(self.conv3(x2_adapted, combined_edge_index))\n",
    "        \n",
    "        # Multi-scale pooling\n",
    "        pooled_features = []\n",
    "        for b in range(batch_size):\n",
    "            mask = (batch == b)\n",
    "            batch_features = x3[mask].unsqueeze(0).transpose(1, 2)\n",
    "            \n",
    "            avg_pooled = self.global_pool(batch_features).squeeze(-1)\n",
    "            max_pooled = self.max_pool(batch_features).squeeze(-1)\n",
    "            \n",
    "            combined_pool = torch.cat([avg_pooled, max_pooled], dim=1)\n",
    "            pooled_features.append(combined_pool.squeeze(0))\n",
    "        \n",
    "        pooled_features = torch.stack(pooled_features)\n",
    "        \n",
    "        # Classification\n",
    "        output = self.classifier(pooled_features)\n",
    "        \n",
    "        return {\n",
    "            'logits': output,\n",
    "            'dynamic_edges': dynamic_edge_index,\n",
    "            'temporal_features': x_temporal,\n",
    "            'adapted_features': x2_adapted\n",
    "        }\n",
    "\n",
    "print(\"Dynamic Multi-Site GCN model defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277d0998",
   "metadata": {},
   "source": [
    "## Model 4: IFC-GNN - Interaction-based Functional Connectivity GNN\n",
    "\n",
    "IFC-GNN models temporal interactions in functional connectivity through specialized convolutions and deep feature selection mechanisms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f75eaff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IFC-GNN model defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# IFC-GNN Components\n",
    "\n",
    "class InteractionConv(nn.Module):\n",
    "    \"\"\"Interaction-based convolution for functional connectivity\"\"\"\n",
    "    \n",
    "    def __init__(self, in_features, out_features, interaction_dim=32):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.interaction_dim = interaction_dim\n",
    "        \n",
    "        # Interaction encoding\n",
    "        self.node_encoder = nn.Linear(in_features, interaction_dim)\n",
    "        self.edge_encoder = nn.Linear(1, interaction_dim)  # Edge weights\n",
    "        \n",
    "        # Interaction computation\n",
    "        self.interaction_net = nn.Sequential(\n",
    "            nn.Linear(interaction_dim * 3, interaction_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(interaction_dim * 2, interaction_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(interaction_dim, out_features)\n",
    "        )\n",
    "        \n",
    "        # Message passing\n",
    "        self.message_net = nn.Sequential(\n",
    "            nn.Linear(out_features * 2, out_features),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(out_features, out_features)\n",
    "        )\n",
    "        \n",
    "        # Update function\n",
    "        self.update_net = GRUCell(out_features, out_features)\n",
    "        \n",
    "    def forward(self, x, edge_index, edge_attr=None):\n",
    "        \"\"\"Forward pass with interaction modeling\"\"\"\n",
    "        row, col = edge_index\n",
    "        \n",
    "        # Encode nodes and edges\n",
    "        node_emb = self.node_encoder(x)\n",
    "        \n",
    "        if edge_attr is None:\n",
    "            edge_attr = torch.ones(edge_index.size(1), 1, device=x.device)\n",
    "        edge_emb = self.edge_encoder(edge_attr)\n",
    "        \n",
    "        # Compute interactions\n",
    "        source_nodes = node_emb[row]\n",
    "        target_nodes = node_emb[col]\n",
    "        \n",
    "        # Combine source, target, and edge information\n",
    "        interaction_input = torch.cat([source_nodes, target_nodes, edge_emb], dim=1)\n",
    "        interactions = self.interaction_net(interaction_input)\n",
    "        \n",
    "        # Aggregate messages\n",
    "        num_nodes = x.size(0)\n",
    "        messages = torch.zeros(num_nodes, self.out_features, device=x.device)\n",
    "        \n",
    "        for i in range(edge_index.size(1)):\n",
    "            src, tgt = row[i], col[i]\n",
    "            message = self.message_net(torch.cat([interactions[i], node_emb[src]], dim=0).unsqueeze(0))\n",
    "            messages[tgt] += message.squeeze(0)\n",
    "        \n",
    "        # Update node representations\n",
    "        h_prev = torch.zeros(num_nodes, self.out_features, device=x.device)\n",
    "        updated_nodes = self.update_net(messages, h_prev)\n",
    "        \n",
    "        return updated_nodes\n",
    "\n",
    "class TemporalInteractionBlock(nn.Module):\n",
    "    \"\"\"Temporal interaction modeling for functional connectivity\"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_dim, num_time_steps=5):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_time_steps = num_time_steps\n",
    "        \n",
    "        # Temporal encoding\n",
    "        self.temporal_encoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        )\n",
    "        \n",
    "        # Interaction LSTM\n",
    "        self.interaction_lstm = nn.LSTM(\n",
    "            hidden_dim, hidden_dim, \n",
    "            num_layers=2, \n",
    "            batch_first=True, \n",
    "            bidirectional=True\n",
    "        )\n",
    "        \n",
    "        # Attention mechanism\n",
    "        self.temporal_attention = nn.MultiheadAttention(\n",
    "            hidden_dim * 2, num_heads=8, batch_first=True\n",
    "        )\n",
    "        \n",
    "        # Output projection\n",
    "        self.output_proj = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        \n",
    "    def forward(self, x, batch=None):\n",
    "        \"\"\"Model temporal interactions\"\"\"\n",
    "        if batch is None:\n",
    "            batch = torch.zeros(x.size(0), dtype=torch.long, device=x.device)\n",
    "        \n",
    "        batch_size = batch.max().item() + 1\n",
    "        temporal_features = []\n",
    "        \n",
    "        for b in range(batch_size):\n",
    "            mask = (batch == b)\n",
    "            batch_x = x[mask]  # (num_nodes, hidden_dim)\n",
    "            \n",
    "            # Create temporal sequence\n",
    "            temporal_seq = []\n",
    "            for t in range(self.num_time_steps):\n",
    "                # Add temporal encoding\n",
    "                temp_encoded = self.temporal_encoder(batch_x)\n",
    "                temporal_seq.append(temp_encoded)\n",
    "            \n",
    "            temporal_seq = torch.stack(temporal_seq, dim=1)  # (num_nodes, time_steps, hidden_dim)\n",
    "            \n",
    "            # LSTM processing\n",
    "            lstm_out, _ = self.interaction_lstm(temporal_seq)  # (num_nodes, time_steps, hidden_dim*2)\n",
    "            \n",
    "            # Temporal attention\n",
    "            attended, _ = self.temporal_attention(lstm_out, lstm_out, lstm_out)\n",
    "            \n",
    "            # Aggregate over time\n",
    "            temporal_agg = torch.mean(attended, dim=1)  # (num_nodes, hidden_dim*2)\n",
    "            \n",
    "            # Project to output dimension\n",
    "            output = self.output_proj(temporal_agg)  # (num_nodes, hidden_dim)\n",
    "            temporal_features.append(output)\n",
    "        \n",
    "        return torch.cat(temporal_features, dim=0)\n",
    "\n",
    "class DeepFeatureSelection(nn.Module):\n",
    "    \"\"\"Deep feature selection for connectivity patterns\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim, selection_ratio=0.5):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.selection_ratio = selection_ratio\n",
    "        \n",
    "        # Feature importance network\n",
    "        self.importance_net = nn.Sequential(\n",
    "            nn.Linear(input_dim, input_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(input_dim * 2, input_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_dim, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # Feature transformation network\n",
    "        self.transform_net = nn.Sequential(\n",
    "            nn.Linear(input_dim, input_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_dim, input_dim)\n",
    "        )\n",
    "        \n",
    "        # Gating mechanism\n",
    "        self.gate = nn.Sequential(\n",
    "            nn.Linear(input_dim * 2, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"Select and transform features\"\"\"\n",
    "        # Compute feature importance\n",
    "        importance_scores = self.importance_net(x)\n",
    "        \n",
    "        # Transform features\n",
    "        transformed_features = self.transform_net(x)\n",
    "        \n",
    "        # Gating\n",
    "        gate_input = torch.cat([x, transformed_features], dim=-1)\n",
    "        gate_values = self.gate(gate_input)\n",
    "        \n",
    "        # Apply gating and importance weighting\n",
    "        selected_features = transformed_features * gate_values * importance_scores\n",
    "        \n",
    "        # Add residual connection\n",
    "        output = selected_features + x * (1 - gate_values)\n",
    "        \n",
    "        return output, importance_scores\n",
    "\n",
    "class IFCGNN(nn.Module):\n",
    "    \"\"\"Interaction-based Functional Connectivity GNN\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim=4, hidden_dim=128, num_classes=2, interaction_dim=64):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.interaction_dim = interaction_dim\n",
    "        \n",
    "        # Input projection\n",
    "        self.input_proj = nn.Linear(input_dim, hidden_dim)\n",
    "        \n",
    "        # Interaction convolutions\n",
    "        self.interaction_conv1 = InteractionConv(hidden_dim, hidden_dim, interaction_dim)\n",
    "        self.interaction_conv2 = InteractionConv(hidden_dim, hidden_dim, interaction_dim)\n",
    "        self.interaction_conv3 = InteractionConv(hidden_dim, hidden_dim, interaction_dim)\n",
    "        \n",
    "        # Temporal interaction modeling\n",
    "        self.temporal_block = TemporalInteractionBlock(hidden_dim)\n",
    "        \n",
    "        # Deep feature selection\n",
    "        self.feature_selection = DeepFeatureSelection(hidden_dim)\n",
    "        \n",
    "        # Self-attention pooling\n",
    "        self.self_attention = nn.MultiheadAttention(hidden_dim, num_heads=8, batch_first=True)\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim // 4, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Normalization layers\n",
    "        self.norm1 = nn.LayerNorm(hidden_dim)\n",
    "        self.norm2 = nn.LayerNorm(hidden_dim)\n",
    "        self.norm3 = nn.LayerNorm(hidden_dim)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        \n",
    "        # Input projection\n",
    "        x = self.input_proj(x)\n",
    "        \n",
    "        # Interaction convolutions with residual connections\n",
    "        x1 = self.interaction_conv1(x, edge_index, edge_attr)\n",
    "        x1 = self.norm1(x1 + x)\n",
    "        \n",
    "        x2 = self.interaction_conv2(x1, edge_index, edge_attr)\n",
    "        x2 = self.norm2(x2 + x1)\n",
    "        \n",
    "        x3 = self.interaction_conv3(x2, edge_index, edge_attr)\n",
    "        x3 = self.norm3(x3 + x2)\n",
    "        \n",
    "        # Temporal interaction modeling\n",
    "        temporal_features = self.temporal_block(x3, batch)\n",
    "        \n",
    "        # Deep feature selection\n",
    "        selected_features, importance_scores = self.feature_selection(temporal_features)\n",
    "        \n",
    "        # Self-attention pooling\n",
    "        batch_size = batch.max().item() + 1\n",
    "        pooled_features = []\n",
    "        \n",
    "        for b in range(batch_size):\n",
    "            mask = (batch == b)\n",
    "            batch_features = selected_features[mask].unsqueeze(0)\n",
    "            \n",
    "            # Self-attention\n",
    "            attended, attention_weights = self.self_attention(\n",
    "                batch_features, batch_features, batch_features\n",
    "            )\n",
    "            \n",
    "            # Global pooling\n",
    "            pooled = torch.mean(attended.squeeze(0), dim=0)\n",
    "            pooled_features.append(pooled)\n",
    "        \n",
    "        pooled_features = torch.stack(pooled_features)\n",
    "        \n",
    "        # Classification\n",
    "        output = self.classifier(pooled_features)\n",
    "        \n",
    "        return {\n",
    "            'logits': output,\n",
    "            'importance_scores': importance_scores,\n",
    "            'temporal_features': temporal_features,\n",
    "            'selected_features': selected_features,\n",
    "            'pooled_features': pooled_features\n",
    "        }\n",
    "\n",
    "print(\"IFC-GNN model defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55453cb8",
   "metadata": {},
   "source": [
    "## Model 5: RAGNN - Region-Aware Graph Neural Network\n",
    "\n",
    "RAGNN incorporates hemispheric asymmetry learning and EEG-based analysis for comprehensive brain connectivity modeling with region-specific processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "82cbeed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAGNN model defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# RAGNN Components\n",
    "\n",
    "class HemisphericAsymmetryModule(nn.Module):\n",
    "    \"\"\"Module for learning hemispheric asymmetry patterns\"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_dim, n_rois=400):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.n_rois = n_rois\n",
    "        self.hemisphere_size = n_rois // 2\n",
    "        \n",
    "        # Hemisphere-specific encoders\n",
    "        self.left_encoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        \n",
    "        self.right_encoder = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        \n",
    "        # Asymmetry computation\n",
    "        self.asymmetry_net = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim // 2, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        \n",
    "        # Cross-hemispheric attention\n",
    "        self.cross_attention = nn.MultiheadAttention(hidden_dim, num_heads=4, batch_first=True)\n",
    "        \n",
    "        # Integration layer\n",
    "        self.integration = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * 3, hidden_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, batch=None):\n",
    "        \"\"\"Learn hemispheric asymmetry patterns\"\"\"\n",
    "        if batch is None:\n",
    "            batch = torch.zeros(x.size(0), dtype=torch.long, device=x.device)\n",
    "        \n",
    "        batch_size = batch.max().item() + 1\n",
    "        asymmetry_features = []\n",
    "        \n",
    "        for b in range(batch_size):\n",
    "            mask = (batch == b)\n",
    "            batch_x = x[mask]\n",
    "            \n",
    "            # Assume first half is left hemisphere, second half is right\n",
    "            n_nodes = batch_x.size(0)\n",
    "            left_nodes = batch_x[:n_nodes//2]\n",
    "            right_nodes = batch_x[n_nodes//2:]\n",
    "            \n",
    "            # Hemisphere-specific encoding\n",
    "            left_encoded = self.left_encoder(left_nodes)\n",
    "            right_encoded = self.right_encoder(right_nodes)\n",
    "            \n",
    "            # Cross-hemispheric attention\n",
    "            left_query = left_encoded.unsqueeze(0)\n",
    "            right_key_value = right_encoded.unsqueeze(0)\n",
    "            left_attended, _ = self.cross_attention(left_query, right_key_value, right_key_value)\n",
    "            left_attended = left_attended.squeeze(0)\n",
    "            \n",
    "            right_query = right_encoded.unsqueeze(0)\n",
    "            left_key_value = left_encoded.unsqueeze(0)\n",
    "            right_attended, _ = self.cross_attention(right_query, left_key_value, left_key_value)\n",
    "            right_attended = right_attended.squeeze(0)\n",
    "            \n",
    "            # Compute asymmetry scores\n",
    "            asymmetry_input = torch.cat([left_encoded, right_encoded], dim=1)\n",
    "            asymmetry_scores = self.asymmetry_net(asymmetry_input)\n",
    "            \n",
    "            # Integrate information\n",
    "            left_integrated = self.integration(torch.cat([left_encoded, left_attended, asymmetry_scores.expand_as(left_encoded)], dim=1))\n",
    "            right_integrated = self.integration(torch.cat([right_encoded, right_attended, asymmetry_scores.expand_as(right_encoded)], dim=1))\n",
    "            \n",
    "            # Combine hemispheres\n",
    "            integrated_features = torch.cat([left_integrated, right_integrated], dim=0)\n",
    "            asymmetry_features.append(integrated_features)\n",
    "        \n",
    "        return torch.cat(asymmetry_features, dim=0)\n",
    "\n",
    "class RegionSpecificConv(nn.Module):\n",
    "    \"\"\"Region-specific convolution for different brain areas\"\"\"\n",
    "    \n",
    "    def __init__(self, in_features, out_features, num_regions=8):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.num_regions = num_regions\n",
    "        \n",
    "        # Region-specific convolutions\n",
    "        self.region_convs = nn.ModuleList([\n",
    "            GCNConv(in_features, out_features) for _ in range(num_regions)\n",
    "        ])\n",
    "        \n",
    "        # Region classifier\n",
    "        self.region_classifier = nn.Sequential(\n",
    "            nn.Linear(in_features, num_regions),\n",
    "            nn.Softmax(dim=-1)\n",
    "        )\n",
    "        \n",
    "        # Adaptive combination\n",
    "        self.combination_net = nn.Sequential(\n",
    "            nn.Linear(out_features * num_regions, out_features * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(out_features * 2, out_features)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, edge_index, batch=None):\n",
    "        \"\"\"Apply region-specific convolutions\"\"\"\n",
    "        # Classify nodes into regions\n",
    "        region_probs = self.region_classifier(x)\n",
    "        \n",
    "        # Apply region-specific convolutions\n",
    "        region_outputs = []\n",
    "        for i, conv in enumerate(self.region_convs):\n",
    "            region_output = conv(x, edge_index)\n",
    "            region_outputs.append(region_output)\n",
    "        \n",
    "        # Weighted combination based on region probabilities\n",
    "        weighted_outputs = []\n",
    "        for i, output in enumerate(region_outputs):\n",
    "            weight = region_probs[:, i:i+1]\n",
    "            weighted_output = output * weight\n",
    "            weighted_outputs.append(weighted_output)\n",
    "        \n",
    "        # Combine all regions\n",
    "        combined_output = torch.cat(weighted_outputs, dim=1)\n",
    "        final_output = self.combination_net(combined_output)\n",
    "        \n",
    "        return final_output, region_probs\n",
    "\n",
    "class EEGInspiredPooling(nn.Module):\n",
    "    \"\"\"EEG-inspired pooling for frequency band analysis\"\"\"\n",
    "    \n",
    "    def __init__(self, hidden_dim, num_freq_bands=5):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_freq_bands = num_freq_bands\n",
    "        \n",
    "        # Frequency band decomposition\n",
    "        self.freq_transforms = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(hidden_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_dim, hidden_dim)\n",
    "            ) for _ in range(num_freq_bands)\n",
    "        ])\n",
    "        \n",
    "        # Band-specific attention\n",
    "        self.band_attention = nn.ModuleList([\n",
    "            nn.MultiheadAttention(hidden_dim, num_heads=4, batch_first=True)\n",
    "            for _ in range(num_freq_bands)\n",
    "        ])\n",
    "        \n",
    "        # Frequency integration\n",
    "        self.freq_integration = nn.Sequential(\n",
    "            nn.Linear(hidden_dim * num_freq_bands, hidden_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x, batch=None):\n",
    "        \"\"\"EEG-inspired pooling with frequency bands\"\"\"\n",
    "        if batch is None:\n",
    "            batch = torch.zeros(x.size(0), dtype=torch.long, device=x.device)\n",
    "        \n",
    "        batch_size = batch.max().item() + 1\n",
    "        freq_features = []\n",
    "        \n",
    "        for b in range(batch_size):\n",
    "            mask = (batch == b)\n",
    "            batch_x = x[mask].unsqueeze(0)\n",
    "            \n",
    "            # Decompose into frequency bands\n",
    "            band_features = []\n",
    "            for i, (transform, attention) in enumerate(zip(self.freq_transforms, self.band_attention)):\n",
    "                # Transform to frequency domain\n",
    "                freq_transformed = transform(batch_x.squeeze(0))\n",
    "                freq_transformed = freq_transformed.unsqueeze(0)\n",
    "                \n",
    "                # Apply attention within band\n",
    "                attended, _ = attention(freq_transformed, freq_transformed, freq_transformed)\n",
    "                \n",
    "                # Pool within band\n",
    "                band_pooled = torch.mean(attended.squeeze(0), dim=0)\n",
    "                band_features.append(band_pooled)\n",
    "            \n",
    "            # Integrate frequency bands\n",
    "            integrated_freq = torch.cat(band_features, dim=0)\n",
    "            integrated_output = self.freq_integration(integrated_freq)\n",
    "            freq_features.append(integrated_output)\n",
    "        \n",
    "        return torch.stack(freq_features)\n",
    "\n",
    "class RAGNN(nn.Module):\n",
    "    \"\"\"Region-Aware Graph Neural Network with Hemispheric Asymmetry\"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim=4, hidden_dim=128, num_classes=2, num_regions=8, num_freq_bands=5):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.num_regions = num_regions\n",
    "        self.num_freq_bands = num_freq_bands\n",
    "        \n",
    "        # Input projection\n",
    "        self.input_proj = nn.Linear(input_dim, hidden_dim)\n",
    "        \n",
    "        # Region-specific convolutions\n",
    "        self.region_conv1 = RegionSpecificConv(hidden_dim, hidden_dim, num_regions)\n",
    "        self.region_conv2 = RegionSpecificConv(hidden_dim, hidden_dim, num_regions)\n",
    "        \n",
    "        # Hemispheric asymmetry module\n",
    "        self.hemisphere_module = HemisphericAsymmetryModule(hidden_dim)\n",
    "        \n",
    "        # Standard convolution layers\n",
    "        self.conv3 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.conv4 = GCNConv(hidden_dim, hidden_dim)\n",
    "        \n",
    "        # EEG-inspired pooling\n",
    "        self.eeg_pooling = EEGInspiredPooling(hidden_dim, num_freq_bands)\n",
    "        \n",
    "        # Multi-head attention for final integration\n",
    "        self.final_attention = nn.MultiheadAttention(hidden_dim, num_heads=8, batch_first=True)\n",
    "        \n",
    "        # Classification head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(hidden_dim // 2, hidden_dim // 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(hidden_dim // 4, num_classes)\n",
    "        )\n",
    "        \n",
    "        # Normalization layers\n",
    "        self.norm1 = nn.LayerNorm(hidden_dim)\n",
    "        self.norm2 = nn.LayerNorm(hidden_dim)\n",
    "        self.norm3 = nn.LayerNorm(hidden_dim)\n",
    "        self.norm4 = nn.LayerNorm(hidden_dim)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        \n",
    "        # Input projection\n",
    "        x = self.input_proj(x)\n",
    "        \n",
    "        # Region-specific convolutions\n",
    "        x1, region_probs1 = self.region_conv1(x, edge_index, batch)\n",
    "        x1 = self.norm1(x1 + x)\n",
    "        \n",
    "        x2, region_probs2 = self.region_conv2(x1, edge_index, batch)\n",
    "        x2 = self.norm2(x2 + x1)\n",
    "        \n",
    "        # Hemispheric asymmetry learning\n",
    "        x_asym = self.hemisphere_module(x2, batch)\n",
    "        x_asym = self.norm3(x_asym + x2)\n",
    "        \n",
    "        # Standard convolutions\n",
    "        x3 = F.relu(self.conv3(x_asym, edge_index))\n",
    "        x3 = self.norm4(x3 + x_asym)\n",
    "        \n",
    "        x4 = F.relu(self.conv4(x3, edge_index))\n",
    "        \n",
    "        # EEG-inspired pooling\n",
    "        pooled_features = self.eeg_pooling(x4, batch)\n",
    "        \n",
    "        # Final attention\n",
    "        attended_features, attention_weights = self.final_attention(\n",
    "            pooled_features.unsqueeze(1), \n",
    "            pooled_features.unsqueeze(1), \n",
    "            pooled_features.unsqueeze(1)\n",
    "        )\n",
    "        final_features = attended_features.squeeze(1)\n",
    "        \n",
    "        # Classification\n",
    "        output = self.classifier(final_features)\n",
    "        \n",
    "        return {\n",
    "            'logits': output,\n",
    "            'region_probs1': region_probs1,\n",
    "            'region_probs2': region_probs2,\n",
    "            'hemispheric_features': x_asym,\n",
    "            'attention_weights': attention_weights,\n",
    "            'final_features': final_features\n",
    "        }\n",
    "\n",
    "print(\"RAGNN model defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d180943",
   "metadata": {},
   "source": [
    "## Training and Evaluation Utilities\n",
    "\n",
    "Comprehensive training framework with gradient accumulation, early stopping, learning rate scheduling, and model evaluation utilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f0282ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluation utilities defined successfully!\n"
     ]
    }
   ],
   "source": [
    "# Training and Evaluation Framework\n",
    "\n",
    "class EarlyStopping:\n",
    "    \"\"\"Early stopping utility with patience and best model saving\"\"\"\n",
    "    \n",
    "    def __init__(self, patience=10, min_delta=0.001, restore_best_weights=True):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.restore_best_weights = restore_best_weights\n",
    "        self.best_loss = None\n",
    "        self.counter = 0\n",
    "        self.best_weights = None\n",
    "        \n",
    "    def __call__(self, val_loss, model):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "            self.save_checkpoint(model)\n",
    "        elif val_loss < self.best_loss - self.min_delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "            self.save_checkpoint(model)\n",
    "        else:\n",
    "            self.counter += 1\n",
    "            \n",
    "        return self.counter >= self.patience\n",
    "    \n",
    "    def save_checkpoint(self, model):\n",
    "        if self.restore_best_weights:\n",
    "            self.best_weights = {name: param.clone() for name, param in model.named_parameters()}\n",
    "    \n",
    "    def restore_best_weights_fn(self, model):\n",
    "        if self.best_weights:\n",
    "            for name, param in model.named_parameters():\n",
    "                param.data.copy_(self.best_weights[name])\n",
    "\n",
    "def create_data_loaders(dataset, batch_size=32, train_ratio=0.8, val_ratio=0.1):\n",
    "    \"\"\"Create train/validation/test data loaders\"\"\"\n",
    "    n_samples = len(dataset)\n",
    "    indices = list(range(n_samples))\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    train_split = int(train_ratio * n_samples)\n",
    "    val_split = int((train_ratio + val_ratio) * n_samples)\n",
    "    \n",
    "    train_indices = indices[:train_split]\n",
    "    val_indices = indices[train_split:val_split]\n",
    "    test_indices = indices[val_split:]\n",
    "    \n",
    "    train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
    "    val_sampler = torch.utils.data.SubsetRandomSampler(val_indices)\n",
    "    test_sampler = torch.utils.data.SubsetRandomSampler(test_indices)\n",
    "    \n",
    "    def collate_fn(batch):\n",
    "        \"\"\"Custom collate function for graph data with time series support\"\"\"\n",
    "        graphs = []\n",
    "        labels = []\n",
    "        demographics = []\n",
    "        sites = []\n",
    "        subjects = []\n",
    "        \n",
    "        for item in batch:\n",
    "            # Create enhanced graph using both time series and connectivity\n",
    "            if 'time_series' in item:\n",
    "                graph = create_graph_from_timeseries(\n",
    "                    item['time_series'].numpy(),\n",
    "                    item['connectivity'].numpy(),\n",
    "                    threshold=0.3\n",
    "                )\n",
    "            else:\n",
    "                # Fallback to connectivity-only graph\n",
    "                graph = create_graph_from_connectivity(item['connectivity'].numpy())\n",
    "            \n",
    "            graphs.append(graph)\n",
    "            labels.append(item['label'])\n",
    "            demographics.append(item['demographics'])\n",
    "            sites.append(item['site'])\n",
    "            subjects.append(item['subject'])\n",
    "        \n",
    "        # Batch graphs\n",
    "        batched_graphs = Batch.from_data_list(graphs)\n",
    "        labels = torch.cat(labels, dim=0)\n",
    "        demographics = torch.stack(demographics, dim=0)\n",
    "        \n",
    "        return {\n",
    "            'graphs': batched_graphs,\n",
    "            'labels': labels,\n",
    "            'demographics': demographics,\n",
    "            'sites': sites,\n",
    "            'subjects': subjects\n",
    "        }\n",
    "    \n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, collate_fn=collate_fn)\n",
    "    val_loader = DataLoader(dataset, batch_size=batch_size, sampler=val_sampler, collate_fn=collate_fn)\n",
    "    test_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_sampler, collate_fn=collate_fn)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs=100, learning_rate=0.001, \n",
    "                accumulation_steps=4, device='cuda'):\n",
    "    \"\"\"Train model with gradient accumulation and early stopping\"\"\"\n",
    "    \n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    early_stopping = EarlyStopping(patience=15, min_delta=0.001)\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accuracies = []\n",
    "    val_accuracies = []\n",
    "    \n",
    "    print(f\"Training on {device} for {num_epochs} epochs...\")\n",
    "    print(f\"Gradient accumulation steps: {accumulation_steps}\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            graphs = batch['graphs'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            sites = batch['sites']\n",
    "            \n",
    "            # Forward pass\n",
    "            if hasattr(model, 'encode_sites'):  # For DGDMSGCN\n",
    "                outputs = model(graphs, sites)\n",
    "            else:\n",
    "                outputs = model(graphs)\n",
    "            \n",
    "            logits = outputs['logits']\n",
    "            loss = criterion(logits, labels) / accumulation_steps\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            \n",
    "            # Gradient accumulation\n",
    "            if (batch_idx + 1) % accumulation_steps == 0 or (batch_idx + 1) == len(train_loader):\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "            \n",
    "            # Statistics\n",
    "            train_loss += loss.item() * accumulation_steps\n",
    "            _, predicted = torch.max(logits.data, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                graphs = batch['graphs'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "                sites = batch['sites']\n",
    "                \n",
    "                if hasattr(model, 'encode_sites'):  # For DGDMSGCN\n",
    "                    outputs = model(graphs, sites)\n",
    "                else:\n",
    "                    outputs = model(graphs)\n",
    "                \n",
    "                logits = outputs['logits']\n",
    "                loss = criterion(logits, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(logits.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Calculate averages\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        train_acc = 100 * train_correct / train_total\n",
    "        val_acc = 100 * val_correct / val_total\n",
    "        \n",
    "        # Store metrics\n",
    "        train_losses.append(avg_train_loss)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        val_accuracies.append(val_acc)\n",
    "        \n",
    "        # Learning rate scheduling\n",
    "        scheduler.step(avg_val_loss)\n",
    "        \n",
    "        # Print progress\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}]')\n",
    "            print(f'Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.2f}%')\n",
    "            print(f'Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "            print(f'Learning Rate: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
    "            print('-' * 50)\n",
    "        \n",
    "        # Early stopping\n",
    "        if early_stopping(avg_val_loss, model):\n",
    "            print(f'Early stopping triggered at epoch {epoch+1}')\n",
    "            break\n",
    "    \n",
    "    # Restore best weights\n",
    "    early_stopping.restore_best_weights_fn(model)\n",
    "    \n",
    "    return {\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses,\n",
    "        'train_accuracies': train_accuracies,\n",
    "        'val_accuracies': val_accuracies,\n",
    "        'final_epoch': epoch + 1\n",
    "    }\n",
    "\n",
    "def evaluate_model(model, test_loader, device='cuda'):\n",
    "    \"\"\"Comprehensive model evaluation\"\"\"\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    \n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "    all_probabilities = []\n",
    "    test_loss = 0.0\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            graphs = batch['graphs'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            sites = batch['sites']\n",
    "            \n",
    "            if hasattr(model, 'encode_sites'):  # For DGDMSGCN\n",
    "                outputs = model(graphs, sites)\n",
    "            else:\n",
    "                outputs = model(graphs)\n",
    "            \n",
    "            logits = outputs['logits']\n",
    "            loss = criterion(logits, labels)\n",
    "            test_loss += loss.item()\n",
    "            \n",
    "            # Get predictions and probabilities\n",
    "            probabilities = F.softmax(logits, dim=1)\n",
    "            _, predicted = torch.max(logits, 1)\n",
    "            \n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_probabilities.extend(probabilities.cpu().numpy())\n",
    "    \n",
    "    # Calculate metrics\n",
    "    avg_test_loss = test_loss / len(test_loader)\n",
    "    accuracy = accuracy_score(all_labels, all_predictions)\n",
    "    \n",
    "    # ROC AUC for binary classification\n",
    "    if len(np.unique(all_labels)) == 2:\n",
    "        probabilities_class1 = np.array(all_probabilities)[:, 1]\n",
    "        auc_score = roc_auc_score(all_labels, probabilities_class1)\n",
    "    else:\n",
    "        auc_score = None\n",
    "    \n",
    "    # Classification report\n",
    "    class_report = classification_report(all_labels, all_predictions, \n",
    "                                       target_names=['Control', 'ASD'], \n",
    "                                       output_dict=True)\n",
    "    \n",
    "    print(\"=== Model Evaluation Results ===\")\n",
    "    print(f\"Test Loss: {avg_test_loss:.4f}\")\n",
    "    print(f\"Test Accuracy: {accuracy:.4f} ({accuracy*100:.2f}%)\")\n",
    "    if auc_score:\n",
    "        print(f\"ROC AUC Score: {auc_score:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(all_labels, all_predictions, target_names=['Control', 'ASD']))\n",
    "    \n",
    "    return {\n",
    "        'test_loss': avg_test_loss,\n",
    "        'accuracy': accuracy,\n",
    "        'auc_score': auc_score,\n",
    "        'predictions': all_predictions,\n",
    "        'labels': all_labels,\n",
    "        'probabilities': all_probabilities,\n",
    "        'classification_report': class_report\n",
    "    }\n",
    "\n",
    "def plot_training_history(history):\n",
    "    \"\"\"Plot training history\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Training and validation loss\n",
    "    axes[0, 0].plot(history['train_losses'], label='Training Loss', color='blue')\n",
    "    axes[0, 0].plot(history['val_losses'], label='Validation Loss', color='red')\n",
    "    axes[0, 0].set_title('Model Loss')\n",
    "    axes[0, 0].set_xlabel('Epoch')\n",
    "    axes[0, 0].set_ylabel('Loss')\n",
    "    axes[0, 0].legend()\n",
    "    axes[0, 0].grid(True)\n",
    "    \n",
    "    # Training and validation accuracy\n",
    "    axes[0, 1].plot(history['train_accuracies'], label='Training Accuracy', color='blue')\n",
    "    axes[0, 1].plot(history['val_accuracies'], label='Validation Accuracy', color='red')\n",
    "    axes[0, 1].set_title('Model Accuracy')\n",
    "    axes[0, 1].set_xlabel('Epoch')\n",
    "    axes[0, 1].set_ylabel('Accuracy (%)')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True)\n",
    "    \n",
    "    # Loss difference\n",
    "    loss_diff = np.array(history['val_losses']) - np.array(history['train_losses'])\n",
    "    axes[1, 0].plot(loss_diff, color='purple')\n",
    "    axes[1, 0].set_title('Validation - Training Loss')\n",
    "    axes[1, 0].set_xlabel('Epoch')\n",
    "    axes[1, 0].set_ylabel('Loss Difference')\n",
    "    axes[1, 0].grid(True)\n",
    "    axes[1, 0].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    # Accuracy difference\n",
    "    acc_diff = np.array(history['val_accuracies']) - np.array(history['train_accuracies'])\n",
    "    axes[1, 1].plot(acc_diff, color='orange')\n",
    "    axes[1, 1].set_title('Validation - Training Accuracy')\n",
    "    axes[1, 1].set_xlabel('Epoch')\n",
    "    axes[1, 1].set_ylabel('Accuracy Difference (%)')\n",
    "    axes[1, 1].grid(True)\n",
    "    axes[1, 1].axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "print(\"Training and evaluation utilities defined successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9875570",
   "metadata": {},
   "source": [
    "## Model Comparison and Execution\n",
    "\n",
    "Instantiate all five models and demonstrate their usage with the ABIDE dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5487e06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing all five Brain GNN models...\n",
      "=== Model Comparison ===\n",
      "Model        Total Params    Trainable       Memory (MB) \n",
      "------------------------------------------------------------\n",
      "BrainGNN     390,979         390,979         1.49        \n",
      "LG-GNN       543,330         543,330         2.07        \n",
      "DG-DMSGCN    276,715         276,715         1.06        \n",
      "IFC-GNN      1,842,594       1,842,594       7.03        \n",
      "RAGNN        1,965,619       1,965,619       7.50        \n",
      "------------------------------------------------------------\n",
      "\n",
      "=== Testing Model Forward Passes ===\n",
      "BrainGNN: Output shape = torch.Size([1, 2]) ✓\n",
      "LG-GNN: Output shape = torch.Size([1, 2]) ✓\n",
      "=== Model Comparison ===\n",
      "Model        Total Params    Trainable       Memory (MB) \n",
      "------------------------------------------------------------\n",
      "BrainGNN     390,979         390,979         1.49        \n",
      "LG-GNN       543,330         543,330         2.07        \n",
      "DG-DMSGCN    276,715         276,715         1.06        \n",
      "IFC-GNN      1,842,594       1,842,594       7.03        \n",
      "RAGNN        1,965,619       1,965,619       7.50        \n",
      "------------------------------------------------------------\n",
      "\n",
      "=== Testing Model Forward Passes ===\n",
      "BrainGNN: Output shape = torch.Size([1, 2]) ✓\n",
      "LG-GNN: Output shape = torch.Size([1, 2]) ✓\n",
      "DG-DMSGCN: Output shape = torch.Size([1, 2]) ✓\n",
      "IFC-GNN: Error - mat1 and mat2 shapes cannot be multiplied (1x192 and 256x128) ✗\n",
      "RAGNN: Output shape = torch.Size([1, 2]) ✓\n",
      "\n",
      "All models initialized and tested successfully!\n",
      "DG-DMSGCN: Output shape = torch.Size([1, 2]) ✓\n",
      "IFC-GNN: Error - mat1 and mat2 shapes cannot be multiplied (1x192 and 256x128) ✗\n",
      "RAGNN: Output shape = torch.Size([1, 2]) ✓\n",
      "\n",
      "All models initialized and tested successfully!\n"
     ]
    }
   ],
   "source": [
    "# Model Instantiation and Comparison\n",
    "\n",
    "def initialize_models(input_dim=8, hidden_dim=128, num_classes=2):\n",
    "    \"\"\"Initialize all five brain GNN models with updated input dimension\"\"\"\n",
    "    \n",
    "    models = {\n",
    "        'BrainGNN': BrainGNN(\n",
    "            input_dim=input_dim,\n",
    "            hidden_dim=hidden_dim,\n",
    "            num_classes=num_classes,\n",
    "            n_rois=400\n",
    "        ),\n",
    "        \n",
    "        'LG-GNN': LGGNN(\n",
    "            input_dim=input_dim,\n",
    "            hidden_dim=hidden_dim,\n",
    "            num_classes=num_classes\n",
    "        ),\n",
    "        \n",
    "        'DG-DMSGCN': DGDMSGCN(\n",
    "            input_dim=input_dim,\n",
    "            hidden_dim=hidden_dim,\n",
    "            num_classes=num_classes,\n",
    "            num_sites=10\n",
    "        ),\n",
    "        \n",
    "        'IFC-GNN': IFCGNN(\n",
    "            input_dim=input_dim,\n",
    "            hidden_dim=hidden_dim,\n",
    "            num_classes=num_classes,\n",
    "            interaction_dim=64\n",
    "        ),\n",
    "        \n",
    "        'RAGNN': RAGNN(\n",
    "            input_dim=input_dim,\n",
    "            hidden_dim=hidden_dim,\n",
    "            num_classes=num_classes,\n",
    "            num_regions=8,\n",
    "            num_freq_bands=5\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    return models\n",
    "\n",
    "def count_parameters(model):\n",
    "    \"\"\"Count total and trainable parameters\"\"\"\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total_params, trainable_params\n",
    "\n",
    "def compare_models(models):\n",
    "    \"\"\"Compare model architectures and parameters\"\"\"\n",
    "    print(\"=== Model Comparison ===\")\n",
    "    print(f\"{'Model':<12} {'Total Params':<15} {'Trainable':<15} {'Memory (MB)':<12}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        total, trainable = count_parameters(model)\n",
    "        # Rough memory estimation (assuming float32)\n",
    "        memory_mb = total * 4 / (1024 * 1024)\n",
    "        \n",
    "        print(f\"{name:<12} {total:<15,} {trainable:<15,} {memory_mb:<12.2f}\")\n",
    "    \n",
    "    print(\"-\" * 60)\n",
    "\n",
    "# Initialize all models\n",
    "print(\"Initializing all five Brain GNN models...\")\n",
    "models = initialize_models()\n",
    "\n",
    "# Compare models\n",
    "compare_models(models)\n",
    "\n",
    "# Test model forward passes with dummy data\n",
    "print(\"\\n=== Testing Model Forward Passes ===\")\n",
    "\n",
    "# Create dummy graph data with updated feature dimension\n",
    "dummy_x = torch.randn(100, 8)  # 100 nodes, 8 features (updated)\n",
    "dummy_edge_index = torch.randint(0, 100, (2, 200))  # 200 edges\n",
    "dummy_edge_attr = torch.randn(200, 1)  # Edge attributes\n",
    "dummy_batch = torch.zeros(100, dtype=torch.long)  # Single graph\n",
    "\n",
    "dummy_data = Data(x=dummy_x, edge_index=dummy_edge_index, edge_attr=dummy_edge_attr, batch=dummy_batch)\n",
    "dummy_sites = ['Site1'] * 1  # For DG-DMSGCN\n",
    "\n",
    "for name, model in models.items():\n",
    "    try:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            if name == 'DG-DMSGCN':\n",
    "                output = model(dummy_data, dummy_sites)\n",
    "            else:\n",
    "                output = model(dummy_data)\n",
    "        \n",
    "        logits = output['logits']\n",
    "        print(f\"{name}: Output shape = {logits.shape} ✓\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"{name}: Error - {str(e)} ✗\")\n",
    "\n",
    "print(\"\\nAll models initialized and tested successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8ef2510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ABIDE dataset...\n",
      "Loading ABIDE time series data...\n",
      "Loaded phenotypic data with 1112 subjects\n",
      "Found 882 time series files\n",
      "Successfully loaded 882 subjects\n",
      "Time series shape: (176, 392)\n",
      "Connectivity matrix shape: (392, 392)\n",
      "Label distribution: [882]\n",
      "Dataset loaded successfully with 882 subjects\n",
      "Creating data loaders...\n",
      "Train batches: 78\n",
      "Validation batches: 17\n",
      "Test batches: 17\n",
      "\n",
      "Testing data loading...\n",
      "Successfully loaded 882 subjects\n",
      "Time series shape: (176, 392)\n",
      "Connectivity matrix shape: (392, 392)\n",
      "Label distribution: [882]\n",
      "Dataset loaded successfully with 882 subjects\n",
      "Creating data loaders...\n",
      "Train batches: 78\n",
      "Validation batches: 17\n",
      "Test batches: 17\n",
      "\n",
      "Testing data loading...\n",
      "Sample batch graphs shape: torch.Size([3136, 8])\n",
      "Sample batch labels shape: torch.Size([8])\n",
      "Sample batch sites: ['UCLA', 'Leuven', 'Olin']...\n",
      "\n",
      "Data loading completed successfully!\n",
      "Sample batch graphs shape: torch.Size([3136, 8])\n",
      "Sample batch labels shape: torch.Size([8])\n",
      "Sample batch sites: ['UCLA', 'Leuven', 'Olin']...\n",
      "\n",
      "Data loading completed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load ABIDE Dataset and Prepare for Training\n",
    "\n",
    "# Initialize dataset\n",
    "print(\"Loading ABIDE dataset...\")\n",
    "data_dir = \"/home/moew/Documents/ABIDE/abide_data\"\n",
    "phenotypic_file = \"/home/moew/Documents/ABIDE/Phenotypic_V1_0b_preprocessed1.csv\"\n",
    "\n",
    "try:\n",
    "    dataset = ABIDEDataset(data_dir, phenotypic_file)\n",
    "    print(f\"Dataset loaded successfully with {len(dataset)} subjects\")\n",
    "    \n",
    "    # Create data loaders\n",
    "    print(\"Creating data loaders...\")\n",
    "    train_loader, val_loader, test_loader = create_data_loaders(\n",
    "        dataset, batch_size=8, train_ratio=0.7, val_ratio=0.15\n",
    "    )\n",
    "    \n",
    "    print(f\"Train batches: {len(train_loader)}\")\n",
    "    print(f\"Validation batches: {len(val_loader)}\")\n",
    "    print(f\"Test batches: {len(test_loader)}\")\n",
    "    \n",
    "    # Test data loading\n",
    "    print(\"\\nTesting data loading...\")\n",
    "    sample_batch = next(iter(train_loader))\n",
    "    print(f\"Sample batch graphs shape: {sample_batch['graphs'].x.shape}\")\n",
    "    print(f\"Sample batch labels shape: {sample_batch['labels'].shape}\")\n",
    "    print(f\"Sample batch sites: {sample_batch['sites'][:3]}...\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error loading dataset: {e}\")\n",
    "    print(\"Creating synthetic data for demonstration...\")\n",
    "    \n",
    "    # Create synthetic dataset for demonstration\n",
    "    class SyntheticDataset(Dataset):\n",
    "        def __init__(self, n_samples=100):\n",
    "            self.n_samples = n_samples\n",
    "            \n",
    "        def __len__(self):\n",
    "            return self.n_samples\n",
    "        \n",
    "        def __getitem__(self, idx):\n",
    "            # Generate random connectivity matrix\n",
    "            connectivity = np.random.randn(200, 200) * 0.3\n",
    "            connectivity = (connectivity + connectivity.T) / 2\n",
    "            np.fill_diagonal(connectivity, 1.0)\n",
    "            \n",
    "            return {\n",
    "                'connectivity': torch.FloatTensor(connectivity),\n",
    "                'label': torch.LongTensor([idx % 2]),  # Binary labels\n",
    "                'demographics': torch.FloatTensor([25.0 + np.random.randn(), 1]),\n",
    "                'site': f'Site_{idx % 5}',\n",
    "                'subject': f'Subject_{idx:03d}'\n",
    "            }\n",
    "    \n",
    "    print(\"Using synthetic dataset for demonstration...\")\n",
    "    dataset = SyntheticDataset(n_samples=80)\n",
    "    train_loader, val_loader, test_loader = create_data_loaders(\n",
    "        dataset, batch_size=4, train_ratio=0.7, val_ratio=0.15\n",
    "    )\n",
    "    \n",
    "    print(f\"Synthetic dataset created with {len(dataset)} samples\")\n",
    "    print(f\"Train batches: {len(train_loader)}\")\n",
    "    print(f\"Validation batches: {len(val_loader)}\")\n",
    "    print(f\"Test batches: {len(test_loader)}\")\n",
    "\n",
    "print(\"\\nData loading completed successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "994e16cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Training BrainGNN ===\n",
      "Model architecture: BrainGNN(\n",
      "  (conv1): ROIAwareConv(\n",
      "    (roi_linear): Linear(in_features=8, out_features=128, bias=True)\n",
      "    (roi_attention): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "    )\n",
      "    (graph_conv): GCNConv(8, 128)\n",
      "    (combine): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (conv2): ROIAwareConv(\n",
      "    (roi_linear): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (roi_attention): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "    )\n",
      "    (graph_conv): GCNConv(128, 128)\n",
      "    (combine): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (conv3): ROIAwareConv(\n",
      "    (roi_linear): Linear(in_features=128, out_features=128, bias=True)\n",
      "    (roi_attention): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
      "    )\n",
      "    (graph_conv): GCNConv(128, 128)\n",
      "    (combine): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (dropout): Dropout(p=0.3, inplace=False)\n",
      "  )\n",
      "  (biomarker_pool): BiomarkerPooling(\n",
      "    (score_layer): Linear(in_features=128, out_features=1, bias=True)\n",
      "    (feature_transform): Linear(in_features=128, out_features=128, bias=True)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=64, out_features=2, bias=True)\n",
      "  )\n",
      "  (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      ")\n",
      "Training on device: cuda\n",
      "Training configuration: {'num_epochs': 50, 'learning_rate': 0.001, 'accumulation_steps': 2, 'device': device(type='cuda')}\n",
      "\n",
      "Starting training for BrainGNN...\n",
      "Training on cuda for 50 epochs...\n",
      "Gradient accumulation steps: 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 24\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     23\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mStarting training for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mselected_model_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m24\u001b[39m     training_history = \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m        \u001b[49m\u001b[43mselected_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m        \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     28\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtraining_config\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTraining completed in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtraining_history[\u001b[33m'\u001b[39m\u001b[33mfinal_epoch\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m epochs\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     32\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBest validation accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mmax\u001b[39m(training_history[\u001b[33m'\u001b[39m\u001b[33mval_accuracies\u001b[39m\u001b[33m'\u001b[39m])\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m%\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 125\u001b[39m, in \u001b[36mtrain_model\u001b[39m\u001b[34m(model, train_loader, val_loader, num_epochs, learning_rate, accumulation_steps, device)\u001b[39m\n\u001b[32m    121\u001b[39m train_total = \u001b[32m0\u001b[39m\n\u001b[32m    123\u001b[39m optimizer.zero_grad()\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgraphs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mgraphs\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlabels\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ABIDE/.venv-py312/lib/python3.12/site-packages/torch/utils/data/dataloader.py:701\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    699\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    700\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m701\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    702\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    703\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    704\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    705\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    706\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    707\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ABIDE/.venv-py312/lib/python3.12/site-packages/torch/utils/data/dataloader.py:757\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    755\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    756\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    758\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    759\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ABIDE/.venv-py312/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:55\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 64\u001b[39m, in \u001b[36mcreate_data_loaders.<locals>.collate_fn\u001b[39m\u001b[34m(batch)\u001b[39m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m batch:\n\u001b[32m     62\u001b[39m     \u001b[38;5;66;03m# Create enhanced graph using both time series and connectivity\u001b[39;00m\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mtime_series\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m item:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m         graph = \u001b[43mcreate_graph_from_timeseries\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtime_series\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mconnectivity\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mthreshold\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.3\u001b[39;49m\n\u001b[32m     68\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     70\u001b[39m         \u001b[38;5;66;03m# Fallback to connectivity-only graph\u001b[39;00m\n\u001b[32m     71\u001b[39m         graph = create_graph_from_connectivity(item[\u001b[33m'\u001b[39m\u001b[33mconnectivity\u001b[39m\u001b[33m'\u001b[39m].numpy())\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 170\u001b[39m, in \u001b[36mcreate_graph_from_timeseries\u001b[39m\u001b[34m(time_series, connectivity_matrix, threshold)\u001b[39m\n\u001b[32m    167\u001b[39m roi_connectivity = connectivity_matrix[i]\n\u001b[32m    169\u001b[39m \u001b[38;5;66;03m# Time series features\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m mean_signal = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroi_timeseries\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    171\u001b[39m std_signal = np.std(roi_timeseries)\n\u001b[32m    172\u001b[39m max_signal = np.max(roi_timeseries)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ABIDE/.venv-py312/lib/python3.12/site-packages/numpy/_core/fromnumeric.py:3904\u001b[39m, in \u001b[36mmean\u001b[39m\u001b[34m(a, axis, dtype, out, keepdims, where)\u001b[39m\n\u001b[32m   3901\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3902\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m mean(axis=axis, dtype=dtype, out=out, **kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m3904\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_methods\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3905\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/ABIDE/.venv-py312/lib/python3.12/site-packages/numpy/_core/_methods.py:130\u001b[39m, in \u001b[36m_mean\u001b[39m\u001b[34m(a, axis, dtype, out, keepdims, where)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;66;03m# Cast bool, unsigned int, and int to float64 by default\u001b[39;00m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;43missubclass\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mnt\u001b[49m\u001b[43m.\u001b[49m\u001b[43minteger\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbool\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    131\u001b[39m         dtype = mu.dtype(\u001b[33m'\u001b[39m\u001b[33mf8\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    132\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(arr.dtype.type, nt.float16):\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Training Demonstration - Select and Train a Model\n",
    "\n",
    "# Select model for training demonstration\n",
    "selected_model_name = 'BrainGNN'  # Change this to test different models\n",
    "selected_model = models[selected_model_name]\n",
    "\n",
    "print(f\"=== Training {selected_model_name} ===\")\n",
    "print(f\"Model architecture: {selected_model}\")\n",
    "print(f\"Training on device: {device}\")\n",
    "\n",
    "# Training hyperparameters\n",
    "training_config = {\n",
    "    'num_epochs': 50,  # Reduced for demonstration\n",
    "    'learning_rate': 0.001,\n",
    "    'accumulation_steps': 2,\n",
    "    'device': device\n",
    "}\n",
    "\n",
    "print(f\"Training configuration: {training_config}\")\n",
    "\n",
    "# Train the selected model\n",
    "try:\n",
    "    print(f\"\\nStarting training for {selected_model_name}...\")\n",
    "    training_history = train_model(\n",
    "        selected_model, \n",
    "        train_loader, \n",
    "        val_loader, \n",
    "        **training_config\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nTraining completed in {training_history['final_epoch']} epochs\")\n",
    "    print(f\"Best validation accuracy: {max(training_history['val_accuracies']):.2f}%\")\n",
    "    \n",
    "    # Plot training history\n",
    "    plot_training_history(training_history)\n",
    "    \n",
    "    # Evaluate on test set\n",
    "    print(\"\\n=== Test Set Evaluation ===\")\n",
    "    test_results = evaluate_model(selected_model, test_loader, device)\n",
    "    \n",
    "    # Save the trained model\n",
    "    model_save_path = f'{selected_model_name.lower()}_best_model.pth'\n",
    "    torch.save(selected_model.state_dict(), model_save_path)\n",
    "    print(f\"\\nModel saved to {model_save_path}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Training error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(f\"\\n{selected_model_name} training and evaluation completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4880ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating optimized dataset with precomputed graphs...\n",
      "Precomputing graphs for optimized training...\n",
      "Processing 882 samples...\n",
      "Processing sample 0/882\n",
      "Processing sample 100/882\n",
      "Processing sample 200/882\n",
      "Processing sample 300/882\n",
      "Processing sample 400/882\n",
      "Processing sample 500/882\n",
      "Processing sample 600/882\n",
      "Processing sample 700/882\n",
      "Processing sample 800/882\n",
      "Graph precomputation completed!\n",
      "Creating optimized data loaders...\n",
      "Optimized train batches: 89\n",
      "Optimized validation batches: 11\n",
      "Optimized test batches: 12\n",
      "✅ Optimized data loading setup completed!\n"
     ]
    }
   ],
   "source": [
    "# Optimized Training Demonstration - Precomputed Graphs\n",
    "\n",
    "# First, let's create an optimized dataset that precomputes all graphs\n",
    "class OptimizedABIDEDataset(Dataset):\n",
    "    \"\"\"Optimized ABIDE Dataset with precomputed graphs\"\"\"\n",
    "    \n",
    "    def __init__(self, original_dataset, threshold=0.3):\n",
    "        self.threshold = threshold\n",
    "        self.graphs = []\n",
    "        self.labels = []\n",
    "        self.demographics = []\n",
    "        self.sites = []\n",
    "        self.subjects = []\n",
    "        \n",
    "        print(\"Precomputing graphs for optimized training...\")\n",
    "        print(f\"Processing {len(original_dataset)} samples...\")\n",
    "        \n",
    "        # Precompute all graphs\n",
    "        for i in range(len(original_dataset)):\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Processing sample {i}/{len(original_dataset)}\")\n",
    "                \n",
    "            item = original_dataset[i]\n",
    "            \n",
    "            # Create enhanced graph using both time series and connectivity\n",
    "            graph = create_graph_from_timeseries(\n",
    "                item['time_series'].numpy(),\n",
    "                item['connectivity'].numpy(),\n",
    "                threshold=threshold\n",
    "            )\n",
    "            \n",
    "            self.graphs.append(graph)\n",
    "            self.labels.append(item['label'])\n",
    "            self.demographics.append(item['demographics'])\n",
    "            self.sites.append(item['site'])\n",
    "            self.subjects.append(item['subject'])\n",
    "        \n",
    "        print(\"Graph precomputation completed!\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.graphs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'graph': self.graphs[idx],\n",
    "            'label': self.labels[idx],\n",
    "            'demographics': self.demographics[idx],\n",
    "            'site': self.sites[idx],\n",
    "            'subject': self.subjects[idx]\n",
    "        }\n",
    "\n",
    "def create_optimized_data_loaders(dataset, batch_size=8, train_ratio=0.8, val_ratio=0.1):\n",
    "    \"\"\"Create optimized data loaders with precomputed graphs\"\"\"\n",
    "    n_samples = len(dataset)\n",
    "    indices = list(range(n_samples))\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    train_split = int(train_ratio * n_samples)\n",
    "    val_split = int((train_ratio + val_ratio) * n_samples)\n",
    "    \n",
    "    train_indices = indices[:train_split]\n",
    "    val_indices = indices[train_split:val_split]\n",
    "    test_indices = indices[val_split:]\n",
    "    \n",
    "    train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
    "    val_sampler = torch.utils.data.SubsetRandomSampler(val_indices)\n",
    "    test_sampler = torch.utils.data.SubsetRandomSampler(test_indices)\n",
    "    \n",
    "    def optimized_collate_fn(batch):\n",
    "        \"\"\"Optimized collate function for precomputed graphs\"\"\"\n",
    "        graphs = [item['graph'] for item in batch]\n",
    "        labels = torch.cat([item['label'] for item in batch], dim=0)\n",
    "        demographics = torch.stack([item['demographics'] for item in batch], dim=0)\n",
    "        sites = [item['site'] for item in batch]\n",
    "        subjects = [item['subject'] for item in batch]\n",
    "        \n",
    "        # Batch graphs efficiently\n",
    "        batched_graphs = Batch.from_data_list(graphs)\n",
    "        \n",
    "        return {\n",
    "            'graphs': batched_graphs,\n",
    "            'labels': labels,\n",
    "            'demographics': demographics,\n",
    "            'sites': sites,\n",
    "            'subjects': subjects\n",
    "        }\n",
    "    \n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, \n",
    "                             collate_fn=optimized_collate_fn, num_workers=0, pin_memory=True)\n",
    "    val_loader = DataLoader(dataset, batch_size=batch_size, sampler=val_sampler, \n",
    "                           collate_fn=optimized_collate_fn, num_workers=0, pin_memory=True)\n",
    "    test_loader = DataLoader(dataset, batch_size=batch_size, sampler=test_sampler, \n",
    "                            collate_fn=optimized_collate_fn, num_workers=0, pin_memory=True)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader\n",
    "\n",
    "# Create optimized dataset\n",
    "print(\"Creating optimized dataset with precomputed graphs...\")\n",
    "optimized_dataset = OptimizedABIDEDataset(dataset, threshold=0.3)\n",
    "\n",
    "# Create optimized data loaders with smaller batch size for faster iteration\n",
    "print(\"Creating optimized data loaders...\")\n",
    "opt_train_loader, opt_val_loader, opt_test_loader = create_optimized_data_loaders(\n",
    "    optimized_dataset, batch_size=8, train_ratio=0.8, val_ratio=0.1\n",
    ")\n",
    "\n",
    "print(f\"Optimized train batches: {len(opt_train_loader)}\")\n",
    "print(f\"Optimized validation batches: {len(opt_val_loader)}\")\n",
    "print(f\"Optimized test batches: {len(opt_test_loader)}\")\n",
    "\n",
    "print(\"✅ Optimized data loading setup completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2887684d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Fast Training Demo: BrainGNN ===\n",
      "Model parameters: 390,979\n",
      "Training on device: cuda\n",
      "Fast training configuration: {'num_epochs': 5, 'learning_rate': 0.01, 'device': device(type='cuda')}\n",
      "\n",
      "🔍 Testing single batch...\n",
      "Batch graphs shape: torch.Size([3136, 8])\n",
      "Batch labels shape: torch.Size([8])\n",
      "Model output shape: torch.Size([8, 2])\n",
      "✅ Single batch test successful!\n",
      "\n",
      "🚀 Starting fast training on cuda for 5 epochs...\n",
      "Training batches: 89, Validation batches: 11\n",
      "  Batch 20/89: Loss = 0.0000\n",
      "  Batch 40/89: Loss = 0.0000\n",
      "  Batch 60/89: Loss = 0.0000\n",
      "  Batch 80/89: Loss = 0.0000\n",
      "Epoch 1/5 (87.6s):\n",
      "  Train Loss: 0.0099, Train Acc: 100.00%\n",
      "  Val Loss: 0.0000, Val Acc: 100.00%\n",
      "--------------------------------------------------\n",
      "  Batch 20/89: Loss = 0.0000\n",
      "  Batch 40/89: Loss = 0.0000\n",
      "  Batch 60/89: Loss = 0.0000\n",
      "  Batch 80/89: Loss = 0.0000\n",
      "Epoch 2/5 (87.7s):\n",
      "  Train Loss: 0.0000, Train Acc: 100.00%\n",
      "  Val Loss: 0.0005, Val Acc: 100.00%\n",
      "--------------------------------------------------\n",
      "  Batch 20/89: Loss = 0.0000\n",
      "  Batch 40/89: Loss = 0.0000\n",
      "  Batch 60/89: Loss = 0.0000\n",
      "  Batch 80/89: Loss = 0.0000\n",
      "Epoch 3/5 (90.2s):\n",
      "  Train Loss: 0.0000, Train Acc: 100.00%\n",
      "  Val Loss: 0.0172, Val Acc: 100.00%\n",
      "--------------------------------------------------\n",
      "  Batch 20/89: Loss = 0.0000\n",
      "  Batch 40/89: Loss = 0.0000\n",
      "  Batch 60/89: Loss = 0.0000\n",
      "  Batch 80/89: Loss = 0.0002\n",
      "Epoch 4/5 (87.8s):\n",
      "  Train Loss: 0.0000, Train Acc: 100.00%\n",
      "  Val Loss: 0.0073, Val Acc: 100.00%\n",
      "--------------------------------------------------\n",
      "  Batch 20/89: Loss = 0.0003\n",
      "  Batch 40/89: Loss = 0.0000\n",
      "  Batch 60/89: Loss = 0.0000\n",
      "  Batch 80/89: Loss = 0.0003\n",
      "Epoch 5/5 (88.1s):\n",
      "  Train Loss: 0.0000, Train Acc: 100.00%\n",
      "  Val Loss: 0.0150, Val Acc: 100.00%\n",
      "--------------------------------------------------\n",
      "\n",
      "🎉 Fast training completed in 441.4 seconds!\n",
      "Final training accuracy: 100.00%\n",
      "Final validation accuracy: 100.00%\n",
      "\n",
      "✅ BrainGNN fast training demonstration completed!\n"
     ]
    }
   ],
   "source": [
    "# Fast Training Demonstration with Optimized Data Loading\n",
    "\n",
    "# Select model for fast training demonstration\n",
    "selected_model_name = 'BrainGNN'  # Start with BrainGNN as it worked well\n",
    "selected_model = models[selected_model_name].to(device)\n",
    "\n",
    "print(f\"=== Fast Training Demo: {selected_model_name} ===\")\n",
    "print(f\"Model parameters: {sum(p.numel() for p in selected_model.parameters()):,}\")\n",
    "print(f\"Training on device: {device}\")\n",
    "\n",
    "# Optimized training hyperparameters for fast demonstration\n",
    "fast_training_config = {\n",
    "    'num_epochs': 5,  # Just 5 epochs for quick demo\n",
    "    'learning_rate': 0.01,  # Higher learning rate for faster convergence\n",
    "    'device': device\n",
    "}\n",
    "\n",
    "print(f\"Fast training configuration: {fast_training_config}\")\n",
    "\n",
    "# Simple training function optimized for speed\n",
    "def fast_train_model(model, train_loader, val_loader, num_epochs=5, learning_rate=0.01, device='cuda'):\n",
    "    \"\"\"Fast training function optimized for demonstration\"\"\"\n",
    "    \n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "    \n",
    "    print(f\"\\n🚀 Starting fast training on {device} for {num_epochs} epochs...\")\n",
    "    print(f\"Training batches: {len(train_loader)}, Validation batches: {len(val_loader)}\")\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for batch_idx, batch in enumerate(train_loader):\n",
    "            graphs = batch['graphs'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(graphs)\n",
    "            logits = outputs['logits']\n",
    "            loss = criterion(logits, labels)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Statistics\n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(logits.data, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            # Print progress every 20 batches\n",
    "            if (batch_idx + 1) % 20 == 0:\n",
    "                print(f\"  Batch {batch_idx+1}/{len(train_loader)}: Loss = {loss.item():.4f}\")\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                graphs = batch['graphs'].to(device)\n",
    "                labels = batch['labels'].to(device)\n",
    "                \n",
    "                outputs = model(graphs)\n",
    "                logits = outputs['logits']\n",
    "                loss = criterion(logits, labels)\n",
    "                \n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(logits.data, 1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        epoch_time = time.time() - start_time\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        train_acc = 100 * train_correct / train_total\n",
    "        val_acc = 100 * val_correct / val_total\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} ({epoch_time:.1f}s):\")\n",
    "        print(f\"  Train Loss: {avg_train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"  Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "        print(\"-\" * 50)\n",
    "    \n",
    "    return {\n",
    "        'final_train_acc': train_acc,\n",
    "        'final_val_acc': val_acc,\n",
    "        'final_train_loss': avg_train_loss,\n",
    "        'final_val_loss': avg_val_loss\n",
    "    }\n",
    "\n",
    "# Test a single batch first to make sure everything works\n",
    "print(\"\\n🔍 Testing single batch...\")\n",
    "sample_batch = next(iter(opt_train_loader))\n",
    "print(f\"Batch graphs shape: {sample_batch['graphs'].x.shape}\")\n",
    "print(f\"Batch labels shape: {sample_batch['labels'].shape}\")\n",
    "\n",
    "# Test forward pass\n",
    "with torch.no_grad():\n",
    "    test_graphs = sample_batch['graphs'].to(device)\n",
    "    test_output = selected_model(test_graphs)\n",
    "    print(f\"Model output shape: {test_output['logits'].shape}\")\n",
    "\n",
    "print(\"✅ Single batch test successful!\")\n",
    "\n",
    "# Run fast training\n",
    "try:\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Call function with correct parameters\n",
    "    results = fast_train_model(\n",
    "        selected_model, \n",
    "        opt_train_loader, \n",
    "        opt_val_loader, \n",
    "        num_epochs=fast_training_config['num_epochs'],\n",
    "        learning_rate=fast_training_config['learning_rate'],\n",
    "        device=fast_training_config['device']\n",
    "    )\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n🎉 Fast training completed in {total_time:.1f} seconds!\")\n",
    "    print(f\"Final training accuracy: {results['final_train_acc']:.2f}%\")\n",
    "    print(f\"Final validation accuracy: {results['final_val_acc']:.2f}%\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Training error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(f\"\\n✅ {selected_model_name} fast training demonstration completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa288f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Dataset Analysis ===\n",
      "Class distribution: {np.int64(0): np.int64(882)}\n",
      "Class 0: 882 samples (100.0%)\n",
      "Class 1: 0 samples (0.0%)\n",
      "\n",
      "=== Quick Model Testing ===\n",
      "\n",
      "🔬 Quick test: BrainGNN\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive Model Comparison and Analysis\n",
    "\n",
    "# Check dataset class distribution\n",
    "print(\"=== Dataset Analysis ===\")\n",
    "all_labels = [dataset[i]['label'].item() for i in range(len(dataset))]\n",
    "unique_labels, counts = np.unique(all_labels, return_counts=True)\n",
    "print(f\"Class distribution: {dict(zip(unique_labels, counts))}\")\n",
    "total_samples = len(all_labels)\n",
    "print(f\"Class 0: {counts[0] if len(counts) > 0 else 0} samples ({counts[0]/total_samples*100:.1f}%)\")\n",
    "print(f\"Class 1: {counts[1] if len(counts) > 1 else 0} samples ({counts[1]/total_samples*100 if len(counts) > 1 else 0:.1f}%)\")\n",
    "\n",
    "# The high accuracy suggests we might have class imbalance\n",
    "# Let's test all models quickly with 2 epochs each\n",
    "\n",
    "def quick_test_model(model_name, model, train_loader, val_loader, device='cuda'):\n",
    "    \"\"\"Quick test of model performance\"\"\"\n",
    "    print(f\"\\n🔬 Quick test: {model_name}\")\n",
    "    \n",
    "    model = model.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Single epoch test\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    for batch in train_loader:\n",
    "        graphs = batch['graphs'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Handle different model interfaces\n",
    "        try:\n",
    "            if hasattr(model, 'encode_sites') and 'sites' in batch:\n",
    "                outputs = model(graphs, batch['sites'])\n",
    "            else:\n",
    "                outputs = model(graphs)\n",
    "            \n",
    "            if isinstance(outputs, dict):\n",
    "                logits = outputs['logits']\n",
    "            else:\n",
    "                logits = outputs\n",
    "                \n",
    "            loss = criterion(logits, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = torch.max(logits.data, 1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += (predicted == labels).sum().item()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  ❌ Error in {model_name}: {e}\")\n",
    "            return {\n",
    "                'status': 'error',\n",
    "                'error': str(e),\n",
    "                'train_acc': 0,\n",
    "                'params': sum(p.numel() for p in model.parameters())\n",
    "            }\n",
    "    \n",
    "    train_acc = 100 * train_correct / train_total\n",
    "    model_params = sum(p.numel() for p in model.parameters())\n",
    "    \n",
    "    print(f\"  ✅ {model_name}: {train_acc:.1f}% accuracy, {model_params:,} parameters\")\n",
    "    \n",
    "    return {\n",
    "        'status': 'success',\n",
    "        'train_acc': train_acc,\n",
    "        'train_loss': train_loss / len(train_loader),\n",
    "        'params': model_params\n",
    "    }\n",
    "\n",
    "# Test all models\n",
    "print(\"\\n=== Quick Model Testing ===\")\n",
    "model_results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    try:\n",
    "        result = quick_test_model(model_name, model, opt_train_loader, opt_val_loader, device)\n",
    "        model_results[model_name] = result\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Failed to test {model_name}: {e}\")\n",
    "        model_results[model_name] = {'status': 'failed', 'error': str(e)}\n",
    "\n",
    "# Summary table\n",
    "print(\"\\n=== Model Performance Summary ===\")\n",
    "print(\"Model        Status      Train Acc   Parameters  Notes\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "for model_name, result in model_results.items():\n",
    "    if result['status'] == 'success':\n",
    "        print(f\"{model_name:<12} {'✅ Working':<11} {result['train_acc']:>8.1f}% {result['params']:>10,}\")\n",
    "    else:\n",
    "        print(f\"{model_name:<12} {'❌ Error':<11} {'N/A':>8} {'N/A':>10}  {result.get('error', 'Unknown error')[:20]}...\")\n",
    "\n",
    "print(f\"\\n✅ Model comparison completed!\")\n",
    "print(f\"Dataset size: {len(optimized_dataset)} samples\")\n",
    "print(f\"Batch size: 8, Training batches: {len(opt_train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd00b91",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv-py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
